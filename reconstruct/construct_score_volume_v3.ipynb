{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD653/MD653_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD653/MD653_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD653/MD653_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD653/MD653_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD652/MD652_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD652/MD652_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD652/MD652_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD652/MD652_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD642/MD642_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD657/MD657_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from multiprocess import Pool\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from conversion import images_to_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_setting = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "downscale = 32\n",
    "voxel_z_size = SECTION_THICKNESS/(XY_PIXEL_DISTANCE_LOSSLESS * downscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scoremap_worker(stack, sec, structure, downscale, classifier_setting):\n",
    "    try:\n",
    "        actual_setting = resolve_actual_setting(setting=classifier_setting, stack=stack, sec=sec)\n",
    "        sm = DataManager.load_scoremap(stack=stack, section=sec, structure=structure, downscale=downscale, setting=actual_setting)\n",
    "        return sm\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_scoremaps_multiple_sections_parallel(sections, stack, structure, downscale, classifier_setting):\n",
    "    pool = Pool(12)\n",
    "    scoremaps = pool.map(lambda sec: load_scoremap_worker(stack, sec, structure, downscale, classifier_setting=classifier_setting),\n",
    "                                     sections)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return {sec: sm for sec, sm in zip(sections, scoremaps) if sm is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_scoremaps_multiple_sections_sequential(sections, stack, structure, downscale, setting):\n",
    "    scoremaps = {}\n",
    "    for sec in sections:\n",
    "#         t = time.time()\n",
    "        scoremaps[sec-1] = DataManager.load_scoremap(stack=stack, section=sec, structure=structure, downscale=downscale, setting=setting)\n",
    "#         sys.stderr.write('Load scoremaps: %.2f seconds\\n' % (time.time() - t))\n",
    "    return scoremaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7N\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load scoremaps: 13.46 seconds\n",
      "Create score volume: 4.68 seconds\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD603']:\n",
    "    \n",
    "    first_sec, last_sec = metadata_cache['section_limits'][stack]\n",
    "    \n",
    "#     for structure in all_known_structures:\n",
    "    for structure in ['7N']:\n",
    "        print structure\n",
    "    \n",
    "        t = time.time()\n",
    "        scoremaps = load_scoremaps_multiple_sections_parallel(stack=stack, sections=range(first_sec, last_sec+1), \n",
    "                                                        structure=structure, downscale=downscale, classifier_setting=classifier_setting)\n",
    "        \n",
    "        if len(scoremaps) < 2:\n",
    "            sys.stderr.write('Number of valid scoremaps for %s is less than 2.\\n' % structure)\n",
    "            continue\n",
    "        \n",
    "        sys.stderr.write('Load scoremaps: %.2f seconds\\n' % (time.time() - t)) # 10-40s (down=32, 12 processes)\n",
    "        \n",
    "        t = time.time()\n",
    "        score_volume, score_volume_bbox = images_to_volume(images=scoremaps, voxel_size=(1, 1, voxel_z_size), \n",
    "                                                           first_sec=first_sec-1, last_sec=last_sec-1)\n",
    "        sys.stderr.write('Create score volume: %.2f seconds\\n' % (time.time() - t)) # 2s\n",
    "        \n",
    "#         t = time.time()\n",
    "\n",
    "        score_volume_filepath = DataManager.get_score_volume_filepath(stack=stack, downscale=downscale, structure=structure, classifier_setting=classifier_setting)\n",
    "        create_if_not_exists(os.path.dirname(score_volume_filepath))\n",
    "        \n",
    "        bp.pack_ndarray_file(score_volume.astype(np.float16), score_volume_filepath)\n",
    "\n",
    "        score_volume_bbox_filepath = DataManager.get_score_volume_bbox_filepath(stack=stack, downscale=downscale, structure=structure,\n",
    "                                                                               classifier_setting=classifier_setting)\n",
    "        np.savetxt(score_volume_bbox_filepath, np.array(score_volume_bbox)[None], fmt='%d')\n",
    "        \n",
    "        del score_volume, scoremaps\n",
    "        \n",
    "#         sys.stderr.write('Save score volume: %.2f seconds\\n' % (time.time() - t)) # 1s (down=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD642']:\n",
    "    \n",
    "    first_sec, last_sec = metadata_cache['section_limits'][stack]\n",
    "\n",
    "    nissl_sections = []\n",
    "    for sec in range(first_sec, last_sec):\n",
    "        fn = metadata_cache['sections_to_filenames'][stack][sec]\n",
    "        if not is_invalid(fn) and fn.split('-')[1][0] == 'N':\n",
    "            nissl_sections.append(sec)\n",
    "    \n",
    "    for structure in all_known_structures:\n",
    "#     for structure in ['7N']:\n",
    "        \n",
    "        print structure\n",
    "    \n",
    "        t = time.time()\n",
    "        scoremaps = load_scoremaps_multiple_sections_parallel(stack=stack, sections=nissl_sections, \n",
    "                                                              structure=structure, downscale=downscale, \n",
    "                                                              classifier_setting=classifier_setting)\n",
    "        \n",
    "        if len(scoremaps) < 2:\n",
    "            sys.stderr.write('Number of valid scoremaps for %s is less than 2.\\n' % structure)\n",
    "            continue\n",
    "        \n",
    "        sys.stderr.write('Load scoremaps: %.2f seconds\\n' % (time.time() - t)) # 10-40s (down=32, 12 processes)\n",
    "        \n",
    "        t = time.time()\n",
    "        score_volume, score_volume_bbox = images_to_volume(images=scoremaps, voxel_size=(1, 1, voxel_z_size), \n",
    "                                                           first_sec=np.min(nissl_sections)-1, \n",
    "                                                           last_sec=np.max(nissl_sections)-1)\n",
    "        sys.stderr.write('Create score volume: %.2f seconds\\n' % (time.time() - t)) # 2s\n",
    "        \n",
    "#         t = time.time()\n",
    "\n",
    "        score_volume_filepath = DataManager.get_score_volume_filepath(stack=stack, downscale=downscale, \n",
    "                                                                      structure=structure, \n",
    "                                                                      classifier_setting=classifier_setting)\n",
    "        create_if_not_exists(os.path.dirname(score_volume_filepath))\n",
    "        bp.pack_ndarray_file(score_volume.astype(np.float16), score_volume_filepath)\n",
    "\n",
    "#         score_volume_bbox_filepath = DataManager.get_score_volume_bbox_filepath(stack=stack, downscale=downscale, structure=structure,\n",
    "#                                                                                classifier_setting=classifier_setting)\n",
    "#         np.savetxt(score_volume_bbox_filepath, np.array(score_volume_bbox)[None], fmt='%d')\n",
    "        \n",
    "        del score_volume, scoremaps\n",
    "        \n",
    "#         sys.stderr.write('Save score volume: %.2f seconds\\n' % (time.time() - t)) # 1s (down=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N\n",
      "6N\n",
      "7N\n",
      "7n\n",
      "Amb\n",
      "LC\n",
      "LRt\n",
      "Pn\n",
      "Tz\n",
      "VLL\n",
      "RMC\n",
      "SNC\n",
      "SNR\n",
      "3N\n",
      "4N\n",
      "Sp5I\n",
      "Sp5O\n",
      "Sp5C\n",
      "PBG\n",
      "10N\n",
      "VCA\n",
      "VCP\n",
      "DC\n",
      "AP\n",
      "12N\n",
      "RtTg\n",
      "sp5\n",
      "outerContour\n",
      "SC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File does not exist: /oasis/projects/nsf/csd395/yuncong/CSHL_volumes/MD642/MD642_down32_scoreVolume_clf_2/score_volumes/MD642_down32_scoreVolume_clf_2_sp5.bp\n",
      "File does not exist: /oasis/projects/nsf/csd395/yuncong/CSHL_volumes/MD642/MD642_down32_scoreVolume_clf_2/score_volumes/MD642_down32_scoreVolume_clf_2_outerContour.bp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IC\n"
     ]
    }
   ],
   "source": [
    "for structure in all_known_structures:\n",
    "    print structure\n",
    "    try:\n",
    "        score_volume = DataManager.load_score_volume(stack='MD642', structure=structure, downscale=32, \n",
    "                                                 classifier_setting=classifier_setting)\n",
    "        score_volume_cropped = score_volume[:, :600, :]\n",
    "\n",
    "        score_volume_filepath = DataManager.get_score_volume_filepath(stack=stack, downscale=downscale, \n",
    "                                                                  structure=structure, \n",
    "                                                                  classifier_setting=classifier_setting)\n",
    "        create_if_not_exists(os.path.dirname(score_volume_filepath))\n",
    "        bp.pack_ndarray_file(score_volume_cropped.astype(np.float16), score_volume_filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_volume_sections(score_volume_cropped, cmap=plt.cm.hot, every=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
