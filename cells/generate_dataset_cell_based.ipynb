{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network_model</th>\n",
       "      <th>stain</th>\n",
       "      <th>margins</th>\n",
       "      <th>num_sample_per_class</th>\n",
       "      <th>stacks</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Inception-BN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>200/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Inception-BN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>200/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Inception-BN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>200/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>cell</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>cell</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           network_model  stain  margins  num_sample_per_class stacks\n",
       "dataset_id                                                           \n",
       "20          Inception-BN  nissl  200/500                  1000  MD585\n",
       "21          Inception-BN  nissl  200/500                  1000  MD589\n",
       "22          Inception-BN  nissl  200/500                  1000  MD594\n",
       "98                  cell  nissl      500                  1000  MD594\n",
       "99                  cell  nissl      500                  1000  MD589"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_id = 98\n",
    "dataset_properties = dataset_settings.loc[dataset_id]\n",
    "\n",
    "num_samples_per_label = dataset_properties['num_sample_per_class']\n",
    "stacks = dataset_properties['stacks'].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structures_to_sample = all_known_structures\n",
    "\n",
    "# negative_labels_to_sample = [s + '_negative' for s in structures_to_sample]\n",
    "\n",
    "margins_to_sample = map(int, str(dataset_properties['margins']).split('/'))\n",
    "\n",
    "surround_positive_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix=surr_l) \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample \n",
    "                             for surr_l in structures_to_sample\n",
    "                             if surr_l != s]\n",
    "\n",
    "surround_noclass_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix='noclass') \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample]\n",
    "\n",
    "labels_to_sample = structures_to_sample + surround_positive_labels_to_sample + surround_noclass_labels_to_sample + ['bg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cell_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_predefined_regions_one_section_by_label(stack, sec, margins_to_sample, labeled_contours, num_samples_per_label=None):\n",
    "    \"\"\"\n",
    "    Sample region addresses in a particular section and associate them with different labels (positive, surround, negative, noclass, foreground, background, etc.).\n",
    "    \n",
    "    Args:\n",
    "        region_contours (list of nx2 arrays): list of contour vertices.\n",
    "        margins_to_sample (list of ints):\n",
    "        labeled_contours (dict of nx2 arrays): {label: contour vertices}\n",
    "        \n",
    "    Returns:\n",
    "        dict of 3-tuple list: {label: list of (stack, section, region_index)}.\n",
    "        If section is invalid, return None.\n",
    "    \"\"\"\n",
    "\n",
    "    addresses = {}\n",
    "\n",
    "    if is_invalid(stack=stack, sec=sec):\n",
    "        sys.stderr.write('Regions on section %d are not sampled because the section is invalid.\\n' % sec)\n",
    "        return\n",
    "    \n",
    "    region_contours = load_cell_classifier_data(what='region_contours', stack=stack, sec=sec, ext='bp')\n",
    "    region_labels = label_regions(stack=stack, section=sec, \n",
    "                                  region_contours=region_contours,\n",
    "                                  surround_margins=margins_to_sample,\n",
    "                                  labeled_contours=labeled_contours)\n",
    "\n",
    "    for label, region_indices in region_labels.iteritems():\n",
    "        if label == 'bg' or len(region_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        if num_samples_per_label is None:\n",
    "            addresses[label] = [(stack, sec, ridx) for ridx in region_indices]\n",
    "        else:\n",
    "            sampled_region_indices = np.random.choice(region_indices, min(num_samples_per_label, len(region_indices)), replace=False)\n",
    "            addresses[label] = [(stack, sec, ridx) for ridx in sampled_region_indices]\n",
    "\n",
    "    return addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cell_based_features_one_section_(stack, section, region_indices):\n",
    "    \"\"\"\n",
    "    Load pre-computed cell-based features for a list of regions on a particular section.\n",
    "    \"\"\"\n",
    "    \n",
    "    region_features_all_regions = load_cell_classifier_data(what='region_features', stack=stack, sec=section, ext='hdf')\n",
    "    # Loading hdf ~ 2 seconds.\n",
    "    \n",
    "    features1 = np.asarray([rf['largeOrientationHist'] for rf in region_features_all_regions])\n",
    "    features2 = np.asarray([rf['largeSizeHist'] for rf in region_features_all_regions])\n",
    "    features3 = np.asarray([rf['largeLargeLinkLenHist'] for rf in region_features_all_regions])\n",
    "    features4 = np.asarray([rf['largeSmallLinkLenHist'] for rf in region_features_all_regions])\n",
    "    \n",
    "        \n",
    "    f1 = features1[region_indices]\n",
    "    f1n = f1/f1.sum(axis=1)[:,None].astype(np.float)\n",
    "    \n",
    "    f2 = features2[region_indices]\n",
    "    f2n = f2/f2.sum(axis=1)[:,None].astype(np.float)\n",
    "    \n",
    "    f3 = features3[region_indices]\n",
    "    f3n = f3/f3.sum(axis=1)[:,None].astype(np.float)\n",
    "    \n",
    "    f4 = features4[region_indices]\n",
    "    f4n = f4/f4.sum(axis=1)[:,None].astype(np.float)\n",
    "    \n",
    "    features = np.c_[f1n, f2n, f3n, f4n]\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_dataset_cell_based(num_samples_per_label, stacks, labels_to_sample):\n",
    "    \"\"\"\n",
    "    Generate dataset.\n",
    "    - Extract addresses\n",
    "    - Map addresses to features\n",
    "    - Remove None features\n",
    "    \n",
    "    Returns:\n",
    "        features, addresseslab\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample addresses\n",
    "    \n",
    "    addresses = defaultdict(list)\n",
    "    addresses_by_section_by_label = []\n",
    "    \n",
    "#     t = time.time()\n",
    "    \n",
    "    for stack in stacks:\n",
    "        \n",
    "        first_sec, last_sec = metadata_cache['section_limits'][stack]\n",
    "    \n",
    "        t1 = time.time()\n",
    "\n",
    "        contours_df, _ = DataManager.load_annotation_v3(stack=stack)\n",
    "        labeled_contours = contours_df[(contours_df['orientation'] == 'sagittal') & (contours_df['downsample'] == 1)].drop_duplicates(subset=['section', 'name', 'side', 'filename', 'downsample', 'creator'])\n",
    "        labeled_contours = convert_annotation_v3_original_to_aligned_cropped(labeled_contours, stack=stack)\n",
    "\n",
    "        sys.stderr.write('Load annotation. Time: %.2f seconds.\\n' % (time.time() - t1))\n",
    "\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Sample addresses from each section\n",
    "\n",
    "        pool = Pool(NUM_CORES/2)\n",
    "        addresses_by_section_by_label_curr_stack = \\\n",
    "        pool.map(lambda sec: sample_predefined_regions_one_section_by_label(stack=stack, sec=sec, \n",
    "                                                                 margins_to_sample=margins_to_sample,\n",
    "                                                                 labeled_contours=labeled_contours[labeled_contours['section']==sec],\n",
    "                                                                 num_samples_per_label=30),\n",
    "                 range(first_sec, last_sec+1))\n",
    "#                  range(150, 170))\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "                \n",
    "        addresses_by_section_by_label += addresses_by_section_by_label_curr_stack\n",
    "\n",
    "        sys.stderr.write('Sample addresses (stack %s): %.2s seconds.\\n' % (stack, time.time() - t1))\n",
    "        \n",
    "    # Aggregate addresses sampled form each section\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    addresses_by_label = defaultdict(list)\n",
    "    for addrs_by_label in addresses_by_section_by_label:\n",
    "        if addrs_by_label is not None: # handle cases of invalid sections for which sampling function returns None\n",
    "            for label, addrs in addrs_by_label.iteritems():\n",
    "                addresses_by_label[label] += addrs\n",
    "    addresses_by_label.default_factory = None\n",
    "    \n",
    "    if num_samples_per_label is not None:\n",
    "        import random\n",
    "        addresses_by_label = {label: random.sample(addrs, min(num_samples_per_label/len(stacks), len(addrs))) \n",
    "                              for label, addrs in addresses_by_label.iteritems()}\n",
    "\n",
    "    # Remove unwanted labels\n",
    "    addresses_by_label = {label: addrs for label, addrs in addresses_by_label.iteritems() if label in labels_to_sample}\n",
    "    \n",
    "    sys.stderr.write('Aggregate addresses: %.2f seconds\\n' % (time.time() - t))    \n",
    "    \n",
    "    # Map addresses to features\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    load_cell_based_features_given_address_list = lambda addrs: smart_map(addrs, keyfunc=lambda (st, se, ri): (st, se),\n",
    "                       func=lambda (st, se), gr: load_cell_based_features_one_section_(st, se, [ri for _,_,ri in gr]))\n",
    "    features_by_label = apply_function_to_dict(load_cell_based_features_given_address_list, addresses_by_label)\n",
    "    features_by_label = apply_function_to_dict(np.asarray, features_by_label)\n",
    "    \n",
    "    sys.stderr.write('Map addresses to features: %.2f seconds\\n' % (time.time() - t))\n",
    "    \n",
    "    # Remove features that are None are contain nan values.\n",
    "\n",
    "    for name in features_by_label.keys():\n",
    "        valid = [(ftr, addr) for ftr, addr in zip(features_by_label[name], addresses_by_label[name])\n",
    "                    if ftr is not None and not np.any(np.isnan(ftr))]\n",
    "        res = zip(*valid)\n",
    "        features_by_label[name] = np.array(res[0])\n",
    "        addresses_by_label[name] = res[1]\n",
    "    \n",
    "    return features_by_label, addresses_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'No object named structures in the file'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotation has no structures.\n",
      "Load annotation. Time: 1.36 seconds.\n",
      "Analyzing section 92..\n",
      "Analyzing section 93..\n",
      "Analyzing section 94..\n",
      "Analyzing section 95..\n",
      "Analyzing section 96..\n",
      "Analyzing section 101..\n",
      "Analyzing section 97..\n",
      "Analyzing section 102..\n",
      "Analyzing section 110..\n",
      "Analyzing section 98..\n",
      "Analyzing section 103..\n",
      "Analyzing section 99..\n",
      "Analyzing section 104..\n",
      "Analyzing section 100..\n",
      "Analyzing section 111..\n",
      "Analyzing section 119..\n",
      "Analyzing section 105..\n",
      "Analyzing section 112..\n",
      "Analyzing section 128..\n",
      "Analyzing section 120..\n",
      "Analyzing section 106..\n",
      "Analyzing section 113..\n",
      "Analyzing section 137..\n",
      "Analyzing section 121..\n",
      "Analyzing section 107..\n",
      "Analyzing section 129..\n",
      "Analyzing section 122..\n",
      "Analyzing section 114..\n",
      "Analyzing section 146..\n",
      "Analyzing section 108..\n",
      "Analyzing section 123..\n",
      "Analyzing section 115..\n",
      "Analyzing section 155..\n",
      "Analyzing section 130..\n",
      "Analyzing section 138..\n",
      "Analyzing section 109..\n",
      "Analyzing section 124..\n",
      "Analyzing section 116..\n",
      "Analyzing section 125..\n",
      "Analyzing section 147..\n",
      "Analyzing section 164..\n",
      "Regions on section 131 are not sampled because the section is invalid.\n",
      "Analyzing section 132..\n",
      "Analyzing section 117..\n",
      "Analyzing section 139..\n",
      "Analyzing section 126..\n",
      "Analyzing section 173..\n",
      "Analyzing section 118..\n",
      "Analyzing section 127..\n",
      "Analyzing section 156..\n",
      "Analyzing section 148..\n",
      "Analyzing section 140..\n",
      "Analyzing section 133..\n",
      "Analyzing section 182..\n",
      "Analyzing section 165..\n",
      "Analyzing section 141..\n",
      "Analyzing section 191..\n",
      "Analyzing section 134..\n",
      "Analyzing section 149..\n",
      "Analyzing section 174..\n",
      "Analyzing section 157..\n",
      "Analyzing section 135..\n",
      "Analyzing section 142..\n",
      "Analyzing section 183..\n",
      "Analyzing section 166..\n",
      "Analyzing section 150..\n",
      "Analyzing section 136..\n",
      "Analyzing section 143..\n",
      "Analyzing section 175..\n",
      "Analyzing section 192..\n",
      "Analyzing section 158..\n",
      "Analyzing section 151..\n",
      "Analyzing section 200..\n",
      "Analyzing section 144..\n",
      "Analyzing section 184..\n",
      "Analyzing section 167..\n",
      "Analyzing section 176..\n",
      "Analyzing section 145..\n",
      "Analyzing section 159..\n",
      "Regions on section 193 are not sampled because the section is invalid.\n",
      "Analyzing section 194..\n",
      "Analyzing section 201..\n",
      "Analyzing section 152..\n",
      "Analyzing section 209..\n",
      "Analyzing section 185..\n",
      "Analyzing section 168..\n",
      "Analyzing section 160..\n",
      "Analyzing section 202..\n",
      "Analyzing section 177..\n",
      "Analyzing section 153..\n",
      "Analyzing section 195..\n",
      "Analyzing section 203..\n",
      "Analyzing section 210..\n",
      "Analyzing section 186..\n",
      "Analyzing section 169..\n",
      "Analyzing section 178..\n",
      "Analyzing section 161..\n",
      "Analyzing section 154..\n",
      "Analyzing section 196..\n",
      "Analyzing section 204..\n",
      "Analyzing section 211..\n",
      "Analyzing section 197..\n",
      "Analyzing section 179..\n",
      "Regions on section 187 are not sampled because the section is invalid.\n",
      "Analyzing section 188..\n",
      "Analyzing section 170..\n",
      "Analyzing section 162..\n",
      "Analyzing section 218..\n",
      "Analyzing section 205..\n",
      "Analyzing section 212..\n",
      "Analyzing section 198..\n",
      "Analyzing section 206..\n",
      "Analyzing section 219..\n",
      "Analyzing section 189..\n",
      "Analyzing section 180..\n",
      "Analyzing section 171..\n",
      "Analyzing section 163..\n",
      "Analyzing section 213..\n",
      "Analyzing section 199..\n",
      "Analyzing section 220..\n",
      "Analyzing section 207..\n",
      "Analyzing section 181..\n",
      "Analyzing section 190..\n",
      "Analyzing section 214..\n",
      "Analyzing section 172..\n",
      "Analyzing section 227..\n",
      "Analyzing section 221..\n",
      "Analyzing section 208..\n",
      "Analyzing section 236..\n",
      "Analyzing section 228..\n",
      "Analyzing section 215..\n",
      "Analyzing section 245..\n",
      "Analyzing section 222..\n",
      "Analyzing section 254..\n",
      "Analyzing section 229..\n",
      "Analyzing section 237..\n",
      "Analyzing section 263..\n",
      "Analyzing section 216..\n",
      "Analyzing section 223..\n",
      "Analyzing section 272..\n",
      "Analyzing section 255..\n",
      "Analyzing section 246..\n",
      "Regions on section 238 are not sampled because the section is invalid.\n",
      "Analyzing section 239..\n",
      "Analyzing section 230..\n",
      "Analyzing section 224..\n",
      "Analyzing section 264..\n",
      "Analyzing section 217..\n",
      "Analyzing section 256..\n",
      "Analyzing section 273..\n",
      "Analyzing section 231..\n",
      "Analyzing section 247..\n",
      "Analyzing section 240..\n",
      "Analyzing section 225..\n",
      "Analyzing section 265..\n",
      "Analyzing section 232..\n",
      "Analyzing section 257..\n",
      "Analyzing section 274..\n",
      "Analyzing section 281..\n",
      "Analyzing section 226..\n",
      "Analyzing section 241..\n",
      "Analyzing section 248..\n",
      "Analyzing section 233..\n",
      "Analyzing section 266..\n",
      "Analyzing section 258..\n",
      "Analyzing section 275..\n",
      "Analyzing section 290..\n",
      "Analyzing section 282..\n",
      "Analyzing section 242..\n",
      "Analyzing section 234..\n",
      "Analyzing section 249..\n",
      "Analyzing section 267..\n",
      "Analyzing section 276..\n",
      "Analyzing section 259..\n",
      "Analyzing section 283..\n",
      "Analyzing section 291..\n",
      "Analyzing section 235..\n",
      "Analyzing section 243..\n",
      "Analyzing section 277..\n",
      "Analyzing section 250..\n",
      "Analyzing section 268..\n",
      "Analyzing section 260..\n",
      "Analyzing section 284..\n",
      "Analyzing section 292..\n",
      "Analyzing section 299..\n",
      "Analyzing section 244..\n",
      "Analyzing section 251..\n",
      "Analyzing section 269..\n",
      "Analyzing section 278..\n",
      "Regions on section 261 are not sampled because the section is invalid.\n",
      "Analyzing section 262..\n",
      "Analyzing section 285..\n",
      "Analyzing section 300..\n",
      "Analyzing section 293..\n",
      "Analyzing section 308..\n",
      "Analyzing section 279..\n",
      "Analyzing section 252..\n",
      "Analyzing section 301..\n",
      "Analyzing section 286..\n",
      "Analyzing section 270..\n",
      "Analyzing section 294..\n",
      "Analyzing section 317..\n",
      "Analyzing section 309..\n",
      "Analyzing section 318..\n",
      "Analyzing section 280..\n",
      "Analyzing section 302..\n",
      "Analyzing section 310..\n",
      "Analyzing section 253..\n",
      "Analyzing section 271..\n",
      "Analyzing section 319..\n",
      "Analyzing section 287..\n",
      "Analyzing section 295..\n",
      "Analyzing section 311..\n",
      "Analyzing section 320..\n",
      "Analyzing section 303..\n",
      "Analyzing section 312..\n",
      "Analyzing section 326..\n",
      "Analyzing section 321..\n",
      "Analyzing section 313..\n",
      "Analyzing section 296..\n",
      "Analyzing section 288..\n",
      "Analyzing section 322..\n",
      "Analyzing section 327..\n",
      "Analyzing section 335..\n",
      "Analyzing section 304..\n",
      "Analyzing section 314..\n",
      "Analyzing section 336..\n",
      "Analyzing section 323..\n",
      "Analyzing section 344..\n",
      "Analyzing section 328..\n",
      "Analyzing section 297..\n",
      "Analyzing section 345..\n",
      "Analyzing section 315..\n",
      "Analyzing section 337..\n",
      "Analyzing section 324..\n",
      "Analyzing section 346..\n",
      "Analyzing section 329..\n",
      "Analyzing section 305..\n",
      "Analyzing section 289..\n",
      "Analyzing section 338..\n",
      "Analyzing section 347..\n",
      "Analyzing section 325..\n",
      "Analyzing section 298..\n",
      "Analyzing section 316..\n",
      "Analyzing section 330..\n",
      "Analyzing section 339..\n",
      "Analyzing section 348..\n",
      "Analyzing section 331..\n",
      "Analyzing section 306..\n",
      "Analyzing section 353..\n",
      "Analyzing section 349..\n",
      "Analyzing section 340..\n",
      "Analyzing section 354..\n",
      "Analyzing section 350..\n",
      "Analyzing section 332..\n",
      "Regions on section 341 are not sampled because the section is invalid.\n",
      "Analyzing section 342..\n",
      "Analyzing section 307..\n",
      "Analyzing section 355..\n",
      "Analyzing section 351..\n",
      "Analyzing section 343..\n",
      "Analyzing section 362..\n",
      "Analyzing section 356..\n",
      "Analyzing section 352..\n",
      "Analyzing section 333..\n",
      "Analyzing section 363..\n",
      "Analyzing section 357..\n",
      "Analyzing section 364..\n",
      "Analyzing section 358..\n",
      "Analyzing section 334..\n",
      "Analyzing section 359..\n",
      "Analyzing section 360..\n",
      "Analyzing section 361..\n",
      "Sample addresses (stack MD594): 13 seconds.\n",
      "Aggregate addresses: 0.04 seconds\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in divide\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "Map addresses to features: 65.19 seconds\n"
     ]
    }
   ],
   "source": [
    "features, addresses = generate_dataset_cell_based(num_samples_per_label=num_samples_per_label, \n",
    "                                                  stacks=stacks,\n",
    "                                                  labels_to_sample=labels_to_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10N 2\n",
      "10N_surround_500_12N 781\n",
      "10N_surround_500_AP 9\n",
      "10N_surround_500_noclass 966\n",
      "12N 994\n",
      "12N_surround_500_10N 2\n",
      "12N_surround_500_noclass 951\n",
      "3N 657\n",
      "3N_surround_500_4N 1\n",
      "3N_surround_500_noclass 658\n",
      "4N 26\n",
      "4N_surround_500_3N 54\n",
      "4N_surround_500_noclass 404\n",
      "5N 990\n",
      "5N_surround_500_noclass 984\n",
      "6N 69\n",
      "6N_surround_500_7n 11\n",
      "6N_surround_500_noclass 757\n",
      "7N 992\n",
      "7N_surround_500_noclass 930\n",
      "7n 222\n",
      "7n_surround_500_5N 1\n",
      "7n_surround_500_6N 19\n",
      "7n_surround_500_noclass 883\n",
      "AP 253\n",
      "AP_surround_500_12N 2\n",
      "AP_surround_500_noclass 493\n",
      "Amb 173\n",
      "Amb_surround_500_7N 1\n",
      "Amb_surround_500_LRt 45\n",
      "Amb_surround_500_noclass 359\n",
      "DC 986\n",
      "DC_surround_500_VCA 937\n",
      "DC_surround_500_VCP 736\n",
      "DC_surround_500_noclass 779\n",
      "IC 997\n",
      "IC_surround_500_SC 996\n",
      "IC_surround_500_noclass 767\n",
      "LC 701\n",
      "LC_surround_500_noclass 700\n",
      "LRt 999\n",
      "LRt_surround_500_Amb 20\n",
      "LRt_surround_500_noclass 976\n",
      "PBG 487\n",
      "PBG_surround_500_SNR 90\n",
      "PBG_surround_500_noclass 675\n",
      "Pn 989\n",
      "Pn_surround_500_RtTg 992\n",
      "Pn_surround_500_Tz 2\n",
      "Pn_surround_500_noclass 896\n",
      "RMC 993\n",
      "RMC_surround_500_noclass 977\n",
      "RtTg 991\n",
      "RtTg_surround_500_Pn 985\n",
      "RtTg_surround_500_Tz 49\n",
      "RtTg_surround_500_noclass 924\n",
      "SC 1000\n",
      "SC_surround_500_IC 998\n",
      "SC_surround_500_noclass 950\n",
      "SNC 266\n",
      "SNC_surround_500_SNR 927\n",
      "SNC_surround_500_noclass 959\n",
      "SNR 867\n",
      "SNR_surround_500_PBG 5\n",
      "SNR_surround_500_SNC 266\n",
      "SNR_surround_500_noclass 844\n",
      "Sp5C 994\n",
      "Sp5C_surround_500_Sp5I 450\n",
      "Sp5C_surround_500_noclass 979\n",
      "Sp5I 1000\n",
      "Sp5I_surround_500_Sp5C 450\n",
      "Sp5I_surround_500_Sp5O 778\n",
      "Sp5I_surround_500_noclass 946\n",
      "Sp5O 754\n",
      "Sp5O_surround_500_Sp5I 840\n",
      "Sp5O_surround_500_noclass 740\n",
      "Tz 964\n",
      "Tz_surround_500_RtTg 273\n",
      "Tz_surround_500_noclass 949\n",
      "VCA 998\n",
      "VCA_surround_500_DC 867\n",
      "VCA_surround_500_VCP 888\n",
      "VCA_surround_500_noclass 856\n",
      "VCP 998\n",
      "VCP_surround_500_DC 905\n",
      "VCP_surround_500_VCA 935\n",
      "VCP_surround_500_noclass 885\n",
      "VLL 994\n",
      "VLL_surround_500_noclass 879\n"
     ]
    }
   ],
   "source": [
    "for l, v in sorted(addresses.items()):\n",
    "    print l, len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_cells_v2/classifiers/datasets/dataset_98/patch_features.hdf s3://mousebrainatlas-data/CSHL_cells_v2/classifiers/datasets/dataset_98/patch_features.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:1138: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->values] [items->None]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n",
      "Child returned 0\n",
      "0.84 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_cells_v2/classifiers/datasets/dataset_98/patch_addresses.pkl s3://mousebrainatlas-data/CSHL_cells_v2/classifiers/datasets/dataset_98/patch_addresses.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "0.48 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Save training features\n",
    "features_fp = os.path.join(CELL_FEATURES_CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset_id, 'patch_features.hdf')\n",
    "create_parent_dir_if_not_exists(features_fp)\n",
    "save_hdf_v2(features, features_fp)\n",
    "upload_to_s3(features_fp)\n",
    "# train_feat_dir = create_if_not_exists(os.path.join(CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset, 'patch_features'))\n",
    "# for label, feats in training_features.iteritems():\n",
    "#     bp.pack_ndarray_file(feats, os.path.join(train_feat_dir, label + '.bp'))\n",
    "\n",
    "# Save training addresses\n",
    "addresses_fp = os.path.join(CELL_FEATURES_CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset_id, 'patch_addresses.pkl')\n",
    "save_pickle(addresses, addresses_fp)\n",
    "upload_to_s3(addresses_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
