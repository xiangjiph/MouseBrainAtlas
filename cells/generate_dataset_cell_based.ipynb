{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *\n",
    "from cell_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network_model</th>\n",
       "      <th>stain</th>\n",
       "      <th>margins</th>\n",
       "      <th>num_sample_per_class</th>\n",
       "      <th>stacks</th>\n",
       "      <th>cell_features_used</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Inception-BN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>200/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD585</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Inception-BN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>200/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Inception-BN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>200/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "      <td>largeLargeLinkLenHist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "      <td>largeLargeLinkLenHist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "      <td>largeSizeHist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "      <td>largeSizeHist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "      <td>largeSizeHist/largeLargeLinkLenHist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "      <td>largeSizeHist/largeLargeLinkLenHist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD594</td>\n",
       "      <td>largeOrientationHist/largeSizeHist/largeLargeL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>nissl</td>\n",
       "      <td>500</td>\n",
       "      <td>1000</td>\n",
       "      <td>MD589</td>\n",
       "      <td>largeOrientationHist/largeSizeHist/largeLargeL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           network_model  stain  margins  num_sample_per_class stacks  \\\n",
       "dataset_id                                                              \n",
       "20          Inception-BN  nissl  200/500                  1000  MD585   \n",
       "21          Inception-BN  nissl  200/500                  1000  MD589   \n",
       "22          Inception-BN  nissl  200/500                  1000  MD594   \n",
       "92                   NaN  nissl      500                  1000  MD589   \n",
       "93                   NaN  nissl      500                  1000  MD594   \n",
       "94                   NaN  nissl      500                  1000  MD589   \n",
       "95                   NaN  nissl      500                  1000  MD594   \n",
       "96                   NaN  nissl      500                  1000  MD589   \n",
       "97                   NaN  nissl      500                  1000  MD594   \n",
       "98                   NaN  nissl      500                  1000  MD594   \n",
       "99                   NaN  nissl      500                  1000  MD589   \n",
       "\n",
       "                                           cell_features_used  \n",
       "dataset_id                                                     \n",
       "20                                                        NaN  \n",
       "21                                                        NaN  \n",
       "22                                                        NaN  \n",
       "92                                      largeLargeLinkLenHist  \n",
       "93                                      largeLargeLinkLenHist  \n",
       "94                                              largeSizeHist  \n",
       "95                                              largeSizeHist  \n",
       "96                        largeSizeHist/largeLargeLinkLenHist  \n",
       "97                        largeSizeHist/largeLargeLinkLenHist  \n",
       "98          largeOrientationHist/largeSizeHist/largeLargeL...  \n",
       "99          largeOrientationHist/largeSizeHist/largeLargeL...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_id = 93\n",
    "dataset_properties = dataset_settings.loc[dataset_id]\n",
    "\n",
    "num_samples_per_label = dataset_properties['num_sample_per_class']\n",
    "stacks = dataset_properties['stacks'].split('/')\n",
    "\n",
    "cell_features_used = dataset_properties['cell_features_used'].split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structures_to_sample = all_known_structures\n",
    "\n",
    "# negative_labels_to_sample = [s + '_negative' for s in structures_to_sample]\n",
    "\n",
    "margins_to_sample = map(int, str(dataset_properties['margins']).split('/'))\n",
    "\n",
    "surround_positive_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix=surr_l) \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample \n",
    "                             for surr_l in structures_to_sample\n",
    "                             if surr_l != s]\n",
    "\n",
    "surround_noclass_labels_to_sample = [convert_to_surround_name(s, margin=m, suffix='noclass') \n",
    "                             for m in margins_to_sample\n",
    "                             for s in structures_to_sample]\n",
    "\n",
    "labels_to_sample = structures_to_sample + surround_positive_labels_to_sample + surround_noclass_labels_to_sample + ['bg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify region indices by section by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_predefined_regions_one_section_by_label(stack, sec, labels_to_sample, labeled_contours):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        dict {label: list of region indices}\n",
    "    \"\"\"\n",
    "    \n",
    "    if is_invalid(stack=stack, sec=sec):\n",
    "        sys.stderr.write('Regions on section %d are not identified because the section is invalid.\\n' % sec)\n",
    "        return\n",
    "    \n",
    "    region_contours = load_cell_classifier_data(what='region_contours', stack=stack, sec=sec, ext='bp')\n",
    "    \n",
    "    surround_margins = set([get_margin_from_surround_label(label) for label in labels_to_sample if is_surround_label(label)])\n",
    "    region_labels = label_regions(stack=stack, section=sec, \n",
    "                                  region_contours=region_contours,\n",
    "                                  surround_margins=surround_margins,\n",
    "                                  labeled_contours=labeled_contours)\n",
    "    region_labels = {label: region_indices for label, region_indices in region_labels.iteritems()\n",
    "                     if len(region_indices) > 0}\n",
    "    return region_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'No object named structures in the file'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotation has no structures.\n",
      "Analyzing section 110..\n",
      "Analyzing section 92..\n",
      "Analyzing section 128..\n",
      "Analyzing section 101..\n",
      "Analyzing section 137..\n",
      "Analyzing section 119..\n",
      "Analyzing section 155..\n",
      "Analyzing section 146..\n",
      "Analyzing section 93..\n",
      "Analyzing section 94..\n",
      "Analyzing section 95..\n",
      "Analyzing section 102..\n",
      "Analyzing section 103..\n",
      "Analyzing section 111..\n",
      "Analyzing section 96..\n",
      "Analyzing section 120..\n",
      "Analyzing section 112..\n",
      "Analyzing section 97..\n",
      "Analyzing section 129..\n",
      "Analyzing section 104..\n",
      "Analyzing section 147..\n",
      "Analyzing section 98..\n",
      "Analyzing section 138..\n",
      "Analyzing section 121..\n",
      "Analyzing section 99..\n",
      "Analyzing section 130..\n",
      "Analyzing section 113..\n",
      "Analyzing section 105..\n",
      "Analyzing section 156..\n",
      "Analyzing section 100..\n",
      "Analyzing section 122..\n",
      "Analyzing section 106..\n",
      "Analyzing section 164..\n",
      "Analyzing section 114..\n",
      "Analyzing section 148..\n",
      "Analyzing section 139..\n",
      "Analyzing section 131..\n",
      "Analyzing section 107..\n",
      "Analyzing section 123..\n",
      "Analyzing section 115..\n",
      "Analyzing section 108..\n",
      "Analyzing section 124..\n",
      "Analyzing section 132..\n",
      "Analyzing section 149..\n",
      "Analyzing section 109..\n",
      "Analyzing section 157..\n",
      "Analyzing section 116..\n",
      "Analyzing section 125..\n",
      "Analyzing section 140..\n",
      "Analyzing section 173..\n",
      "Analyzing section 117..\n",
      "Analyzing section 165..\n",
      "Analyzing section 133..\n",
      "Analyzing section 126..\n",
      "Regions on section 118 are not identified because the section is invalid.\n",
      "Analyzing section 182..\n",
      "Analyzing section 150..\n",
      "Analyzing section 141..\n",
      "Analyzing section 127..\n",
      "Analyzing section 134..\n",
      "Analyzing section 174..\n",
      "Analyzing section 191..\n",
      "Analyzing section 158..\n",
      "Analyzing section 166..\n",
      "Analyzing section 142..\n",
      "Analyzing section 151..\n",
      "Analyzing section 183..\n",
      "Analyzing section 175..\n",
      "Analyzing section 135..\n",
      "Analyzing section 192..\n",
      "Analyzing section 143..\n",
      "Analyzing section 136..\n",
      "Analyzing section 159..\n",
      "Analyzing section 152..\n",
      "Analyzing section 184..\n",
      "Analyzing section 176..\n",
      "Analyzing section 167..\n",
      "Analyzing section 193..\n",
      "Analyzing section 200..\n",
      "Analyzing section 144..\n",
      "Analyzing section 153..\n",
      "Analyzing section 194..\n",
      "Analyzing section 160..\n",
      "Analyzing section 185..\n",
      "Analyzing section 177..\n",
      "Analyzing section 145..\n",
      "Analyzing section 168..\n",
      "Analyzing section 201..\n",
      "Analyzing section 195..\n",
      "Analyzing section 154..\n",
      "Analyzing section 186..\n",
      "Analyzing section 178..\n",
      "Analyzing section 202..\n",
      "Analyzing section 161..\n",
      "Analyzing section 209..\n",
      "Analyzing section 196..\n",
      "Analyzing section 169..\n",
      "Analyzing section 203..\n",
      "Analyzing section 187..\n",
      "Analyzing section 197..\n",
      "Analyzing section 218..\n",
      "Analyzing section 179..\n",
      "Analyzing section 210..\n",
      "Analyzing section 162..\n",
      "Analyzing section 204..\n",
      "Analyzing section 188..\n",
      "Analyzing section 198..\n",
      "Analyzing section 170..\n",
      "Analyzing section 180..\n",
      "Analyzing section 219..\n",
      "Analyzing section 211..\n",
      "Analyzing section 205..\n",
      "Analyzing section 163..\n",
      "Analyzing section 199..\n",
      "Analyzing section 189..\n",
      "Analyzing section 220..\n",
      "Analyzing section 181..\n",
      "Analyzing section 171..\n",
      "Analyzing section 227..\n",
      "Analyzing section 206..\n",
      "Analyzing section 212..\n",
      "Analyzing section 190..\n",
      "Analyzing section 236..\n",
      "Analyzing section 172..\n",
      "Regions on section 221 are not identified because the section is invalid.\n",
      "Analyzing section 222..\n",
      "Analyzing section 245..\n",
      "Analyzing section 228..\n",
      "Analyzing section 207..\n",
      "Analyzing section 213..\n",
      "Analyzing section 237..\n",
      "Analyzing section 254..\n",
      "Analyzing section 263..\n",
      "Analyzing section 229..\n",
      "Analyzing section 223..\n",
      "Analyzing section 238..\n",
      "Analyzing section 246..\n",
      "Analyzing section 208..\n",
      "Analyzing section 214..\n",
      "Analyzing section 255..\n",
      "Analyzing section 230..\n",
      "Analyzing section 264..\n",
      "Analyzing section 247..\n",
      "Analyzing section 239..\n",
      "Analyzing section 224..\n",
      "Analyzing section 272..\n",
      "Analyzing section 256..\n",
      "Analyzing section 248..\n",
      "Analyzing section 231..\n",
      "Analyzing section 215..\n",
      "Analyzing section 240..\n",
      "Analyzing section 265..\n",
      "Analyzing section 225..\n",
      "Analyzing section 249..\n",
      "Analyzing section 273..\n",
      "Analyzing section 257..\n",
      "Analyzing section 232..\n",
      "Analyzing section 241..\n",
      "Analyzing section 226..\n",
      "Analyzing section 250..\n",
      "Analyzing section 266..\n",
      "Analyzing section 216..\n",
      "Analyzing section 233..\n",
      "Analyzing section 242..\n",
      "Analyzing section 258..\n",
      "Analyzing section 274..\n",
      "Analyzing section 281..\n",
      "Analyzing section 243..\n",
      "Analyzing section 234..\n",
      "Analyzing section 251..\n",
      "Analyzing section 267..\n",
      "Analyzing section 259..\n",
      "Analyzing section 217..\n",
      "Analyzing section 275..\n",
      "Analyzing section 244..\n",
      "Analyzing section 235..\n",
      "Analyzing section 268..\n",
      "Analyzing section 260..\n",
      "Analyzing section 282..\n",
      "Analyzing section 252..\n",
      "Analyzing section 290..\n",
      "Analyzing section 299..\n",
      "Analyzing section 308..\n",
      "Analyzing section 269..\n",
      "Analyzing section 261..\n",
      "Analyzing section 253..\n",
      "Analyzing section 276..\n",
      "Analyzing section 283..\n",
      "Analyzing section 309..\n",
      "Analyzing section 262..\n",
      "Regions on section 300 are not identified because the section is invalid.\n",
      "Analyzing section 301..\n",
      "Analyzing section 291..\n",
      "Analyzing section 317..\n",
      "Analyzing section 270..\n",
      "Analyzing section 277..\n",
      "Analyzing section 284..\n",
      "Analyzing section 310..\n",
      "Analyzing section 326..\n",
      "Analyzing section 318..\n",
      "Analyzing section 302..\n",
      "Analyzing section 292..\n",
      "Analyzing section 327..\n",
      "Analyzing section 271..\n",
      "Analyzing section 319..\n",
      "Analyzing section 278..\n",
      "Analyzing section 328..\n",
      "Analyzing section 311..\n",
      "Analyzing section 285..\n",
      "Analyzing section 329..\n",
      "Analyzing section 320..\n",
      "Analyzing section 303..\n",
      "Analyzing section 330..\n",
      "Analyzing section 293..\n",
      "Analyzing section 335..\n",
      "Analyzing section 312..\n",
      "Analyzing section 279..\n",
      "Analyzing section 331..\n",
      "Analyzing section 321..\n",
      "Analyzing section 332..\n",
      "Analyzing section 336..\n",
      "Analyzing section 286..\n",
      "Analyzing section 313..\n",
      "Analyzing section 304..\n",
      "Analyzing section 333..\n",
      "Analyzing section 322..\n",
      "Analyzing section 294..\n",
      "Analyzing section 280..\n",
      "Analyzing section 337..\n",
      "Analyzing section 314..\n",
      "Analyzing section 334..\n",
      "Analyzing section 338..\n",
      "Analyzing section 287..\n",
      "Analyzing section 323..\n",
      "Analyzing section 344..\n",
      "Analyzing section 305..\n",
      "Analyzing section 339..\n",
      "Analyzing section 315..\n",
      "Analyzing section 353..\n",
      "Analyzing section 345..\n",
      "Regions on section 324 are not identified because the section is invalid.\n",
      "Analyzing section 325..\n",
      "Analyzing section 340..\n",
      "Analyzing section 354..\n",
      "Analyzing section 346..\n",
      "Analyzing section 295..\n",
      "Analyzing section 355..\n",
      "Analyzing section 347..\n",
      "Analyzing section 316..\n",
      "Analyzing section 362..\n",
      "Analyzing section 341..\n",
      "Analyzing section 356..\n",
      "Analyzing section 306..\n",
      "Analyzing section 363..\n",
      "Analyzing section 288..\n",
      "Analyzing section 348..\n",
      "Analyzing section 364..\n",
      "Analyzing section 357..\n",
      "Analyzing section 365..\n",
      "Analyzing section 342..\n",
      "Analyzing section 358..\n",
      "Analyzing section 366..\n",
      "Analyzing section 349..\n",
      "Analyzing section 367..\n",
      "Analyzing section 359..\n",
      "Analyzing section 368..\n",
      "Analyzing section 343..\n",
      "Analyzing section 350..\n",
      "Analyzing section 369..\n",
      "Analyzing section 360..\n",
      "Analyzing section 296..\n",
      "Analyzing section 370..\n",
      "Analyzing section 307..\n",
      "Analyzing section 361..\n",
      "Analyzing section 351..\n",
      "Analyzing section 289..\n",
      "Analyzing section 352..\n",
      "Analyzing section 297..\n",
      "Analyzing section 298..\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_annotated_nissl_stacks:\n",
    "# # for stack in ['MD589']:\n",
    "    \n",
    "#     contours_df, _ = DataManager.load_annotation_v3(stack=stack)\n",
    "#     labeled_contours = contours_df[(contours_df['orientation'] == 'sagittal') & (contours_df['downsample'] == 1)].drop_duplicates(subset=['section', 'name', 'side', 'filename', 'downsample', 'creator'])\n",
    "#     labeled_contours = convert_annotation_v3_original_to_aligned_cropped(labeled_contours, stack=stack)\n",
    "\n",
    "#     first_sec, last_sec = metadata_cache['section_limits'][stack]\n",
    "    \n",
    "#     pool = Pool(NUM_CORES/2)\n",
    "#     addresses_by_section_by_label = \\\n",
    "#     pool.map(lambda sec: identify_predefined_regions_one_section_by_label(stack=stack, sec=sec, \n",
    "#                                                              labels_to_sample=labels_to_sample,\n",
    "#                                                              labeled_contours=labeled_contours[labeled_contours['section']==sec]),\n",
    "#              range(first_sec, last_sec+1))\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "    \n",
    "#     for sec, region_indices_by_label in zip(range(first_sec, last_sec+1), addresses_by_section_by_label):\n",
    "#         if region_indices_by_label is not None:\n",
    "#             save_hdf_v2(region_indices_by_label, DataManager.get_region_labels_filepath(stack=stack, sec=sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_predefined_regions_one_section_by_label(stack, sec, labels_to_sample, labeled_contours, num_samples_per_label=None):\n",
    "    \"\"\"\n",
    "    Sample region addresses in a particular section and associate them with different labels (positive, surround, negative, noclass, foreground, background, etc.).\n",
    "    \n",
    "    Args:\n",
    "        region_contours (list of nx2 arrays): list of contour vertices.\n",
    "        labeled_contours (dict of nx2 arrays): {label: contour vertices}\n",
    "        \n",
    "    Returns:\n",
    "        dict of 3-tuple list: {label: list of (stack, section, region_index)}.\n",
    "        If section is invalid, return None.\n",
    "    \"\"\"\n",
    "\n",
    "    addresses = {}\n",
    "    \n",
    "    if is_invalid(stack=stack, sec=sec):\n",
    "        sys.stderr.write('Regions on section %d are not sampled because the section is invalid.\\n' % sec)\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        region_labels = load_hdf_v2(DataManager.get_region_labels_filepath(stack=stack, sec=sec))\n",
    "        region_labels = {label: region_indices for label, region_indices in region_labels.iteritems()\n",
    "                        if label in labels_to_sample}\n",
    "    except Exception as e:\n",
    "        sys.stderr.write('%s\\n' % e)\n",
    "        sys.stderr.write('Cannot load pre-computed region labels for section %d... re-compute\\n' % sec)\n",
    "        region_labels = identify_predefined_regions_one_section_by_label(stack, sec, labels_to_sample, labeled_contours)\n",
    "\n",
    "    for label, region_indices in region_labels.iteritems():\n",
    "        if num_samples_per_label is None:\n",
    "            addresses[label] = [(stack, sec, ridx) for ridx in region_indices]\n",
    "        else:\n",
    "            sampled_region_indices = np.random.choice(region_indices, min(num_samples_per_label, len(region_indices)), replace=False)\n",
    "            addresses[label] = [(stack, sec, ridx) for ridx in sampled_region_indices]\n",
    "\n",
    "    return addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_cell_based_features_one_section_(stack, section, region_indices, cell_features_used):\n",
    "    \"\"\"\n",
    "    Load pre-computed cell-based features for a list of regions on a particular section.\n",
    "    \"\"\"\n",
    "    \n",
    "    region_features_all_regions = load_cell_classifier_data(what='region_features', stack=stack, sec=section, ext='hdf')\n",
    "    # Loading hdf ~ 2 seconds.\n",
    "    \n",
    "    all_features_normalized = []\n",
    "    for feature_name in cell_features_used:\n",
    "        feats = np.asarray([region_features_all_regions[region_ind][feature_name] for region_ind in region_indices])\n",
    "        feats_normalized = feats/feats.sum(axis=1)[:,None].astype(np.float)\n",
    "        all_features_normalized.append(feats_normalized)\n",
    "    \n",
    "    features = np.hstack(all_features_normalized)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_cell_based(num_samples_per_label, stacks, labels_to_sample, cell_features_used):\n",
    "    \"\"\"\n",
    "    Generate dataset.\n",
    "    - Extract addresses\n",
    "    - Map addresses to features\n",
    "    - Remove None features\n",
    "    \n",
    "    Returns:\n",
    "        features, addresseslab\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample addresses\n",
    "    \n",
    "    addresses = defaultdict(list)\n",
    "    addresses_by_section_by_label = []\n",
    "    \n",
    "#     t = time.time()\n",
    "    \n",
    "    for stack in stacks:\n",
    "        \n",
    "        first_sec, last_sec = metadata_cache['section_limits'][stack]\n",
    "    \n",
    "        t1 = time.time()\n",
    "\n",
    "        contours_df, _ = DataManager.load_annotation_v3(stack=stack)\n",
    "        labeled_contours = contours_df[(contours_df['orientation'] == 'sagittal') & (contours_df['downsample'] == 1)].drop_duplicates(subset=['section', 'name', 'side', 'filename', 'downsample', 'creator'])\n",
    "        labeled_contours = convert_annotation_v3_original_to_aligned_cropped(labeled_contours, stack=stack)\n",
    "\n",
    "        sys.stderr.write('Load annotation. Time: %.2f seconds.\\n' % (time.time() - t1))\n",
    "\n",
    "        t1 = time.time()\n",
    "        \n",
    "        # Sample addresses from each section\n",
    "\n",
    "        # If region labels are already computed, sequential loading is much faster (3s) than parallel loading (50s) due to disk read contention.\n",
    "        addresses_by_section_by_label_curr_stack = [\n",
    "            sample_predefined_regions_one_section_by_label(stack=stack, sec=sec, \n",
    "                                                                 labels_to_sample=labels_to_sample,\n",
    "                                                                 labeled_contours=labeled_contours[labeled_contours['section']==sec],\n",
    "                                                                 num_samples_per_label=30)\n",
    "            for sec in range(first_sec, last_sec+1)]\n",
    "\n",
    "#         pool = Pool(NUM_CORES/2)\n",
    "#         addresses_by_section_by_label_curr_stack = \\\n",
    "#         pool.map(lambda sec: sample_predefined_regions_one_section_by_label(stack=stack, sec=sec, \n",
    "#                                                                  labels_to_sample=labels_to_sample,\n",
    "#                                                                  labeled_contours=labeled_contours[labeled_contours['section']==sec],\n",
    "#                                                                  num_samples_per_label=30),\n",
    "#                  range(first_sec, last_sec+1))\n",
    "#         pool.close()\n",
    "#         pool.join()\n",
    "                \n",
    "        addresses_by_section_by_label += addresses_by_section_by_label_curr_stack\n",
    "\n",
    "        sys.stderr.write('Sample addresses (stack %s): %.2s seconds.\\n' % (stack, time.time() - t1))\n",
    "        \n",
    "    # Aggregate addresses sampled form each section\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    addresses_by_label = defaultdict(list)\n",
    "    for addrs_by_label in addresses_by_section_by_label:\n",
    "        if addrs_by_label is not None: # handle cases of invalid sections for which sampling function returns None\n",
    "            for label, addrs in addrs_by_label.iteritems():\n",
    "                addresses_by_label[label] += addrs\n",
    "    addresses_by_label.default_factory = None\n",
    "    \n",
    "    if num_samples_per_label is not None:\n",
    "        import random\n",
    "        addresses_by_label = {label: random.sample(addrs, min(num_samples_per_label/len(stacks), len(addrs))) \n",
    "                              for label, addrs in addresses_by_label.iteritems()}\n",
    "\n",
    "    # Remove unwanted labels\n",
    "    addresses_by_label = {label: addrs for label, addrs in addresses_by_label.iteritems() if label in labels_to_sample}\n",
    "    \n",
    "    sys.stderr.write('Aggregate addresses: %.2f seconds\\n' % (time.time() - t))    \n",
    "    \n",
    "    # Map addresses to features\n",
    "    \n",
    "    t = time.time()\n",
    "    \n",
    "    load_cell_based_features_given_address_list = lambda addrs: smart_map(addrs, keyfunc=lambda (st, se, ri): (st, se),\\\n",
    "                        func=lambda (st, se), gr: \\\n",
    "                        load_cell_based_features_one_section_(stack=st, section=se, \n",
    "                                                              region_indices=[ri for _,_,ri in gr], cell_features_used=cell_features_used))\n",
    "    features_by_label = apply_function_to_dict(load_cell_based_features_given_address_list, addresses_by_label)\n",
    "    features_by_label = apply_function_to_dict(np.asarray, features_by_label)\n",
    "    \n",
    "    sys.stderr.write('Map addresses to features: %.2f seconds\\n' % (time.time() - t))\n",
    "    \n",
    "    # Remove features that are None are contain nan values.\n",
    "\n",
    "    for name in features_by_label.keys():\n",
    "        valid = [(ftr, addr) for ftr, addr in zip(features_by_label[name], addresses_by_label[name])\n",
    "                    if ftr is not None and not np.any(np.isnan(ftr))]\n",
    "        res = zip(*valid)\n",
    "        features_by_label[name] = np.array(res[0])\n",
    "        addresses_by_label[name] = res[1]\n",
    "    \n",
    "    return features_by_label, addresses_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'No object named structures in the file'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotation has no structures.\n",
      "Load annotation. Time: 1.32 seconds.\n",
      "Regions on section 131 are not sampled because the section is invalid.\n",
      "Regions on section 187 are not sampled because the section is invalid.\n",
      "Regions on section 193 are not sampled because the section is invalid.\n",
      "Regions on section 238 are not sampled because the section is invalid.\n",
      "Regions on section 261 are not sampled because the section is invalid.\n",
      "Regions on section 341 are not sampled because the section is invalid.\n",
      "Sample addresses (stack MD594): 1. seconds.\n",
      "Aggregate addresses: 0.03 seconds\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: RuntimeWarning: invalid value encountered in divide\n",
      "  if sys.path[0] == '':\n",
      "Map addresses to features: 42.06 seconds\n"
     ]
    }
   ],
   "source": [
    "features, addresses = generate_dataset_cell_based(num_samples_per_label=num_samples_per_label, \n",
    "                                                  stacks=stacks,\n",
    "                                                  labels_to_sample=labels_to_sample,\n",
    "                                                 cell_features_used=cell_features_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10N 2\n",
      "10N_surround_500_12N 785\n",
      "10N_surround_500_AP 9\n",
      "10N_surround_500_noclass 974\n",
      "12N 998\n",
      "12N_surround_500_10N 2\n",
      "12N_surround_500_noclass 960\n",
      "3N 657\n",
      "3N_surround_500_4N 1\n",
      "3N_surround_500_noclass 664\n",
      "4N 26\n",
      "4N_surround_500_3N 54\n",
      "4N_surround_500_noclass 411\n",
      "5N 991\n",
      "5N_surround_500_noclass 974\n",
      "6N 69\n",
      "6N_surround_500_7n 11\n",
      "6N_surround_500_noclass 774\n",
      "7N 977\n",
      "7N_surround_500_noclass 950\n",
      "7n 197\n",
      "7n_surround_500_5N 1\n",
      "7n_surround_500_6N 19\n",
      "7n_surround_500_noclass 876\n",
      "AP 266\n",
      "AP_surround_500_12N 2\n",
      "AP_surround_500_noclass 515\n",
      "Amb 173\n",
      "Amb_surround_500_7N 1\n",
      "Amb_surround_500_LRt 45\n",
      "Amb_surround_500_noclass 359\n",
      "DC 987\n",
      "DC_surround_500_VCA 938\n",
      "DC_surround_500_VCP 736\n",
      "DC_surround_500_noclass 836\n",
      "IC 995\n",
      "IC_surround_500_SC 997\n",
      "IC_surround_500_noclass 776\n",
      "LC 701\n",
      "LC_surround_500_noclass 706\n",
      "LRt 998\n",
      "LRt_surround_500_Amb 20\n",
      "LRt_surround_500_noclass 985\n",
      "PBG 488\n",
      "PBG_surround_500_SNR 90\n",
      "PBG_surround_500_noclass 673\n",
      "Pn 988\n",
      "Pn_surround_500_RtTg 994\n",
      "Pn_surround_500_Tz 2\n",
      "Pn_surround_500_noclass 891\n",
      "RMC 990\n",
      "RMC_surround_500_noclass 979\n",
      "RtTg 998\n",
      "RtTg_surround_500_Pn 984\n",
      "RtTg_surround_500_Tz 49\n",
      "RtTg_surround_500_noclass 926\n",
      "SC 999\n",
      "SC_surround_500_IC 997\n",
      "SC_surround_500_noclass 953\n",
      "SNC 266\n",
      "SNC_surround_500_SNR 925\n",
      "SNC_surround_500_noclass 950\n",
      "SNR 872\n",
      "SNR_surround_500_PBG 5\n",
      "SNR_surround_500_SNC 266\n",
      "SNR_surround_500_noclass 835\n",
      "Sp5C 995\n",
      "Sp5C_surround_500_Sp5I 450\n",
      "Sp5C_surround_500_noclass 978\n",
      "Sp5I 1000\n",
      "Sp5I_surround_500_Sp5C 450\n",
      "Sp5I_surround_500_Sp5O 778\n",
      "Sp5I_surround_500_noclass 950\n",
      "Sp5O 751\n",
      "Sp5O_surround_500_Sp5I 840\n",
      "Sp5O_surround_500_noclass 740\n",
      "Tz 977\n",
      "Tz_surround_500_RtTg 273\n",
      "Tz_surround_500_noclass 953\n",
      "VCA 1000\n",
      "VCA_surround_500_DC 867\n",
      "VCA_surround_500_VCP 886\n",
      "VCA_surround_500_noclass 888\n",
      "VCP 997\n",
      "VCP_surround_500_DC 905\n",
      "VCP_surround_500_VCA 941\n",
      "VCP_surround_500_noclass 902\n",
      "VLL 995\n",
      "VLL_surround_500_noclass 853\n",
      "bg 537\n"
     ]
    }
   ],
   "source": [
    "for l, v in sorted(addresses.items()):\n",
    "    print l, len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_cells_v2/classifiers/datasets/dataset_93/patch_features.hdf s3://mousebrainatlas-data/CSHL_cells_v2/classifiers/datasets/dataset_93/patch_features.hdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "0.52 seconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp /shared/CSHL_cells_v2/classifiers/datasets/dataset_93/patch_addresses.pkl s3://mousebrainatlas-data/CSHL_cells_v2/classifiers/datasets/dataset_93/patch_addresses.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "0.52 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Save features\n",
    "features_fp = os.path.join(CELL_FEATURES_CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset_id, 'patch_features.hdf')\n",
    "create_parent_dir_if_not_exists(features_fp)\n",
    "save_hdf_v2(features, features_fp)\n",
    "upload_to_s3(features_fp)\n",
    "# train_feat_dir = create_if_not_exists(os.path.join(CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset, 'patch_features'))\n",
    "# for label, feats in training_features.iteritems():\n",
    "#     bp.pack_ndarray_file(feats, os.path.join(train_feat_dir, label + '.bp'))\n",
    "\n",
    "# Save addresses\n",
    "addresses_fp = os.path.join(CELL_FEATURES_CLF_ROOTDIR, 'datasets', 'dataset_%d' % dataset_id, 'patch_addresses.pkl')\n",
    "save_pickle(addresses, addresses_fp)\n",
    "upload_to_s3(addresses_fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
