{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "Cannot load cv2.\n",
      "No vtk\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_anchor.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed/MD653/MD653_sorted_filenames.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_cropbox.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD653/MD653_cropbox.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_anchor.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed/MD652/MD652_sorted_filenames.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_cropbox.txt\n",
      "File does not exist: /media/yuncong/BstemAtlasData/CSHL_data_processed//MD652/MD652_cropbox.txt\n",
      "Cannot load cv2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Precision WorkStation\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from learning_utilities import *\n",
    "from distributed_utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_ROOTDIR = '/home/yuncong/mxnet_models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/mxnet/model.py:880: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n",
      "  **kwargs)\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:40: DeprecationWarning: \u001b[91mmxnet.model.FeedForward has been deprecated. Please use mxnet.mod.Module instead.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Does not work for the mxnet version on 3/30/2017\n",
    "# model_dir_name = 'Sat16ClassFinetuned'\n",
    "# model_name = 'Sat16ClassFinetuned'\n",
    "# model_iteration = 10\n",
    "# output_symbol_name = 'flatten_output'\n",
    "# mean_img = np.load(os.path.join(MODEL_ROOTDIR, model_dir_name, 'saturation_mean_224.npy'))\n",
    "\n",
    "# model_dir_name = 'vgg16-blue'\n",
    "# model_name = 'vgg16-blue'\n",
    "# model_iteration = 0\n",
    "# output_symbol_name = 'fc7_output'\n",
    "# output_dim = 4096\n",
    "# mean_img = np.load(os.path.join(MODEL_ROOTDIR, model_dir_name, 'vgg_mean.npy'))\n",
    "\n",
    "# model_dir_name = 'vgg19'\n",
    "# model_name = 'vgg19'\n",
    "# model_iteration = 0\n",
    "# output_symbol_name = 'fc8_output'\n",
    "\n",
    "# model_dir_name = 'inception-bn'\n",
    "# model_name = 'Inception-BN'\n",
    "# model_iteration = 126\n",
    "# output_symbol_name = 'flatten_output'\n",
    "# mean_img = mx.nd.load(os.path.join(MODEL_ROOTDIR, model_dir_name, 'mean_224.nd'))['mean_img'].asnumpy()\n",
    "\n",
    "model_dir_name = 'inception-bn-blue'\n",
    "model_name = 'inception-bn-blue'\n",
    "model_iteration = 0\n",
    "output_symbol_name = 'flatten_output'\n",
    "output_dim = 1024\n",
    "mean_img = np.load(os.path.join(MODEL_ROOTDIR, model_dir_name, 'mean_224.npy'))\n",
    "\n",
    "\n",
    "model0 = mx.model.FeedForward.load(os.path.join(MODEL_ROOTDIR, model_dir_name, model_name), model_iteration, ctx=mx.gpu())\n",
    "flatten_output = model0.symbol.get_internals()[output_symbol_name]\n",
    "model = mx.model.FeedForward(ctx=mx.gpu(), \n",
    "                           symbol=flatten_output, \n",
    "                           arg_params = model0.arg_params, \n",
    "                           aux_params = model0.aux_params,\n",
    "                           allow_extra_params = True)\n",
    "\n",
    "# model_dir_name = 'inception-bn-sat'\n",
    "# model_name = 'inception-bn-sat'\n",
    "# model_iteration = 0\n",
    "# mean_img = np.load(os.path.join(MODEL_ROOTDIR, model_dir_name, 'mean_224.npy'))\n",
    "\n",
    "# model = mx.model.FeedForward.load(os.path.join(MODEL_ROOTDIR, model_dir_name, model_name), model_iteration, ctx=mx.gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize network topology\n",
    "\n",
    "# a = mx.viz.plot_network(flatten_output, shape={\"data\":(1, 1, 224, 224)}, node_attrs={\"shape\":'rect',\"fixedsize\":'false'})\n",
    "# a.render(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_size = 224\n",
    "half_size = patch_size/2\n",
    "stride = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def convert_to_saturation(img, rescale=True):\n",
    "#     \"\"\"\n",
    "#     Generate saturation channel as a grayscale image.\n",
    "#     \"\"\"\n",
    "#     ma = img.max(axis=-1)\n",
    "#     mi = img.min(axis=-1)\n",
    "# #     sys.stderr.write('compute min and max color components: %.2f seconds\\n' % (time.time() - t1)) # ~5s\n",
    "\n",
    "# #     t1 = time.time()\n",
    "#     s = np.nan_to_num(mi/ma.astype(np.float))\n",
    "# #     sys.stderr.write('min oiver max: %.2f seconds\\n' % (time.time() - t1)) # ~2s\n",
    "\n",
    "# #     t1 = time.time()\n",
    "#     if rescale:\n",
    "#         pmax = s.max()\n",
    "#         pmin = s.min()\n",
    "#         s = (s - pmin) / (pmax - pmin)\n",
    "# #     sys.stderr.write('rescale: %.2f seconds\\n' % (time.time() - t1)) # ~3s\n",
    "\n",
    "#     return img_as_ubyte(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Section 151.\n",
      "97856 samples.\n",
      "load image: 2.25 seconds\n",
      "extract patches: 10.27 seconds\n",
      "predict: 258.06 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD658\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'Filters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bd8d866e8e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m                                                           section=sec)\n\u001b[0;32m    133\u001b[0m         \u001b[0mcreate_parent_dir_if_not_exists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m         \u001b[0msave_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_fp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# bloscpack produces files of similar size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0mupload_to_s3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_fp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yuncong/Brain/utilities/utilities2015.pyc\u001b[0m in \u001b[0;36msave_hdf\u001b[1;34m(data, fn, complevel, key)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msave_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m     \u001b[0mfilters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFilters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomplevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomplib\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'blosc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_carray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAtom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: global name 'Filters' is not defined"
     ]
    }
   ],
   "source": [
    "# for stack in all_stacks:\n",
    "for stack in ['MD658']:\n",
    "    \n",
    "#     if stack in ['MD585', 'MD589', 'MD594', 'MD657']:\n",
    "#         continue\n",
    "\n",
    "#     image_dir = DataManager.get_image_dir(stack, resol='lossless', version='cropped')\n",
    "#     download_from_s3(image_dir, is_dir=True)\n",
    "    # download takes 3000 sec.\n",
    "\n",
    "    print stack\n",
    "\n",
    "    section_to_filename = metadata_cache['sections_to_filenames'][stack]\n",
    "\n",
    "    image_width, image_height = metadata_cache['image_shape'][stack]\n",
    "    grid_spec = (patch_size, stride, image_width, image_height)\n",
    "\n",
    "    sample_locations = grid_parameters_to_sample_locations(grid_spec=grid_spec)\n",
    "\n",
    "    first_detect_sec, last_detect_sec = metadata_cache['section_limits'][stack]\n",
    "\n",
    "    bar = show_progress_bar(first_detect_sec, last_detect_sec)\n",
    "# \n",
    "    for sec in range(153, 154):\n",
    "#     for sec in range(first_detect_sec, last_detect_sec+1):\n",
    "#     for sec in range(143, last_detect_sec+1):\n",
    "        \n",
    "        if is_invalid(stack=stack, sec=sec):\n",
    "            continue\n",
    "            \n",
    "#         if section_to_filename[sec].split('-')[1][0] == 'F':\n",
    "#             continue\n",
    "        if section_to_filename[sec].split('-')[1][0] == 'N':\n",
    "            continue\n",
    "                \n",
    "        bar.value = sec\n",
    "        \n",
    "        sys.stderr.write('\\nSection %d.\\n' % sec)\n",
    "\n",
    "        # Use grids only on mask.\n",
    "#         t = time.time()\n",
    "#         mask_tb = DataManager.load_thumbnail_mask_v2(stack=stack, section=sec)\n",
    "#         indices_roi = locate_patches_v2(grid_spec=grid_spec, mask_tb=mask_tb)\n",
    "#         sys.stderr.write('locate patches: %.2f seconds\\n' % (time.time() - t))       \n",
    "        \n",
    "        # Use grids on the entire frame.\n",
    "        indices_roi = range(len(sample_locations))\n",
    "\n",
    "        n = len(indices_roi)\n",
    "        sys.stderr.write('%d samples.\\n' % n)\n",
    "\n",
    "        sample_locations_roi = sample_locations[indices_roi]\n",
    "        \n",
    "        t = time.time()\n",
    "        img_fp = DataManager.get_image_filepath(stack=stack, section=sec, version='cropped_8bit_blueasgray', resol='lossless')\n",
    "        download_from_s3(img_fp)\n",
    "        im = img_as_ubyte(imread(img_fp))\n",
    "        sys.stderr.write('load image: %.2f seconds\\n' % (time.time() - t)) # ~ 35s\n",
    "        \n",
    "#         t = time.time()\n",
    "#         sat = convert_to_saturation(im)\n",
    "#         del im\n",
    "#         sys.stderr.write('Convert to saturation: %.2f seconds\\n' % (time.time() - t)) # ~ 35s\n",
    "#         sat = imread(DataManager.get_image_filepath(stack=stack, section=sec, version='saturation'))\n",
    "        \n",
    "\n",
    "        t = time.time()\n",
    "\n",
    "        patches = np.array([im[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "                            for x, y in sample_locations_roi]) # n x 224 x 224\n",
    "        patches_mean_subtracted = patches - mean_img\n",
    "        patches_mean_subtracted_input = patches_mean_subtracted[:, None, :, :] # n x 1 x 224 x 224\n",
    "\n",
    "#         patches = np.array([im[y-half_size:y+half_size, x-half_size:x+half_size]\n",
    "#                             for x, y in sample_locations_roi]) # n x 224 x 224 x 1\n",
    "#         patches_mean_subtracted_input = np.rollaxis(patches, 3, 1) - mean_img # n x 3 x 224 x 224\n",
    "\n",
    "        sys.stderr.write('extract patches: %.2f seconds\\n' % (time.time() - t)) # ~ 20s / 140k patches\n",
    "\n",
    "        # Increase batch_size to 500 does not save any time.\n",
    "        batch_size = 256 \n",
    "#         batch_size = 16\n",
    "\n",
    "        # For mxnet 0.9.4, using 80000 patches in a NDArrayIter works but using 90000 patches causes error:\n",
    "        # TypeError: Invalid type '<type 'numpy.ndarray'>' for data, should be NDArray or numpy.ndarray\n",
    "\n",
    "        t1 = time.time()\n",
    "        features = np.empty((n, output_dim))\n",
    "        \n",
    "#         n_each_iter = 20000\n",
    "        n_each_iter = 80000\n",
    "        for b in range(0, n, n_each_iter):\n",
    "            data_iter = mx.io.NDArrayIter(\n",
    "                patches_mean_subtracted_input[b:b+n_each_iter], \n",
    "                np.zeros((n_each_iter, ), np.int), # labels are not important since it is just feed-forward\n",
    "                batch_size = batch_size,\n",
    "                shuffle=False)\n",
    "\n",
    "#             if b == 0:\n",
    "#                 features = model.predict(data_iter)\n",
    "#             else:\n",
    "#                 features = np.vstack([features, model.predict(data_iter)])\n",
    "            features[b:b+n_each_iter] = model.predict(data_iter)\n",
    "        sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t1)) # 220s-250s\n",
    "        \n",
    "#         data_iter = mx.io.NDArrayIter(\n",
    "#             patches_mean_subtracted_input, \n",
    "#             np.zeros((n, ), np.int), # labels are not important since it is just feed-forward\n",
    "#             batch_size = batch_size,\n",
    "#             shuffle=False\n",
    "#         )\n",
    "\n",
    "#         t = time.time()\n",
    "#         features = model.predict(data_iter)\n",
    "#         sys.stderr.write('predict: %.2f seconds\\n' % (time.time() - t))\n",
    "\n",
    "    # The first time when CUDA needs to load model is very slow ~350s, but later runs are faster ~90s\n",
    "        \n",
    "    # Had to modify [model]-symbol.json according to this https://github.com/dmlc/mxnet/issues/2718\n",
    "    \n",
    "    # Out of memory after about 20 sections - had to modify storage code according to https://github.com/dmlc/mxnet/issues/3055\n",
    "    #    - don't think increasing kPoolThreshold to over 4GB will be beneficial, \n",
    "    # since the computation time is similar to before limiting the pool, computation is most likely compute-bound.\n",
    "    # Issue solved by developers.\n",
    "        \n",
    "#         del patches_mean_subtracted_input, patches, im\n",
    "        del patches_mean_subtracted_input, patches_mean_subtracted, patches, im\n",
    "        \n",
    "        t = time.time()\n",
    "\n",
    "        features_fp = DataManager.get_dnn_features_filepath(stack=stack, model_name=model_name, \n",
    "                                                          section=sec)\n",
    "        create_parent_dir_if_not_exists(features_fp)\n",
    "        save_bp(features.astype(np.float16), features_fp) # bloscpack produces files of similar size\n",
    "        \n",
    "        upload_to_s3(features_fp)\n",
    "\n",
    "        feature_locs_fp = DataManager.get_dnn_feature_locations_filepath(stack=stack, model_name=model_name, \n",
    "                                                  section=sec)\n",
    "        np.savetxt(feature_locs_fp, np.c_[indices_roi, sample_locations_roi], fmt='%d %d %d')\n",
    "        \n",
    "        upload_to_s3(feature_locs_fp)\n",
    "\n",
    "        sys.stderr.write('save: %.2f seconds\\n' % (time.time() - t)) # ~.5s\n",
    "        \n",
    "#         del patches_mean_subtracted_input, patches, im\n",
    "#         del patches_mean_subtracted_input, patches_mean_subtracted, patches, sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /media/yuncong/BstemAtlasData/CSHL_patch_features/Inception-BN/MD589 s3://mousebrainatlas-data/CSHL_patch_features/Inception-BN/MD589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_patch_features', model_name, 'MD589'), \n",
    "#                     from_hostname='workstation',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sync with Gordon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmd = 'cd /media/yuncong/BstemAtlasData/CSHL_patch_features/Sat16ClassFinetuned/%(stack)s/ && \\\n",
    "rsync -r . yuncong@oasis-dm.sdsc.edu:/home/yuncong/csd395/CSHL_patch_features/Sat16ClassFinetuned/%(stack)s' % \\\n",
    "{'stack': stack}\n",
    "\n",
    "os.system(cmd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
