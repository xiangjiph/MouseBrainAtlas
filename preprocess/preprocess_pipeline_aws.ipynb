{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.38 seconds.\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt\n",
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 1\n",
      "0.34 seconds.\n",
      "File does not exist: /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from distributed_utilities import *\n",
    "from preprocess_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After receiving data of a new stack, put images and macros in corresponding folder.\n",
    "- Add the stack name to proper variables in `metadata.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD658'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_fmt = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use GUI, quality check and sort images.\n",
    "- Upload `sorted_filenames.txt` to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-rawdata/CSHL_data/MD658 /shared/CSHL_data/MD658 --exclude \"*\" --include \"*.png\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "7.88 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack), \n",
    "                     from_hostname='s3raw', to_hostname='ec2', is_dir=True, include_only='*.'+tb_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD658\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_sorted_filenames.txt /shared/CSHL_data_processed/MD658/MD658_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.43 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_sorted_filenames.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'align_consecutive_v2.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -r $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 161.395050049 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Align...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s %(input_dir)s %(output_dir)s \\'%%(kwargs_str)s\\' %(fmt)s\" % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'fmt': tb_fmt},\n",
    "                kwargs_list=[{'prev_fn': valid_filenames[i-1], 'curr_fn': valid_filenames[i]} for i in range(1, len(valid_filenames))],\n",
    "                argument_type='list',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=16) # \n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 252 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_elastix_output s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_elastix_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "20.50 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "final_metric = {}\n",
    "for i in range(1, len(valid_filenames)):\n",
    "    prev_fn = valid_filenames[i-1]\n",
    "    curr_fn = valid_filenames[i]\n",
    "    with open(os.path.join(output_dir, curr_fn + '_to_' + prev_fn, 'elastix.log'), 'r') as f:\n",
    "        t = f.read()\n",
    "        g = re.search(\"Final metric value  = (.*?)\\n\", t)\n",
    "#         final_metric[(curr_fn, prev_fn)] = -float(g.groups()[0])\n",
    "        final_metric[i] = float(g.groups()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAACqCAYAAAAKnk4GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucHmV9///XZzebZEOUTQjfEAJLUBHFIlBXBamVk2Kl\nSmotYLHG/qSpbbUnxYbSVrTyM5Zaa2sP8KO2qBWJiCFVK6eAtn4BCYaDqAghhLAJkNMKSZZks/v5\n/TEzy+zsHO/D3vfuvp+PRx6577lnZ6577jlc85nr+lzm7oiIiIiIiIiIiDRCR6sLICIiIiIiIiIi\nU4eCTSIiIiIiIiIi0jAKNomIiIiIiIiISMMo2CQiIiIiIiIiIg2jYJOIiIiIiIiIiDSMgk0iIiIi\nIiIiItIwCjaJiIjIGGa2xMzczGZkfP6QmZ1WclnHmtl9Zvacmf1hQwvaAGZ2oZnd3IL1nmpmj5jZ\nbjNb2uBl/7eZLWvAcv7czK5uRJmapdVlbNS2FhERmWrM3VtdBhERkWnLzB4HDgcOd/ftsenrgROB\no9398RLLceAYd3+0AWVaAmwEutz9QJ3L+jfgWXf/k3rLVa9Gfq8GlOU2YI27f66V5ZguzOwO4Mvu\nXnNgyswuA17m7u9pVLlERESmKrVsEhERab2NwLujN2Z2PDCndcVpqKOAh2r5w6yWVVNEzdulHu22\nTdulPO1SDhERkalCwSYREZHW+xLw3tj7ZcAX4zOY2R1mdlHs/fvM7H/D198LJ98fdss6P/557G/c\nzF4Wvj7HzNab2bNmtjlstVGKmT1uZmeFry8zs1Vm9sWwq9xDZtYXfrYWOB34fFiul5vZweG828xs\nk5n9hZl1xL7T983ss2a2A7gsMW3AzB4zszeE0zeb2TPxbkwF3yvaTgNheU5Jbqdw2feY2c/D/9+Q\n+A3+OizPc2Z2s5ktyNlOv2Nmj5rZTjNbY2aHh9M3AC8B/issx6yMbXyJmf3YzHaZ2b+b2ezws3lm\n9s1wG+4KXx+RKOdFOdt0k5m9Jvz8wnC/eFX4/v1mtjr22345fD3bzL5sZjvC3+EeM1sYfnawmf2b\nmW01s34z+6SZdWZsk8vM7PpwWc8C7zOzDjNbYWYbwuWvMrP5sb95b1jmHWb2lyn7X24Zzexy4I2x\n/fDz4fxuZn9gZo8Aj4TTPhfuN8+a2b1m9sZw+luBPwfOD5dxf8q27gj3503hfvlFMzs4/CzqmrrM\nzJ4ws+1mdmnWviMiIjLZKdgkIiLSencBLzazV4Y36RcAXy77x+7+y+HLE9x9rrtfV+LP9hAEuHqA\nc4Dfs9pzB70D+Gq4rDXA58NynQH8D/DBsFw/A/4ROJgg2PKmsAy/HVvW64HHgIXA5bFpDwCHAF8J\n1/Va4GXAewiCCHNLfK9oO/WE5bkz/iXCAMe3gH8I1/V3wLfM7JDYbL8Zlvf/ADOBj6RtEDM7A/gU\ncB6wCNgUlht3fynwBPD2sBz70pYBXAicDbwUeDnwF+H0DuDfCVpH9QKDhNs8Q3Kbfhc4LfzsTeFn\nvxx7/92UZSwj+N2OJNg2HwjXC/AfwAGC3+Mk4C3AReMXMepc4HqC3+g/gQ8BS8N1Hw7sAv4JwMyO\nA/6ZYFssCsuwOGO5qWV090sZux9+MPY3Swm2z3Hh+3sIuq/OJ9jXvmZms939O8D/C1wXLuOElPW/\nL/x3OsH+PZfxv8svAccCZwJ/ZWavzNpIIiIik5mCTSIiIu0hat30ZuAnQH8zV+bud7j7g+4+4u4P\nANcS3OzX4n/d/dvuPkzwPdJuxIkF0i5x9+fCXFSfAX4rNtsWd/9Hdz/g7lEwY6O7/3u4/OsIggmf\ncPd97n4zsJ8g0FHv9zoHeMTdvxSu/1rgp8DbY/P8u7v/LCzbKoLARJoLgS+4+w/DYNIlwCkW5I0q\n6/PuvtnddxIEid4dfscd7v51d9/r7s+Fn+V9x+Q2/W5s/jcSBMWi91nBpiGCAM7L3H3Y3e9192fD\n1k1vA/7Y3fe4+zPAZwl+5yx3uvvq8DcaJAgKXeruT4bb6jLgXRZ0bXsX8F/u/r/uvh/4KyAr4Whq\nGXPKAfApd98Z7Wvu/uVw+x5w988AswiCQ2VcCPyduz/m7rsJfvMLbGwXvY+7+6C73w/cT8axIiIi\nMtkp2CQiItIevkTQauZ9JLrQNYOZvd7Mbg+7Yv2c4IY/s0tYgadir/cCsy09B84CoIuglU9kE2Nb\nqmxO+bunY6+joEBy2lyo+3sdnihbWvmS33Uu6cYsKww+7CC7VU6a+LbYFC4TM5tjZleG3bWeJege\n2JPVdY3x2/S7wBvNbBHQSRA0OzUMhB0M3JeyjC8BNwFfNbMtZvY3ZtZF0LqqC9gadl0bAK4kaPlV\n5nsRLuMbsb//CTBM0BLr8Pj87r6XYDumySpjnjFlMbOPmNlPLOhGOUCwPWrdfzYBM8LvESm7/4iI\niExqCjaJiIi0AXffRJAo/G3ADSmz7GFs0vDDChY5Zn4zS87/FYIub0e6+8HAvwJWsdhVbSdofXJU\nbFovY1tx1TtMbt73Klr2lkTZ0spX1phlmdlBBK1uqizryEQ5toSvP0zQ2ub17v5iXugCl/X7jfne\n4YiFewm6r30vbP3zFLCcoJXayLgFuA+5+8fd/TjgDcCvErTE2wzsAxa4e0/478Xu/qqc75X8HTYD\nvxL7+x53n+3u/cBWIJ6PqptgO45faHYZ09Y5rixhfqaPEnR9nOfuPcDPqX3/6SXoXvh0+uwiIiJT\nl4JNIiIi7eP9wBnuvifls/uAd4atWl4Wzhv3NEGemMj9wKvM7EQLEktflpj/RcBOd3/ezF5H0Kqq\nqcJucKuAy83sRWZ2FPCnVMhPVULe99oGjDB2O8V9G3i5mf2mmc0ws/MJcvl8s4ZyXAv8drj9ZxHk\n+7k77DpY1h+Y2RFhLqlLCboQQvAdBwkSnc8HPlZD+b4LfJAXuszdkXg/hpmdbmbHh62nniUIGo64\n+1bgZuAzZvbiMEn2S82sSpfMfyXYJ44K13WomZ0bfnY98HYLErfPJNiPU4NqWWUMP04eH2leRBAc\n2gbMMLO/Al4c+/xpYImFCe1TXAv8iZkdHeYQi3I8HShYr4iIyJSjYJOIiEibcPcN7r4u4+PPEuQm\nehq4hiCxctxlwDVhV6TzwmTcnwBuJRhp638T8/8+8Akze44gD86qxnyLQh8iaHX1WFimrwBfaODy\nM79X2AXrcuD74XY6Of6H7r6DoDXMhwm6an0U+FV33161EO5+K/CXwNcJWue8lPw8Rmm+QhDIeQzY\nAHwynP73QDdBS7G7gO9ULR9BUOlFvDBCX/J90mEEgZ9nCbq5fZeg2xoErYdmAj8mSO59PUEy77I+\nR9Aa7ebwd7uLIGk37v4QwT7zVYLtuBt4hqA1VZUyfo4gD9QuM/uHjHLcRLAtf0bQBe55xnaz+1r4\n/w4z+2HK338hXN/3CFopPh+WXUREZNox93pbq4uIiIhII5nZ48BFYdBKQmGLoQHgGHff2OryiIiI\nSDq1bBIRERGRtmVmbw+7jx4E/C3wIPB4a0slIiIieRRsEhEREZF2di5B8u0twDHABa6m+SIiIm1N\n3ehERERERERERKRh1LJJREREREREREQapqXBJjN7q5k9bGaPmtmKlM9nmdl14ed3m9mSiS+liIiI\niIiIiIiUNaNVKzazTuCfgDcDTwL3mNkad/9xbLb3A7vc/WVmdgHwaeD8vOUuWLDAlyxZ0qRSi4iI\niIiIiIhMP/fee+92dz+0zLwtCzYBrwMedffHAMzsqwQJIOPBpnOBy8LX1wOfNzPLSwq5ZMkS1q1b\n15wSi4iIiIiIiIhMQ2a2qey8rQw2LQY2x94/Cbw+ax53P2BmPwcOAbZPSAlb6MaLPkLPlo2j75cc\nchCP79iTOm+tn2nZ7bNeLVvL1rK1bC1by26X9WrZWraWrWVr2Vp2u6x3qix74PCjOffqv82dd6pp\nZbCpYcxsObAcoLe3t8WlaYyde/Yxc//wmGl7E+8b8ZmW3T7r1bK1bC1by9aytex2Wa+WrWVr2Vq2\nlq1lt8t6p8Kyd+7ZVzjfVGM5PdKau2KzU4DL3P3s8P0lAO7+qdg8N4Xz3GlmM4CngEPzutH19fX5\nVOhGd/6Vd455f93vnjJuWr2fadnts14tW8vWsrVsLVvLbpf1atlatpatZWvZWna7rHcqLfu63z0l\nd97JwMzudfe+MvO2cjS6e4BjzOxoM5sJXACsScyzBlgWvn4XsDYv0CQiIiIiIiIiIq3Vsm50YQ6m\nDwI3AZ3AF9z9ITP7BLDO3dcA/wZ8ycweBXYSBKRERERERERERKRNtTRnk7t/G/h2YtpfxV4/D/zG\nRJdLRERERERERERqMyUShE81q9f3s/6JAfYPjzCzs4Mj53e3ukgiIiIiIiIiIqW0MmeTpFi9vp9L\nbniQ/cMjAOwfHmHj9j2sXt/f4pKJiIiIiIiIiBRrSbDJzOab2S1m9kj4/7yM+b5jZgNm9s2JLmOr\nXHHTwwwOjR0+ccSD6SIiIiIiIiIi7a5VLZtWALe5+zHAbeH7NFcAvzVhpWoDWwYGK00XERERERER\nEWknrQo2nQtcE76+BliaNpO73wY8N1GFageH96TnZ8qaLiIiIiIiIiLSTloVbFro7lvD108BC1tU\njrZz8dnH0t3VOWZahwXTRURERERERETaXdNGozOzW4HDUj66NP7G3d3MvM51LQeWA/T29tazqJZb\netJiIMjRtGVgkK5wNLqlJy3m2h880eLSiYiIiIiIiIjka1qwyd3PyvrMzJ42s0XuvtXMFgHP1Lmu\nq4CrAPr6+uoKXLWDpSctHg06nX/lnS0ujYiIiIiIiIhIea3qRrcGWBa+Xgbc2KJyiIiIiIiIiIhI\nA7Uq2LQSeLOZPQKcFb7HzPrM7OpoJjP7H+BrwJlm9qSZnd2S0oqIiIiIiIiISClN60aXx913AGem\nTF8HXBR7/8aJLJeIiIiIiIiIiNSnVS2bRERERERERERkCmpJsMnM5pvZLWb2SPj/vJR5TjSzO83s\nITN7wMzOb0VZRURERERERESkvFa1bFoB3ObuxwC3he+T9gLvdfdXAW8F/t7MeiawjCIiIiIiIiIi\nUlGrgk3nAteEr68BliZncPefufsj4estwDPAoRNWQhERERERERERqaxVwaaF7r41fP0UsDBvZjN7\nHTAT2NDsgomIiIiIiIiISO2aNhqdmd0KHJby0aXxN+7uZuY5y1kEfAlY5u4jGfMsB5YD9Pb21lxm\nERERERERERGpT9OCTe5+VtZnZva0mS1y961hMOmZjPleDHwLuNTd78pZ11XAVQB9fX2ZgSsRERER\nEREREWmuVnWjWwMsC18vA25MzmBmM4FvAF909+snsGwiIiIiIiIiIlKjVgWbVgJvNrNHgLPC95hZ\nn5ldHc5zHvDLwPvM7L7w34mtKa6IiIiIiIiIiJRR2I3OzLqA3yMI/AB8F/hXdx+qdaXuvgM4M2X6\nOuCi8PWXgS/Xug4REREREREREZl4ZXI2/QvQBfxz+P63wmkXNatQIiIiIiIiIiIyOZUJNr3W3U+I\nvV9rZvc3q0AiIiIiIiIiIjJ5lcnZNGxmL43emNlLgOF6Vmpm883sFjN7JPx/Xso8R5nZD8NcTQ+Z\n2QfqWaeIiIiIiIiIyERZvb6f9U8McPfGnZy6ci2r1/e3ukgTpkyw6WLgdjO7w8y+C6wFPlznelcA\nt7n7McBt4fukrcAp7n4i8HpghZkdXud6RURERERERESaavvufVxyw4PsHx4BoH9gkEtueHDaBJwy\nu9GZ2W+4+9eAx4BjgGPDjx529311rvdc4LTw9TXAHcCfxWdw9/2xt7No3ch5bS+Klu4fHmFmZwdH\nzu9mwdxZrS6WiIiIiIiIyLS0eefgaKApMjg0zBU3PczSkxa3qFQTJy+Ac0n4/9fdfZ+7PxD+qzfQ\nBLDQ3beGr58CFqbNZGZHmtkDwGbg0+6+pQHrnlKS0dL9wyNs3L6H7bsb8TOJiIiIiIiISFXJQFNk\ny8DgBJekNfIShO8ws5uBo81sTfJDd39H3oLN7FbgsJSPLk0sx83M05bh7puBV4fd51ab2fXu/nTK\nupYDywF6e3vzijXlpEVLRzyYrtZNIiIiIiIiIs23ffe+1PvzpMN7uieoRK2VF2w6B/hF4EvAZ6ou\n2N3PyvrMzJ42s0XuvtXMFgHPFCxri5n9CHgjcH3K51cBVwH09fWlBq6mqqwduWgHFxEREREREZHa\nxNPZdHYYIyNOUTCiu6uTi88+tmCuqSEz2BTmTLrLzN7g7tsavN41wDJgZfj/jckZzOwIYIe7D4aj\n1f0S8NkGl2PSm9nZkRpYmtmpFFciIiIiIiIijZZMZzM8UtzmZXFPNxeffey0yNcE+S2bIvPM7HJg\nSXx+dz+jjvWuBFaZ2fuBTcB5AGbWB3zA3S8CXgl8JuxiZ8DfuvuDdaxzSog3zZvZ2UHPnC6ee/4A\ng0PDo/N0GBw5f3o0zRMRERERERFphqzBuMp0l4sz4Psr6gmhTD5lgk1fA/4VuBoYLpi3FHffAZyZ\nMn0dcFH4+hbg1Y1Y31Sxffc+Nm7fQxQ03T88wvbd+/jN1/dy+0+3sWVgkC6NRiciIiIiIiJSl7TB\nuDZs28OGbXsqL2u65GmKKxNsOuDu/9L0kkihzTsHSbbOG3G4/afbRqOk5195ZwtKJiIiIiIiIjJ1\nVG29lGU65WmKKxNs+i8z+33gG8C+aKK772xaqSTVdB86UURERERERGQiNCLQNN3yNMWVCTYtC/+/\nODbNgZfUulIzmw9cR5AH6nHgPHfflTHvi4EfA6vd/YO1rnMqyEoGPh2b5ImIiIiIiIg0S9b9dxmL\ne7qnXY6mpMIhy9z96JR/NQeaQiuA29z9GOC28H2Wvwa+V+f6poQj53fTYWOndRjTskmeiIiIiIiI\nSLMcOb+b7q7OwvkSt+jTtttcUmbLJjM7w93Xmtk70z539xvqWO+5wGnh62uAO4A/SynDa4CFwHeA\nvjrWNynFM9+funIts7s6OHrBQTw/NDImGXjUJC8tU76IiIiIiIiIVLNg7iw+dMYxXLbmIQYGh1Ln\n6e7q5Ndfs3h0wK7Dp3G3uaS8bnRvAtYCb0/5zIF6gk0L3X1r+PopgoDSGGbWAXwGeA9wVt7CzGw5\nsBygt7e3jmK1j9Xr+8dkvu+P5WVa3NPNhSf3suqeJ9mwbQ+nrlzL6a84lK/f2z8mU/7G7XtYvb6/\nJeUXERERERERmcyWnrSYpSctZvX6fq646WH6BwbpNGPYfVrnYyojM9jk7h8L///tWhZsZrcCh6V8\ndGliPW5mnjLf7wPfdvcnzZIN08aV9SrgKoC+vr60ZU06V9z0MINDw6mf9Q8M8uW7nhjz/j/veoLk\nFx/xYDlHzFMLJxEREREREZFaREEnKa9MgvCauHtmayQze9rMFrn7VjNbBDyTMtspwBvDkfDmAjPN\nbLe75+V3mjKqjjCXFWHrHxhk23P7xnStWzB3Vv0FFBERERERERFJ0bRgU4E1BKPcrQz/vzE5g7tf\nGL02s/cBfdMl0ATBCHP9FQNOaQzGdK3bsG0Pm3bs5ahD5ijoJCIiIiIiItPG9t372LxzUHmOJ0Dh\naHRNshJ4s5k9QpCPaSWAmfWZ2dUtKlNbufjsY0tlvo9L62yY1uLpwIizcfsetu/eV1PZRKS87bv3\nsf6JAe7euHP036kr1+r4ExERERGZQNt372Pj9j3KczxB8kajSx2FLlLPaHTuvgM4M2X6OuCilOn/\nAfxHreubjKL+oFESMiO7qxyMzYJfpkXUiMPmnYNjWjeVifLG54lGyFMLKZF00QVtJHHw9g8M0hFG\nh3X8iIiIiIg0R3zE9jTKc9w8ed3o0kahi9Q7Gp2UEE9CFmW/j4ZTPP0Vh6YOrxiNYpeVXDwufsAl\nb4qjKO9frH5w9ODs7DBGRnw06KUbZpF8m3cOjgs0RdICviLtJO0BhPZXERERmSy27943ZoT3LFsG\nBhVsaoK80ehqGoWuDDObD1wHLAEeB85z910p8w0DD4Zvn3D3dzSrTO2ubPb7vFHs0ty9cScnfvxm\nBgaHxn024owZ9W445a55xGHDtj1s3jmoGxGRhKILW9HnIq2S9QAC9HBBRJpDeVREpNGic0qRw3t0\nvmmGUgnCzewc4FXA7Giau3+ijvWuAG5z95VmtiJ8/2cp8w26+4l1rGfaqTqKHZAaaKpKNyIi483s\n7Mi9wM3sbFXaPJF8aa3y1BrvBbopFmmsrAC38qiISD3KBJo6LMiXfO0PnhhzfY+cunLtaC8iqaYw\n2GRm/wrMAU4HrgbeBfygzvWeC5wWvr4GuIP0YJNUlDWKXU93FwfNmtGQEe6yRDcigPI6iQBHzu9O\nzdkEwYVNN6jSrrIqZ2qNp5tikWbICnArj4qI1CIKGpVx9IKDAFi3aVdqT57+gUEuuSHobKWAUzVl\nHqu/wd3fC+xy948DpwAvr3O9C919a/j6KWBhxnyzzWydmd1lZkvrXOe0kDaKXXdXJ5e941U1jXBX\nVVTpjm5I+gcGNfKdTFsL5s7i6AUHsThsmttpQZKzxT3dHL3gIAVhpW1ltbpTa7z8m2IRqU1WILuW\nFvsiMvlESbzv3riT9U8M1HzvuH33PtZt2sWGbXsqPSC75IYHUwNNkcGhYV3na1CmG110lt9rZocD\nO4BFRX9kZrcCh6V8dGn8jbu7mWX9ske5e7+ZvQRYa2YPuvuGlHUtB5YD9Pb2FhVtSouPYpdMHn7q\nyrWV8jnVKq0SrrxOMl0tmDuL6373lHHTz7/yzhaURqSctFZ5ao0XyKq89g8Msu25fWM+Vxc7kXKy\nup0rj4rI1JdM4l1LepbV6/szWyblmdnZUTqvk4Lf1ZUJNn3TzHqAK4AfEoxEd3XRH7n7WVmfmdnT\nZrbI3bea2SLgmYxl9If/P2ZmdwAnAeOCTe5+FXAVQF9fX7U9bArKSibe7AOkw8YHmuKU10lEZHKI\nztHPD42wZWCQLo1GNyovF1tyejt3sYsPBa3RBqXVsgLcUR4VEZm60oI9VfJERsGqqoGm7q5ODu+Z\nzYZte0rNr+B3dYXt4d39r919wN2/DhwFvMLd/7LO9a4BloWvlwE3Jmcws3lmNit8vQA4Ffhxneud\n1rIOEAPmzenCCLr3vOfkXhb3dI++nzenK/Xverq7Rueb2dnB0QsOKuxiEc/r1Grbd+9rWHPNaDmn\nrlyrLoMiMiUsmDuL7684g40rz+Gk3h4FIkJHzu+mw8rPX7WL3URcU7KeIuv6Ja2S7HYOLxw72i9F\nprZ680Ru3jlYqvdO/N51cU83n3rn8SyYO6tUioDurk4uPvvYUuWRF5RJEP7elGm4+xfrWO9KYJWZ\nvR/YBJwXLrcP+IC7XwS8ErjSzEYIgmIr3V3BpjpcfPaxXHLDg2MOxu6uTj71zuNzk52tXt+f+neX\nveNVLD1pMavX9/PR6x8oHRVudILZWkYFqprgNb6OeNLz5HL6BwZHb0Kiz5UsXUQaQeeTfI1qqZN2\nTUkue8HcWezYvZ9hL/cUtX9gcMzvlfZbAjy+Y++YJ7PJa0qjZD1Fjq7j0brU+ml6afUoiwvmzuLd\nr+sdU+ds1jEgIo075uPLOfHjN7N73wEOxK5lyWWnjfiWpmyeyDL3lvF710j8GmcE3bfiol47i2Np\naaSaMt3oXht7PRs4k6A7Xc3BJnffES4nOX0dcFH4+v8Cx9e6DhkvL59TrX8XBaKqBJAamWA2K2j0\nF6sfzK0gZyV4/fCq+1myYM6YefMCSlnL2bBtD4/v2MvIiI+euFRhmlx0k9X+plPwpSiwPV3F94Ef\nbNw5er6ttdt22jVlw7Y9/PF1943Os394hGeeq97SYsO2PWzYtofODht3bYgaSqWFrqp0JYi+Q9Fx\nkXfNjrYbMK7104Zte9i0Yy9HHTKnVFlk8ij7EK7MzWnVG8+4K256eFwLharHgIgUa9TIqsnlDAwO\njZsnfn9WNq9SlTyRed3bIejB87G3jw80xa9xDqMBJwWXGqcw2OTuH4q/D/M3fbVpJZKmysrnVOvf\npVUK4pJR4viJoxE381nBnv+864ncm46sE9Kw+5h5t+/el9piK6r45J3Y0k6kacnSp9MNc5FWP1WN\nl6PeRIXSXJMx+FLP/p0X2I7OUc0Kiqadq6to1jkuuQ8kz7jR9nnu+QMM7B0a14oo7bdI286NlnZt\nKFrl/uER1j8xUPj7lj0u8irm8e7uafMcGPG2zUOVRdfZYmUewpW5Oa1y45m2D2XlF210q3iR6S5v\nZNUj5pW7zmfdJ6VJ3p/lqVqfOXJ+N1sGnh93T5oWZIqk3cNGgabvrzij1HqlWJmWTUl7gKMbXRCZ\nnIqSjkcHbZRgtmdOF5t3DrJh2566n0KvXt+fWfnIuumIFFW0H9+xd1x3hqToJqWWCtD+4REe27Zn\nXDLMyXDD3Cy1tlJrhnoTFUrzZVWS2vE32r5737jzSZkniPEgTxlRy5PoXNeIm+rkk7+qTz7LBj9q\nCQaUDQzFWyGltSKKf6d6b2jTmuE3StZ1smg/STsusirm8XXlqXpD0ippx15/WG/ZsG3PuGvKVG7R\nWvTdyjyEK3NzWva4zNqHDu/pHv2N4hrZKl5kOknrsnbqyrWZx/yWgcHCc3vaubWMMnMbcFJvT6Xl\nLpg7iw+dcUyl3jtZ97Aaca6xyuRs+i9e2Dc6gOOAr9WzUjObD1wHLAEeB85z910p8/USjHx3ZFiG\nt7n74/WsWxorq1IQiaLDq9f38+Gv3T+m0l8UEMoTtTypKrqhSBv1JK7syXPYveabCwfS0n206w1z\ns5VtpVZrN44qrUrqTVQozbV9975J8xslgy1xeTfsydZ1tWhEDrmsLi1lAw1lgoK1tlKrddtkdVX7\n8Kr7mdFhY7r7lGUwpnJ76sq1udfGWqVtuzL7SfLzqGL+4VX3Z+adKtoWZW5IWinv2IvEA3gwvttg\nvS1am9GiqkxOsWQgKa21bvxaWhQ8LmrNHd8XqhyXaftQWn7RKt1pRKajrDpu1nkw7/pUNOJamXNr\nPWod8a0dFkGMAAAgAElEQVRq752se1iNONdYZVo2/W3s9QFgk7s/Wed6VwC3uftKM1sRvv+zlPm+\nCFzu7reY2Vygve4iJLVSEImy9kdPxssGcDZs28NJn7iZ+QfNzKyUlUkqlyZ5k/T49r2lE7ymGR7x\n0dH8du0d31S8VmW7TCSlXWySf98uXdWSyrZSg+rdOKr2S89qsaYnq4Gsp2QT0TUl+i2z1PoblTl2\nalH0lD95s1U2aWZZ8S5RtQR08p78lQk0lAkKVukiGFdry9Isw+6YV2+dlNbkPu/amCYvZ1NSctuV\n3QZ3b9wJvLAto0p5VjmHR5yuTmNoOL1U7V4hr9LCZsO2PanBtfh+WDawE6mnq2/WOXZoeITtu/cV\n5hR7LAwkFQVOD4z4uL/PUtSa+95NuyoHatP2obQ8oUXJ9WutJ7W6S2W71sfaQdXfqV1aJbZi/8qr\n41btGt5hwfXr2h88kfr56vX9pRsG1CK6d7z2B0+Uqmsmt3eVPEtZA2dpxLnGKhNsepu7jwkEmdmn\nk9MqOhc4LXx9DXAHiWCTmR0HzHD3WwDcfXcd65MmiVcK+gcG6TRj2H1MYrVTV64tXeGO7No7xM8H\nh8bk2pgZdsOL3tcqPirQh844ptINQRoHnh08wHtO7uXr9/aPWZYBPTUGoqq04lm9vn9cwr3kU9m8\nedoh90bVG8eshO5pqvZLT+tiMlFPVpMVpvg+PxGV0bQuOWWfknUY447ZqgHPosp3XsUp/htVqfBl\nVdQgu6tX2d+iaJ+O32w162nh/uGRzGPg8R17c79TvU/+8o7rKKBe5rhPO1cVtVCthQOdHcaLZs1I\nzTWTlFUxTV4b8wJYnWYsWRCc458fGhm9wd67/0DqtSMeUK21G3e0LaNyprVwcuDAsDOnq4O9Q+PX\ns3f/gdEh6Zt9w1zLDVzVbVMUKImCOBdff/9oAC7vXJGX77FK3q1IlZZyTvH3qSr6bdPKVsv68m5q\nky0Uzr/yTqD+XH3tlOuvUcmZp6Kqv1Nay714wDXvnFElSFVUB2jV/pVXx616Hjx6wUEsPWlx6nFZ\ntldJ1XuftBHf/nHtI7l1zUhye0flKxNwqnXgLKmmTLDpzYxvdfQrKdOqWOjuW8PXTwELU+Z5OTBg\nZjcQ5Ii6FVjh7rVHBaQpipot1tr3dcTH5trYP1zbCEBposph8oagVsPufP3efn79NYu5/afbRpfl\nwJyZMzjn1YvGBaLKSrbiSV7seuZ0ZbYciyfIzZvnT667j87wqW6rngjVcuMY5ZJIC3DEle2XHt+2\nPd1dzO7qYGDvEF0TtE3SKkzJY6BsZbSWwEhWl5yyT8nSjtkqAc8yle+8itPRCw5KTWKbFwjLekpX\n1NWrbM6lPPGbrSpJNqFa65u8gM/wiDPMCzfOG7bt4bi//G/2DzsHRpye7q5xrVvSbhLTggFAbsvR\naBuW7bqWDBBHv008QHP6Kw6t+VwbGR5xDpo1g189YRG3/3TbmEoolK+Yxq+Nq9f3c9mah8YFsLq7\nOvn11yxm1T1Psn94hMU93Xz2/BPHjPaaFvSOtnetom0ZlfFPMlq2OOAY7zm5l2/ev3VM+XftHWIg\nvJlIdnWO70P1XFOyci6VCWw3uuUbBN8z2dIr61yRJVmm5LHz9LPPNz1JfVUdxmjOzaplm9PVwayu\nTnbtHRp9IBlvXZfVgiJNPbn66gkA1qIoiJH1XZL1sYl+4FRGs1tkVf2d01p4xgOgeV3Kk/lj4w95\n80amjuaN98Ro1UAeWee5/oHByl3DN2zbkxmcK9OStrurk0+98/jRa9/RK76VWVfJG/GtqK6ZVV8a\nHBoevbaVUevAWVJeZrDJzH4P+H3gpWb2QOyjFwHfL1qwmd0KHJby0aXxN+7uZpa2O80A3gicBDxB\nkOPpfcC/paxrObAcoLe3t6hoMsGK8jo1U9YNWbxrSXSiKcqxMW9OF0BmpH5waJjbf7ptXLPM/oHB\n0UDUtXdvrqnbXnRjMLurY9zFrkwArmie+EW5nrxI9Yguajt27y/VoiCSFeCI3+hn3XRErTPSbmgG\nBofo7urkwpN7WXXPk2NGEWyWMhfyMvlyan1imrf+Wp+SxY+1vIBn2o14fL3R9836LRf3vDC6Y9YN\nRXI/Keo+sj/ssgLFIzVF8ySDwFlmdBhHHTJnzBO8KpzgOxe1mom+RxXxViwDg0N0ddiYrsLx81FW\ncK9st7ARh5EK58T+gUGefvb5MUGMZBe2vqPml+oWVLSer9/bP6bSHKlnRNfV6/vHBKui4Fj0G6U9\nmY3m74rd1DWiRVf/wOBo66a863R0bTsopbVXVhHi+1AyL1JaULJKrhHIPp7j161mtHzLUnSuiIu3\nTEs7dtpFpxkj7hze0z2u+14V8w6aNe4YjVoqVVWmW26aMgHArBE3G/HgJq0FXF7qgHh9rNYHTs0y\nES2yqv7OZa5xUUveZF0vbZc+MOLjWkZlBYF37R1i196h0g+LsurY9QTwih4oVe0antUiq2g7p438\nlnVtKRrxrZ4HBUrw3V7yWjZ9Bfhv4FMEOZUiz7n7zqIFu/tZWZ+Z2dNmtsjdt5rZIuCZlNmeBO5z\n98fCv1kNnExKsMndrwKuAujr62uz50GSlbti3pyuulr8xPV0d7Fn/4ExTxyjJ8Zfviv9qVmyf29e\nOaOTZ9qT5rgtA4OpCXWjyvpnzjshcx2QHciKlt3V2TFhTzwnYnjrtCd/aTc0VSUDFFk3HXv3H2Dj\n9j2ZlejBoeFxCcqbuU3KXlyL8uWUGcI6rmyeoFpvhKJuXHnLz/vN4wGGzg4bV3Hq7urk9FccyrU/\n2Fx5ZJQiL7TSyB6p6bGwkhnfT7ICvJ1mvPv1R44GMGttyZCsqEVBjHh35kaNjDY04rgH2zkeRI8q\no2n7WzNPU8nA+EmfuHlMBXfpSYvrbq0K1Z+QlpF8iprWzTy+3niQ6qPXP9Dw1m9RYKsox1S9lffo\nRs/dcwMr9eQagbHXrbSWb1HrtLzE6LUqOldE9g+PjObPalfJ1gkvv/S/a6575O07aXWAPFk31Z0d\nNq77d7x1Rpl9KRkYKtvaNi7vWhpv4XLqyrU1D0aQ9sBpIvMEVU1LUIuqeTPLtmKsUj9ItoxqtPi5\nqt4AXl5g3QmOj8NePLtS/SDaX6OHrAvmzso+/sz4zHknpF4ra82LVE/L1HbPJzjdZAab3P3nwM/N\nLNldbq6ZzXX38u1ex1sDLANWhv/fmDLPPUCPmR3q7tuAM4B1daxTWqSoT2zfUfMzWzWUER/xLm0d\n8W5tSXlPkdO6SOTlt4DgBJeXUDdvHUWBrA6zhncJKBK1ONm7f7hUf/Yqsp785dUFootkGfHcXFmt\npsr0J0+uLdnMPZJs7l5LjoCyF9cOM7bv3pf5O+QFRpLJbqF8K4l6ghf17rvRto4n5R/YOzSmdUij\nA02RtHw1cVXWGnW5jbdkydPVYWCMC6QnK2ppQYxGVpCzWp01Mpl5pOp+tmvv0LjzeFoFN21bdnUY\nc2fPyDwXNPsJaZmhl6NrQ5ntvDi8BpXtUhgFtqLAZd61Deq76Sp7fNbaijL590fMC86r1/3uKanz\n1ZuvMU3RuaLVoodwyS6R8MJxl+zasnp9f13HeNaNX9YIecngcVzaTbUBI7HuwJF4QLyWFrllW9vG\nv0/Za2nU+rPWa2r/wCDbngtGZe3sMEZGfHQ5eXmC8nIyRvMWdf8rm5YgTVFOSAi2Y1Y9Lx6ojZct\nLc/mZBDtS9ueG//As2xQEYpbU0bn3r8Pu2gDY+6ZilpGRy2x5h80k+eePzAucJTWAjhSa16kWlum\nKsF3+ymTs+lbBOdCA2YT5E96GHhVHetdCawys/cDm4DzAMysD/iAu1/k7sNm9hHgNjMz4F7g/6tj\nndJCeX1i07oXHNzdxbPPDxWeZOInlax1FD2xTXuKXPRdYHxFNSpL1hP1qMKVtY5oWlYFp9FPYcuK\nl6WoO0SVwEraTWre7x1VgKvcICTzOXWaFf9RCfEnXpFka5ZkEsNI8sYxvk3LVpiKclWVCVpF6+0w\nK30xb5dmo06QC239X70FSG8d0q46zUqXtdOMK37jBKB6RW2impFXvYkrc3MV7yJYVrIVUlYFN21a\nXjfqZj8hLZOAPa21bJq0bgl9R80vbOUV7StF17a0z5ply8BgXU+2i258o+9ab3fLshrRyjC5jChQ\nmgy6J3+ftOS7n1x6fOYDurjoepUl6mp3cHcX+w8Mjwu25d34ZQWq04LHkWRrtYO7u3IfVObldonK\nn1W3Kmptm6zzVG2JV8/+YLxw7s3qmh4f/CESz08USdbr8rr/5bW0KTpXlskJWSVgt394bBLwnu4u\n9h0Ybrt8Z0WKzs3Reaye7urR/PHjKn4vUubh1IER55nn9jGnq2PMw74y9ZFa8iLFj/V4i6w8ad34\npPUKg03ufnz8vZn9IkEup5q5+w7gzJTp64CLYu9vAV5dz7pk8ogHnS654cHCC0anWW40Pb5cyE8C\nXvXGrChSX+tQmvFtUGsz/7QuhbXMkyWt8lYl+WLZIZnjou1XNaF7Mq9H1e1Z7w1CPF9RJO3GMZrv\npN4ePnTGMWNytPTM6WLH7v3jyp6Xq6rsE6GifDnxZK5ZN30GfPb8E0vdhKZtzxnhjlO1O0H8mJ0s\n/fPj3dDKzBs/v1WtPDUyV153VyezuzpqGlUzuZwyueviQZMqLbSS+0FRYD+uVUMgl1lvmf07b1S8\nohuK+E1imafQjeiiWCQa7r7WnEtlgoR53S17urs4aNaM0YBG8npZ9dpQz3WkqPV2XBRcrJrAPkte\noDOtRUPZAFaydUtSPHicNv/inm4uDEcArlVRqoUiZXMwNUOZ/Sk++EPR38XrKmkPAeN5F9MkB7tI\n5h7KesAYX8eHV92PWf5Dx6T4g78ov2Bnx/gk/q2Q1pI2Td65JH4ea0R39ayu4VUe5O4dGsGx0YEs\nminZMrWoB8icmTMUaGpDZVo2jeHuPzSz1zejMCJQ7iluUbPNpKIk4LU8vS66kalnKM280YGyxLfJ\n6vX9mU9sDbjvY28Z15Is7alkFfEKSfwGIXkxTGsVlCaenDS+/aLtnjfCRSM0KqdYsnKVdeMYzZfM\n0VJlBMZks+vHt++tuUVc/Ib//CvvzLw5OLyne9w+n7VGh3FPxKLKadUm8B1mpZIbl6nwRZW9eoKw\nRaJWBWVv1Kuc39LkVR6zKrfxVgpmjPmdoL5WLfGHA31Hzc9cVjJoUqUSXE8rpEact5u13qLAYdkH\nL2UDamVaImddS+P7UJnWyWmSox1WHW0wbbTELFnb5LJ3jH06npXYvWyLM6itC2KZ1ttxtbQgyJMX\n6MxKnp+3/ipdQreECezT5u8fGByTT7Gq+PW9Vlmth2pV1Eqs2fK+Q1HexajukUwkH++CVVTvG3av\nu/nfUNjCKQoUl3noErWGgWqB9KLcR/Gy5A3kkfWVk+exRgUz047pqg9ym5HPsIyiFqmT5cHjdFMY\nbDKzP4297QB+EdhSz0rNbD7B6HJLgMeB89x9V2Ke04HPxia9ArjA3VfXs25pf3knC4O6bgIm6ul1\nIyp8ZS6SeQGZWrrz5QWpyogqFo0w4s7Gledkft6sUQ6TiQ77jppfdzLZeCL6vHLfvXEnp65cO26E\nqiriuRxqDZ6kHRNpXfyyboTyWqM8PzQyZmj3KIjV093F7K4OBvYOpbYkSBp2L0xunKxExm8Uk0Pa\nx/MYFOWQK8rzk2QwpntTUfBkcSyAV6tk5TGqGC/OuFEuG8CvpVVLViuttLJl5ckrCow34jze6Bv1\nRq03L+BW5cFLIwNqWdfS5JDXVcVHabz2B0+k5lxKtt6Jjudov0yOlpin7DZJ+43K5Jus0gUxammT\ndW5qhbyRpGopV9kuodG68+avJy4xZ+YMbv/ptrq7hKa1HqpVss6TfCDYrAchZZTp0pp3XaglEXqt\nfj44xH0fe8vo+7zAeFpS6zIPN8o+3E2WJT6QR5Eob9jufQcqb7+8AHfWQ5lk75KibdDMwE68bhiv\nP0flLLq/kfZiXnADZWYfi709QBAc+rq7P1/zSs3+Btjp7ivNbAUwz92Ticjj888HHgWOcPe9ecvu\n6+vzdeuUR3wyy7owFA2TWVaZZt7toMwJ3yAzIJP292VuTBqdWLhWRb932QtimqwnUlnbp551JZcN\nxZWZerrvZeX12LV3qNRykxWwqIVVFBBKtnhJ25eKtldW/q1kBa5MDrcqXUyqSK4/7XuX3S/yRo4r\nuw82Wj3bq+gckXyy3Ixz7GQ5jzdK2miDacG5VpQp6zfI20+yAivRU/zrfvcUzr/yztHXZcqSPBY7\nDI5ecBC3ffi0Or5lsTLnivh88d+wXX7LLLXWI7KUbZEcreNPrruvKS2Yq+S6qSr+EHDv/gOlH0rk\n1Xkmsl7WqFFMG6Vsd7RI2vW27D6ctZ2LrmlV7lsaUZ/Mk1fXLHvslnno1qh7srR1F5W70eclqc7M\n7nX3vlLzFgWbmsHMHgZOc/etZrYIuMPdMx9Jmtly4E3ufmHRshVsmvx0EnlB0VOQMgGZqjdkzb4Q\npqn1hjuta0Pe6IPJZVfZPmk3FGUDOJF4YKSeERiriq+3qJVWPIBZz7FY1JUz74l52j6ddZOSF3Cd\nCEVPn4u212QMmuSdI6bruVrGy9pP8pK4xgNMVYJNWTd7Mzs7+Nnlv1JL8SXUyHNU1Zv5oiBLVt0B\n8h/qVO3aWKWVcNE1NGuE0bzzZiPTBpSps8zp6miLkRWjh19A5gOauLwHhmX24VrrGY0IaJWVlyg7\n7WFhPcduVl21mdf5soG7yVh3mkqqBJsyu9GZ2Zq8P3T3d1QtWMxCd98avn4KWFgw/wXA39WxPplE\nWpU7ox3lNWst022klm4hadu/ytO5qurpOpD1/fKaTSe785TdPnnzJi96RYnoo2bAVYNNtYzIl1wv\n5FfCi0bBKttXv6ipc5kh35N/047NppP7RdUKUKu6btWjSjc4mb4m8lpelAtPatfIc1TZHFl588f/\nrqjukHWjXKVrY/LhVFGgoEzC/bRpeds46/qXDNIV1dUWlwzkDZYINJUZHSxL2YFFRtzHdb8uW7+L\nK7sP11rPqHKuq7f7Wd42j2+vqFz1HLvxe5CJuicrWzecjHWn6SovZ9MpwGbgWuBuXmh1WoqZ3Qoc\nlvLRpfE37u5mlnnkhC2fjgduyplnObAcoLe3t0oxpU3pJDLWRAfg0m6gs55QA7mVm04z3v36I1OT\nqTZrmNIy+UQaKbm9yiSiL6pwpD2xTY7It2VgkI4SFb60ym9RJTyvjGUrS3k50qr2uW/VaGFVTZdz\n13T5nlKfidpPsm4SZ3Z2NH3dUl7Vukw9ge2yN8pl8/lFy8sL0kRJndPKkfXdyqiSyL5s3ScvkFcU\nQjLgM+edUHMr+OTAIlnbM60+kFX/SAZaalFPPaPegFaV1nZZrbua9fBtIq/37fpgUWqXF2w6DHgz\n8G7gN4FvAde6+0NlFuzuZ2V9ZmZPm9miWDe6Z3IWdR7wDXfPvJt196uAqyDoRlemfCKTTStv7vIq\niEXd7kbc+eTS4ysNydzM8k6EMhWWvBZQRU9s4/tCURLevNGmiirh9V70i36HKpW6Vv+mItK+0s65\nHRYMbCDtpWpdplGtMxq17KwgTTy5faOVvf5VuU5G02oZFCYtWJSWL7Kr03IHc6il9X4zgxETUc8o\nqh+WCeA52Q8kJ7vJ8mBRyiuVs8nMZhEEna4APu7un69rpWZXADtiCcLnu/tHM+a9C7jE3W8vs2zl\nbBKZeHm5gJqVRLDdFQVyaslnkibvKWu93ZqanT9Nfe5FJK7WnE0w/nwSjUZX9u9Fykq7dsWT208m\nWXWIrNYzVfMilb3OV5lvsud1zfuuyTyQRUm6p2L9SXXD9tewBOFhkOkcgkDTEmAN8AV376+zgIcA\nq4BeYBNwnrvvNLM+4APuflE43xLg+8CR7l6q472CTSKtMRUqABOtERdUBYREZKqoJ9iUtyyRZoqP\n2jrZctdl1SGi1tXtmJdvOtVLmj1Ct0gtGpUg/IvALwDfJmjN9KMGlQ933wGcmTJ9HXBR7P3jwNQ8\ne4hMMermVF0jukY2e7srN4+IiEi6KFgTJaPvHxjkkhseBKrlZWqVyVh3m071EnUrk8kuL2fTe4A9\nwB8Bf2g2mh/cCPJ6v7jJZRORSWY6VQDaiba7iIjIxKtn1NZ2oTpE+5qMwUCRuMxgk7trCA8RERER\nEZEU9Y7aKlJEwUCZzFoSUDKz+WZ2i5k9Ev4/L2O+vzGzh8zsJ2b2DxZrXiUiIiIiU8Pq9f2sf2KA\nuzfu5MSP38y9m3Zx98adnLpyLavX15UqVKRpskZB01DtIiItCjYBK4Db3P0Y4Lbw/Rhm9gbgVODV\nBLmjXgu8aSILKSIiIiLNlcx7MzA4xIGRYACbKAdOlYBTPHClYJU008VnH0t3V+eYacqpIyISaFWw\n6VzgmvD1NcDSlHkcmA3MBGYBXcDTE1I6EREREZkQaXlv4qIcOGVkJWxWwEmaYelJi/nUO49ncU83\nRjBKmEbhFREJ5CUIb6aF7r41fP0UsDA5g7vfaWa3A1sJkpJ/3t1/MoFlFBEREZEmK5PfpmwOnKmQ\nsFkmF+XUERFJ17Rgk5ndChyW8tGl8Tfu7mbmKX//MuCVwBHhpFvM7I3u/j8p8y4HlgP09vbWW3QR\nERERmSCH93TTXxBMKpsDRwmbRURE2kPTutG5+1nu/gsp/24EnjazRQDh/8+kLOLXgLvcfbe77wb+\nGzglY11XuXufu/cdeuihzfpKIiIiItJgaXlv4qrkwFHCZhERkfbQqpxNa4Bl4etlwI0p8zwBvMnM\nZphZF0FycHWjExEREZlCknlverq7mDenq6YcOErYLCIi0h7MfVwPtuav1OwQYBXQC2wCznP3nWbW\nB3zA3S8ys07gn4FfJkgW/h13/9OiZff19fm6deuaWHoRERERaVer1/dzxU0Ps2VgkMN7urn47GOV\nU0dERKQBzOxed+8rNW8rgk3NpGCTiIiIiIiIiEhjVQk2taobnYiIiIiIiIiITEEtCTaZ2Xwzu8XM\nHgn/n5cx36fN7Efhv/MnupwiIiIiIiIiIlJNq1o2rQBuc/djgNvC92OY2TnALwInAq8HPmJmL57Q\nUoqIiIiIiIiISCWtCjadC1wTvr4GWJoyz3HA99z9gLvvAR4A3jpB5RMRERERERERkRq0Kti00N23\nhq+fAhamzHM/8FYzm2NmC4DTgSMnqoAiIiIiIiIiIlLdjGYt2MxuBQ5L+ejS+Bt3dzMbNySeu99s\nZq8F/i+wDbgTGM5Y13JgOUBvb2+dJRcRERERERERkVo1Ldjk7mdlfWZmT5vZInffamaLgGcylnE5\ncHn4N18BfpYx31XAVQB9fX3jAlciIiIiIiIiIjIxWtWNbg2wLHy9DLgxOYOZdZrZIeHrVwOvBm6e\nsBKKiIiIiIiIiEhlTWvZVGAlsMrM3g9sAs4DMLM+4APufhHQBfyPmQE8C7zH3Q+0qLwiIiIiIiIi\nIlJCS4JN7r4DODNl+jrgovD18wQj0omIiIiIiIiIyCTRqm50IiIiIiIiIiIyBSnYJCIiIiIiIiIi\nDdOSYJOZ/YaZPWRmI2Gepqz53mpmD5vZo2a2YiLLKCIiIiIiIiIi1bWqZdOPgHcC38uawcw6gX8C\nfoUgd9O7zUw5nERERERERERE2lirEoT/BCAcaS7L64BH3f2xcN6vAucCP256AUVEREREREREpCbt\nnLNpMbA59v7JcJqIiIiIiIiIiLSpprVsMrNbgcNSPrrU3W9s8LqWA8vDt7vN7OFGLr+FFgDbW10I\nERlDx6VI+9FxKdJ+dFyKtB8dl1Kvo8rO2LRgk7ufVeci+oEjY++PCKelresq4Ko619d2zGydu2cm\nUBeRiafjUqT96LgUaT86LkXaj45LmUjt3I3uHuAYMzvazGYCFwBrWlwmERERERERERHJ0ZJgk5n9\nmpk9CZwCfMvMbgqnH25m3wZw9wPAB4GbgJ8Aq9z9oVaUV0REREREREREymnVaHTfAL6RMn0L8LbY\n+28D357AorWbKdc1UGQK0HEp0n50XIq0Hx2XIu1Hx6VMGHP3VpdBRERERERERESmiHbO2SQiIiIi\nIiIiIpOMgk1tyszeamYPm9mjZrai1eURmS7M7Atm9oyZ/Sg2bb6Z3WJmj4T/zwunm5n9Q3icPmBm\nv9i6kotMXWZ2pJndbmY/NrOHzOyPwuk6NkVaxMxmm9kPzOz+8Lj8eDj9aDO7Ozz+rgsH+sHMZoXv\nHw0/X9LK8otMVWbWaWbrzeyb4Xsdk9ISCja1ITPrBP4J+BXgOODdZnZca0slMm38B/DWxLQVwG3u\nfgxwW/gegmP0mPDfcuBfJqiMItPNAeDD7n4ccDLwB+F1UcemSOvsA85w9xOAE4G3mtnJwKeBz7r7\ny4BdwPvD+d8P7AqnfzacT0Qa748IBtiK6JiUllCwqT29DnjU3R9z9/3AV4FzW1wmkWnB3b8H7ExM\nPhe4Jnx9DbA0Nv2LHrgL6DGzRRNTUpHpw923uvsPw9fPEVSiF6NjU6RlwuNrd/i2K/znwBnA9eH0\n5HEZHa/XA2eamU1QcUWmBTM7AjgHuDp8b+iYlBZRsKk9LQY2x94/GU4TkdZY6O5bw9dPAQvD1zpW\nRSZY2Mz/JOBudGyKtFTYXec+4BngFmADMODuB8JZ4sfe6HEZfv5z4JCJLbHIlPf3wEeBkfD9IeiY\nlBZRsElEpAIPhvDUMJ4iLWBmc4GvA3/s7s/GP9OxKTLx3H3Y3U8EjiBomf+KFhdJZNoys18FnnH3\ne1tdFhFQsKld9QNHxt4fEU4TkdZ4OuqCE/7/TDhdx6rIBDGzLoJA03+6+w3hZB2bIm3A3QeA24FT\nCLqtzgg/ih97o8dl+PnBwI4JLqrIVHYq8A4ze5wgDcsZwOfQMSktomBTe7oHOCYcOWAmcAGwpsVl\nElVAy1YAAARsSURBVJnO1gDLwtfLgBtj098bjnx1MvDzWJceEWmQMIfEvwE/cfe/i32kY1OkRczs\nUDPrCV93A28myKd2O/CucLbkcRkdr+8C1oYtEkWkAdz9Enc/wt2XENw/rnX3C9ExKS1i2p/ak5m9\njaDPbSfwBXe/vMVFEpkWzOxa4DRgAfA08DFgNbAK6AU2Aee5+87wBvjzBKPX7QV+293XtaLcIlOZ\nmf0S8D/Ag7yQh+LPCfI26dgUaQEzezVBcuFOggfYq9z9E2b2EoJWFfOB9cB73H2fmc0GvkSQc20n\ncIG7P9aa0otMbWZ2GvARd/9VHZPSKgo2iYiIiIiIiIhIw6gbnYiIiIiIiIiINIyCTSIiIiIiIiIi\n0jAKNomIiIiIiIiISMMo2CQiIiIiIiIiIg2jYJOIiIiIiIiIiDSMgk0iIiIigJntbnUZAMzsajM7\nruLftEXZRURERADM3VtdBhEREZGWM7Pd7j631eWoxWQuu4iIiEw9atkkIiIiEmNmp5nZd83sRjN7\nzMxWmtmFZvYDM3vQzF4azvd2M7vbzNab2a1mtjCcfqiZ3WJmD4WtlDaZ2YLws/eEy7nPzK40s86U\n9d9hZn3h691mdrmZ3W9md8XWcbSZ3RmW55OJv7/YzO4xswfM7OPhtNeG72eb2UFh2X6huVtSRERE\npisFm0RERETGOwH4APBK4LeAl7v764CrgQ+F8/wvcLK7nwR8FfhoOP1jwFp3fxVwPdALYGavBM4H\nTnX3E4Fh4MKCchwE3OXuJwDfA34nnP454F/c/XhgazSzmb0FOAZ4HXAi8Boz+2V3vwdYA3wS+Bvg\ny+7+o8pbRURERKSEGa0ugIiIiEgbusfdtwKY2Qbg5nD6g8Dp4esjgOvMbBEwE9gYTv8l4NcA3P07\nZrYrnH4m8BrgHjMD6AaeKSjHfuCb4et7gTeHr08Ffj18/SXg0+Hrt4T/1ofv5xIEn74HfAK4B3ge\n+MOC9YqIiIjUTMEmERERkfH2xV6PxN6P8EL96R+Bv3P3NWZ2GnBZwTINuMbdL6lQjiF/IcHmMGPr\nbmmJNw34lLtfmfLZIQTBpy5gNrCnQjlERERESlM3OhEREZHaHAz0h6+XxaZ/HzgPRru1zQun3wa8\ny8z+T/jZfDM7qsZ1fx+4IHwd74p3E/D/mNnccB2Lo/UBVwJ/CfwnL7SEEhEREWk4BZtEREREanMZ\n8DUzuxfYHpv+ceAtZvYj4DeAp4Dn3P3HwF8AN5vZA8AtwKIa1/1HwB+Y2YPA4miiu98MfAW4M/zs\neuBFZvZeglZSXwFWAq81szNqXLeIiIhILnuhZbaIiIiI1MvMZgHD7n7AzE4hSOR9YqvLJSIiIjJR\nlLNJREREpLF6gVVm1kGQ4Pt3CuYXERERmVLUsklERERERERERBpGOZtERERERERERKRhFGwSERER\nEREREZGGUbBJREREREREREQaRsEmERERERERERFpGAWbRERERERERESkYRRsEhERERERERGRhvn/\nAXldpm4n70cfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8c9fdfc710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metric_arr = np.array(final_metric.values())\n",
    "plt.figure(figsize=(20,2));\n",
    "plt.ylim([-1, metric_arr.max()+.1]);\n",
    "plt.stem(metric_arr);\n",
    "plt.title('Mutual information of pairwise registration');\n",
    "plt.yticks(np.arange(-1, metric_arr.max()+.1, 0.1));\n",
    "plt.xlabel('Image index');\n",
    "plt.ylabel('Mutual info');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst pair: MD658-N57-2017.03.31-19.55.51_MD658_2_0170\n"
     ]
    }
   ],
   "source": [
    "print 'worst pair:', valid_filenames[np.argmin(final_metric.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download `elastix_output/` to local machine, edit consecutive transforms in local GUI, generate `custom_transforms/` to S3, upload to S3.\n",
    "- determine anchor image, upload `anchor.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "#                      from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_custom_transforms && mkdir -p /shared/CSHL_data_processed/MD658\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_custom_transforms /shared/CSHL_data_processed/MD658/MD658_custom_transforms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.67 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_custom_transforms'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD658\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_anchor.txt /shared/CSHL_data_processed/MD658/MD658_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.44 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_anchor.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'compose_transform_thumbnail_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')\n",
    "output_fn = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "                                                dict(stack=stack, anchor_fn=anchor_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -f $output_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing transform...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 nodes requested, 13 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f /shared/CSHL_data_processed/MD658/MD658_transformsTo_anchor.pkl\n",
      "ln -s /shared/CSHL_data_processed/MD658/MD658_transformsTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173.pkl /shared/CSHL_data_processed/MD658/MD658_transformsTo_anchor.pkl\n",
      "done in 20.2088689804 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n",
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Composing transform...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s %(input_dir)s \\'%%(kwargs_str)s\\' %(anchor_idx)d %(output_fn)s\" % \\\n",
    "            {'stack': stack,\n",
    "            'script': script,\n",
    "            'input_dir': input_dir,\n",
    "            'anchor_idx': valid_filenames.index(anchor_fn),\n",
    "            'output_fn': output_fn},\n",
    "            kwargs_list=[{'filenames': valid_filenames}],\n",
    "            argument_type='list',\n",
    "               cluster_size=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "linked_name = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_anchor.pkl' % dict(stack=stack))\n",
    "execute_command('rm -f ' + linked_name)\n",
    "execute_command('ln -s ' + output_fn + ' ' + linked_name)\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658 s3://mousebrainatlas-data/CSHL_data_processed/MD658 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "1.06 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "#                      from_hostname='ec2', to_hostname='s3', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "#                      from_hostname='ec2', to_hostname='s3', is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD658 /shared/CSHL_data_processed/MD658 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.55 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "out_dir = os.path.join(DATA_DIR, stack, stack + '_thumbnail_alignedTo_' + anchor_fn)\n",
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -rf $out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 288.844124079 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Warping...'\n",
    "\n",
    "transforms_filename = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "                                   dict(stack=stack, anchor_fn=anchor_fn))\n",
    "transforms_to_anchor = pickle.load(open(transforms_filename, 'r'))\n",
    "\n",
    "if pad_bg_color == 'auto':\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s %(out_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 %%(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir\n",
    "                    },\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "                                'output_fn': fn + '_thumbnail_alignedTo_' + anchor_fn + '.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames],\n",
    "                    exclude_nodes=[33],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=8)\n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s %(out_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 %(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "                                'output_fn': fn + '_thumbnail_alignedTo_' + anchor_fn + '.tif'}\n",
    "                                for fn in valid_filenames],\n",
    "                    exclude_nodes=[33],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=8)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173 s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.80 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned images to local. In GUI, check alignment correctness.\n",
    "- Place cropbox. Upload `cropbox.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropbox.txt && mkdir -p /shared/CSHL_data_processed/MD658\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropbox.txt /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropbox.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(DataManager.get_cropbox_filename(stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "w = xmax + 1 - xmin\n",
    "h = ymax + 1 - ymin\n",
    "x = xmin\n",
    "y = ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_fn = sections_to_filenames[first_sec]\n",
    "last_fn = sections_to_filenames[last_sec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p /shared/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s\" % \\\n",
    "                           {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "output_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s_cropped\" % \\\n",
    "                           {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "execute_command('mkdir -p ' + output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 623x492+563+65 -write \"/shared/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped/%[filename:name]_cropped.tif\" /shared/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173/*.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 35.737657 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.tif\" %(input_dir)s/*.tif' % \\\n",
    "    {'input_dir': input_dir,\n",
    "     'output_dir': output_dir,\n",
    "    'w':w, 'h':h, 'x':x, 'y':y})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 100 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_thumbnail_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand lossless JP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-rawdata/CSHL_data/MD658 /shared/CSHL_data/MD658 --exclude \"*\" --include \"*_lossless.jp2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3107.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack),\n",
    "                    from_hostname='s3raw',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True,\n",
    "                    include_only='*_lossless.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "expanding...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "done in 0.887854 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_lossless_tif'))\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "\n",
    "# filenames_to_expand = [fn for fn in filenames[first_idx:last_idx+1] if not os.path.exists(os.path.join(input_dir, fn + '_lossless.tif'))]\n",
    "\n",
    "filenames_to_expand = [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                       if not os.path.exists(os.path.join(input_dir, fn + '_lossless.tif'))]\n",
    "\n",
    "run_distributed('export LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH; %(kdu_bin)s -i %(input_dir)s/%%(fn)s_lossless.jp2 -o %(output_dir)s/%%(fn)s_lossless.tif' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN,\n",
    "                 'output_dir': output_dir,\n",
    "                'input_dir': input_dir},\n",
    "                kwargs_list={'fn': filenames_to_expand},\n",
    "                argument_type='single',\n",
    "               cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_tif s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "5965.93 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) # 6000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping and cropping lossless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD585/MD585_lossless_tif && mkdir -p /shared/CSHL_data_processed/MD585\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD585/MD585_lossless_tif /shared/CSHL_data_processed/MD585/MD585_lossless_tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3079.07781506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3079.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)\n",
    "# 3000 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_filepath = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_anchor.pkl' % {'stack':stack})\n",
    "tfs = pickle.load(open(tf_filepath, 'r'))\n",
    "# Note that the index from trasform pickle file starts at 0, BUT the .._renamed folder index starts at 1.#\n",
    "\n",
    "lossless_tif_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_tif')\n",
    "lossless_aligned_cropped_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "\n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "rm -r $lossless_aligned_cropped_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "rm -r $lossless_aligned_cropped_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('warping and cropping lossless...')\n",
    "\n",
    "wait_num_nodes(16)\n",
    "                   \n",
    "if pad_bg_color == 'auto':\n",
    "    # If alternating, then black padding for F sections, white padding for N sections.\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "else:\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4140 seconds (AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "1064.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) \n",
    "# 512 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (optional) contrast stretch Neurotrace, convert to 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_tif')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_tif_contrast_stretched')\n",
    "in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrast stretch neurotrace images...16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "done in 1.195507 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Contrast stretch neurotrace images...')\n",
    "               \n",
    "run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s %(imin)d %(imax)d'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                     'imin': 0,\n",
    "                     'imax': 400\n",
    "                    },\n",
    "                    kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'),\n",
    "                                'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif')}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                if fn.split('-')[1][0] == 'F'],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_contrast_stretched s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_contrast_stretched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "708.19 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) #700s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for full nissl stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1136.945903 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_nissl_stacks:\n",
    "for stack in ['MD595']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for alternating nissl/neurotrace stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1098.395771 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 2371.7916441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1008.132029 seconds\n",
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1053.684169 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 3785.25425816 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1298.919096 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD653', 'MD657']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': \n",
    "                                     [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'N']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds.\n",
    "    \n",
    "    # Match intensity profile between Neurotrace Blue to Nissl\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Match intensity profile between Neurotrace and Nissl...')\n",
    "\n",
    "    filename_pairs = []\n",
    "    l = valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+d], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-d], l[i]))\n",
    "                    break\n",
    "            \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' ' % \\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'filename_pairs': filename_pairs},\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds. \n",
    "    # TODO: One node is especially slow, investigate.\n",
    "    \n",
    "    # Convert Neurotrace images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "    \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'F']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast stretch all nissl-like grayscale images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 55.766311 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_nissl_stacks:\n",
    "for stack in ['MD585']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Contrast stretch nissl grayscale image\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Contrast stretch nissl grayscale image...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_image.py')\n",
    "\n",
    "    run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s \\'%%(filenames)s\\' 23 160'%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "    \n",
    "    \n",
    "#     run_distributed(command='rm -r /scratch/*',\n",
    "#                         argument_type='single',\n",
    "#                        cluster_size=16)\n",
    "#     wait_qsub_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Convert Nissl images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert nissl images to gray...')\n",
    "               \n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                    {'script_path': script_fp, 'stack': stack},\n",
    "#                     kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]},\n",
    "                    kwargs_list={'filenames':\n",
    "                                 [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                  if fn.split('-')[1][0] == 'N']},\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert contrast-stretched Neurotrace images to grayscale\n",
    "\n",
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 75.575123 seconds\n"
     ]
    }
   ],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Convert neurotrace images to gray...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s'%\\\n",
    "#                     {'script_path': script_fp},\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray.tif')}\n",
    "# #                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                  for fn in valid_filenames[150:151]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Match intensity profile between Neurotrace Blue to Nissl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD642']:\n",
    "\n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "    anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "    download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "    xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    w = xmax + 1 - xmin\n",
    "    h = ymax + 1 - ymin\n",
    "    x = xmin\n",
    "    y = ymin\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "    \n",
    "    #########################################################\n",
    "\n",
    "    t = time.time()\n",
    "    print 'Match intensity profile between Neurotrace and Nissl...',\n",
    "\n",
    "    \n",
    "    filename_pairs = []\n",
    "    l = valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+j], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-j], l[i]))\n",
    "                    break\n",
    "    \n",
    "    script = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' ' % \\\n",
    "                    {'script_path': script,\n",
    "                    'stack': stack,\n",
    "                    'filename_pairs': filename_pairs},\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=1)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Convert Neurotrace images to grayscale (New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]:\n",
    "#     download_from_s3(DataManager.get_image_filepath(stack=stack, version='cropped', resol='lossless', fn=fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'));\n",
    "! rm -r {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1183.526723 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert neurotrace images to gray...')\n",
    "               \n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                    {'script_path': script_fp, \n",
    "                    'stack': stack},\n",
    "#                     kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]},\n",
    "                    kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1][1:2]},\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_gray s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_gray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "328.34 seconds.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'), is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped && mkdir -p /shared/CSHL_data_processed/MD589\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r $output_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "if stack in all_nissl_stacks:\n",
    "    \n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=output_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16,\n",
    "                   jobs_per_node=16)\n",
    "    \n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                    dict(script=script_fp,\n",
    "                         stack=stack,\n",
    "                         input_dir=input_dir,\n",
    "                         output_compressed_dir=output_dir),\n",
    "                        kwargs_list={'input_filenames': \n",
    "                                     [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                      for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                      if fn.split('-')[1].startswith('N')]},\n",
    "                        argument_type='list2',\n",
    "                         cluster_size=16,\n",
    "                       jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 765 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "36.94 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG for neurotrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "out_jpeg_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=out_jpeg_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                  if fn.split('-')[1].startswith('F')]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed --exclude \"*\" --include \"*contrast_stretched*.jpg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "31.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True,\n",
    "                    include_only='*contrast_stretched*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# print 'Generating saturation image...',\n",
    "\n",
    "# run_distributed4('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_saturation_dir %(output_saturation_dir)s' % \\\n",
    "#                 dict(script=script_fp,\n",
    "#                      stack=stack,\n",
    "#                      input_dir=input_dir,\n",
    "#                      output_saturation_dir=out_sat_dir,\n",
    "#                      kwargs_list={'input_filenames': [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' for fn in filenames[first_idx:last_idx+1]]},\n",
    "#                     exclude_nodes=exclude_nodes,\n",
    "#                     argument_type='list2')\n",
    "\n",
    "# print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Aligned Masks (new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned thumbnails to local machine.\n",
    "- Run `mask_editing_gui.py`. Draw initial contours. Upload `init_snake_contours.pkl` to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_from_s3(DataManager.get_image_dir(stack=stack, version='aligned_tif', resol='thumbnail'), is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v5.py')\n",
    "\n",
    "output_dir = create_if_not_exists(DataManager.get_auto_submask_rootdir_filepath(stack=stack))\n",
    "! rm -rf {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_snake_contours_fp = DataManager.get_initial_snake_contours_filepath(stack=stack)\n",
    "download_from_s3(init_snake_contours_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 382.931476116 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(init_snake_contours_fp)s --min_size 500 --default_channel 1' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'init_snake_contours_fp': init_snake_contours_fp},\n",
    "                kwargs_list=dict(filenames=valid_filenames),\n",
    "                argument_type='list2',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v4.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_submasks'))\n",
    "! rm -f output_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wait for SGE to know all nodes (timeout in 300 seconds)...\n",
      "All nodes are ready.\n",
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 403.646880865 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "wait_num_nodes(16)\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %(input_dir)s \\'%%(filenames)s\\' %(output_dir)s --border_dissim_percentile %(border_dissim_percentile)d --min_size %(min_size)d' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'border_dissim_percentile': DEFAULT_BORDER_DISSIMILARITY_PERCENTILE,\n",
    "                'min_size': DEFAULT_MINSIZE},\n",
    "                kwargs_list=dict(filenames=valid_filenames),\n",
    "                exclude_nodes=[33],\n",
    "                argument_type='list2',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_submasks s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_submasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- download `submasks/` to local machine\n",
    "- review them in GUI\n",
    "- generate `submasks_modified/`, `masks/`, `submasks_finalDecisions.txt`, upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD594/MD594_masks && mkdir -p /shared/CSHL_data_processed/MD594\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks /shared/CSHL_data_processed/MD594/MD594_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "1.87 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(input_dir),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_masks_alignedTo_' + anchor_fn)\n",
    "execute_command('rm -rf ' + output_dir)\n",
    "\n",
    "transforms_to_anchor = load_pickle(DataManager.get_transforms_filename(stack=stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warping thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 1 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 76.2961359024 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'warping thumbnail mask...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s %(output_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 black' % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir},\n",
    "                kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                            'filename': fn + '_mask.png',\n",
    "                            'output_fn': fn + '_mask_alignedTo_' + anchor_fn + '.png'}\n",
    "                            for fn in valid_filenames],\n",
    "                argument_type='single',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172 s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.42 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD658'\n",
    "\n",
    "download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "w = xmax + 1 - xmin\n",
    "h = ymax + 1 - ymin\n",
    "x = xmin\n",
    "y = ymin\n",
    "first_fn = sections_to_filenames[first_sec]\n",
    "last_fn = sections_to_filenames[last_sec]\n",
    "first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped\n",
      "mkdir -p /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "input_dir = DataManager.get_mask_dirpath(stack=stack, version='aligned')\n",
    "download_from_s3_to_ec2(input_dir, is_dir=True)\n",
    "\n",
    "output_dir = DataManager.get_mask_dirpath(stack=stack, version='aligned_cropped')\n",
    "\n",
    "execute_command('rm -rf ' + output_dir);\n",
    "execute_command('mkdir -p ' + output_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail mask..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 623x492+563+65 -write \"/shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped/%[filename:name]_cropped.png\" /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks/*.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 31.315031 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail mask...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.png\" %(input_dir)s/*.png' % \\\n",
    "    {'stack': stack,\n",
    "    'input_dir': input_dir,\n",
    "    'output_dir': output_dir,\n",
    "    'w':xmax+1-xmin, 'h':ymax+1-ymin, 'x':xmin, 'y':ymin})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 70s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(output_dir, is_dir=True)\n",
    "# transfer_data_synced(relative_to_ec2(output_dir),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Run `extract_test_features_cnn.ipynb` on workstation.\n",
    "- Upload to extracted features to S3.\n",
    "- Continue with `learning/pipeline_aws.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
