{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for AWS compute node\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.environ['REPO_DIR'], 'utilities'))\n",
    "from utilities2015 import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "from distributed_utilities import *\n",
    "from preprocess_utilities import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After receiving data of a new stack, put images and macros in corresponding folder.\n",
    "- Add the stack name to proper variables in `metadata.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb_fmt = 'png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use GUI, quality check and sort images.\n",
    "- Upload `sorted_filenames.txt` to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-rawdata/CSHL_data/MD635 /shared/CSHL_data/MD635 --exclude \"*\" --include \"*.png\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "4.51 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack), \n",
    "                     from_hostname='s3raw', to_hostname='ec2', is_dir=True, include_only='*.'+tb_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_sorted_filenames.txt /shared/CSHL_data_processed/MD635/MD635_sorted_filenames.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.56 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_sorted_filenames.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'align_consecutive_v2.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD635/MD635_elastix_output': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r $output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Align...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 100.961234093 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Align...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s %(input_dir)s %(output_dir)s \\'%%(kwargs_str)s\\' %(fmt)s\" % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'fmt': tb_fmt},\n",
    "                kwargs_list=[{'prev_fn': valid_filenames[i-1], 'curr_fn': valid_filenames[i]} for i in range(1, len(valid_filenames))],\n",
    "                argument_type='list',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 252 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635/MD635_elastix_output s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_elastix_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "21.62 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/shared/CSHL_data_processed/MD635/MD635_elastix_output/MD635-F1-2016.05.18-16.23.55_MD635_2_0002_to_MD635-F1-2016.05.18-16.23.55_MD635_1_0001/elastix.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d03adcee9cdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprev_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcurr_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_fn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_to_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprev_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'elastix.log'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final metric value  = (.*?)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/shared/CSHL_data_processed/MD635/MD635_elastix_output/MD635-F1-2016.05.18-16.23.55_MD635_2_0002_to_MD635-F1-2016.05.18-16.23.55_MD635_1_0001/elastix.log'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "final_metric = {}\n",
    "for i in range(1, len(valid_filenames)):\n",
    "    prev_fn = valid_filenames[i-1]\n",
    "    curr_fn = valid_filenames[i]\n",
    "    with open(os.path.join(output_dir, curr_fn + '_to_' + prev_fn, 'elastix.log'), 'r') as f:\n",
    "        t = f.read()\n",
    "        g = re.search(\"Final metric value  = (.*?)\\n\", t)\n",
    "#         final_metric[(curr_fn, prev_fn)] = -float(g.groups()[0])\n",
    "        final_metric[i] = float(g.groups()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJsAAACqCAYAAAAKnk4GAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkcoo2CQiIiIiIiIiIpX5/wGBs7+d/V+3hAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe089c5bbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "metric_arr = np.array(final_metric.values())\n",
    "plt.figure(figsize=(20,2));\n",
    "plt.ylim([-1, metric_arr.max()+.1]);\n",
    "plt.stem(metric_arr);\n",
    "plt.title('Mutual information of pairwise registration');\n",
    "plt.yticks(np.arange(-1, metric_arr.max()+.1, 0.1));\n",
    "plt.xlabel('Image index');\n",
    "plt.ylabel('Mutual info');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst pair: MD635-F55-2016.05.19-05.55.53_MD635_2_0164\n"
     ]
    }
   ],
   "source": [
    "print 'worst pair:', valid_filenames[np.argmin(final_metric.values())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- download `elastix_output/` to local machine, edit consecutive transforms in local GUI, generate `custom_transforms/` to S3, upload to S3.\n",
    "- determine anchor image, upload `anchor.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_elastix_output && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_elastix_output /shared/CSHL_data_processed/MD635/MD635_elastix_output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "24.13 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_elastix_output'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_custom_transforms && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_custom_transforms /shared/CSHL_data_processed/MD635/MD635_custom_transforms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "1.62 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_custom_transforms'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_anchor.txt && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_anchor.txt /shared/CSHL_data_processed/MD635/MD635_anchor.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.44 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_anchor.txt'), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'compose_transform_thumbnail_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_elastix_output')\n",
    "output_fn = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "                                                dict(stack=stack, anchor_fn=anchor_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -f {output_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Composing transform...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "13 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 10.1481249332 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Composing transform...'\n",
    "\n",
    "run_distributed(\"%(script)s %(stack)s %(input_dir)s \\'%%(kwargs_str)s\\' %(anchor_idx)d %(output_fn)s\" % \\\n",
    "            {'stack': stack,\n",
    "            'script': script,\n",
    "            'input_dir': input_dir,\n",
    "            'anchor_idx': valid_filenames.index(anchor_fn),\n",
    "            'output_fn': output_fn},\n",
    "            kwargs_list=[{'filenames': valid_filenames}],\n",
    "            argument_type='list')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635 s3://mousebrainatlas-data/CSHL_data_processed/MD635 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "1.22 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='ec2', to_hostname='s3', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD635 /shared/CSHL_data_processed/MD635 --exclude \"*\" --include \"*.pkl\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.92 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack), \n",
    "                     from_hostname='s3', to_hostname='ec2', is_dir=True, include_only='*.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "out_dir = os.path.join(DATA_DIR, stack, stack + '_thumbnail_alignedTo_' + anchor_fn)\n",
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -rf $out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warping...\n",
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "13 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 213.944781065 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Warping...'\n",
    "\n",
    "# transforms_filename = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_%(anchor_fn)s.pkl' % \\\n",
    "#                                    dict(stack=stack, anchor_fn=anchor_fn))\n",
    "# transforms_to_anchor = pickle.load(open(transforms_filename, 'r'))\n",
    "\n",
    "transforms_to_anchor = DataManager.load_transforms(stack=stack, downsample_factor=32, use_inverse=False)\n",
    "\n",
    "if pad_bg_color == 'auto':\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s %(out_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 %%(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir\n",
    "                    },\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "                                'output_fn': fn + '_thumbnail_alignedTo_' + anchor_fn + '.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8)\n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s %(out_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 %(pad_bg_color)s' % \\\n",
    "                    {'script': script,\n",
    "                    'stack': stack,\n",
    "                    'input_dir': input_dir,\n",
    "                    'out_dir': out_dir,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                                'filename': fn + '.' + tb_fmt,\n",
    "                                'output_fn': fn + '_thumbnail_alignedTo_' + anchor_fn + '.tif'}\n",
    "                                for fn in valid_filenames],\n",
    "                    argument_type='single',\n",
    "                   jobs_per_node=8)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 300 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188 s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "4.33 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned images to local. In GUI, check alignment correctness.\n",
    "- Place cropbox. Upload `cropbox.txt` to S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt && mkdir -p /shared/CSHL_data_processed/MD635\n",
      "aws s3 cp s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt /shared/CSHL_data_processed/MD635/MD635_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropbox.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "0.45 seconds.\n"
     ]
    }
   ],
   "source": [
    "download_from_s3(DataManager.get_cropbox_filename(stack), redownload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "w = xmax + 1 - xmin\n",
    "h = ymax + 1 - ymin\n",
    "x = xmin\n",
    "y = ymin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_fn = sections_to_filenames[first_sec]\n",
    "last_fn = sections_to_filenames[last_sec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir -p /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s\" % \\\n",
    "                           {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "output_dir = os.path.join(DATA_DIR, stack, \"%(stack)s_thumbnail_alignedTo_%(anchor_fn)s_cropped\" % \\\n",
    "                           {'stack': stack, 'anchor_fn': anchor_fn})\n",
    "\n",
    "execute_command('mkdir -p ' + output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 685x448+659+308 -write \"/shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped/%[filename:name]_cropped.tif\" /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188/*.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 34.986666 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.tif\" %(input_dir)s/*.tif' % \\\n",
    "    {'input_dir': input_dir,\n",
    "     'output_dir': output_dir,\n",
    "    'w':w, 'h':h, 'x':x, 'y':y})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 100 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD635/MD635_thumbnail_alignedTo_MD635-F63-2016.05.19-08.39.03_MD635_2_0188_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.58 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_thumbnail_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand lossless JP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data', stack),\n",
    "                    from_hostname='s3raw',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True,\n",
    "                    include_only='*_lossless.jp2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_lossless_tif'))\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "\n",
    "# filenames_to_expand = [fn for fn in filenames[first_idx:last_idx+1] if not os.path.exists(os.path.join(input_dir, fn + '_lossless.tif'))]\n",
    "\n",
    "filenames_to_expand = [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                       if not os.path.exists(os.path.join(input_dir, fn + '_lossless.tif'))]\n",
    "\n",
    "run_distributed('export LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH; %(kdu_bin)s -i %(input_dir)s/%%(fn)s_lossless.jp2 -o %(output_dir)s/%%(fn)s_lossless.tif' % \\\n",
    "                {'kdu_bin': KDU_EXPAND_BIN,\n",
    "                 'output_dir': output_dir,\n",
    "                'input_dir': input_dir},\n",
    "                kwargs_list={'fn': filenames_to_expand},\n",
    "                argument_type='single',\n",
    "               cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) # 6000s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warping and cropping lossless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD585/MD585_lossless_tif && mkdir -p /shared/CSHL_data_processed/MD585\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD585/MD585_lossless_tif /shared/CSHL_data_processed/MD585/MD585_lossless_tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3079.07781506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3079.08 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_tif'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)\n",
    "# 3000 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_filepath = os.path.join(DATA_DIR, stack, '%(stack)s_transformsTo_anchor.pkl' % {'stack':stack})\n",
    "# tfs = pickle.load(open(tf_filepath, 'r'))\n",
    "# Note that the index from trasform pickle file starts at 0, BUT the .._renamed folder index starts at 1.#\n",
    "\n",
    "tfs = DataManager.load_transforms(stack=stack)\n",
    "\n",
    "lossless_tif_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_tif')\n",
    "lossless_aligned_cropped_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "\n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -r {lossless_aligned_cropped_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if stack in all_nissl_stacks:\n",
    "    pad_bg_color = 'white'\n",
    "else:\n",
    "    pad_bg_color = 'auto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('warping and cropping lossless...')\n",
    "\n",
    "# wait_num_nodes(16)\n",
    "                   \n",
    "if pad_bg_color == 'auto':\n",
    "    # If alternating, then black padding for F sections, white padding for N sections.\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif',\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "else:\n",
    "    run_distributed(command='%(script_path)s %(stack)s %(lossless_tif_dir)s %(lossless_aligned_cropped_dir)s %%(transform)s %%(filename)s %%(output_fn)s lossless %(x)d %(y)d %(w)d %(h)d %(pad_bg_color)s'%\\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'lossless_tif_dir': lossless_tif_dir,\n",
    "                    'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                    'x': x,\n",
    "                    'y': y,\n",
    "                    'w': w,\n",
    "                    'h': h,\n",
    "                    'pad_bg_color': pad_bg_color},\n",
    "                    kwargs_list=[{'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'filename': fn + '_lossless.tif',\n",
    "                                'output_fn': fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'}\n",
    "                                for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]],\n",
    "#                                  for fn in valid_filenames[first_idx_among_valid:first_idx_among_valid+16]],\n",
    "                    argument_type='single',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=4)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4140 seconds (AWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "1064.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True) \n",
    "# 512 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand and Crop together (use /scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD635'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfs = DataManager.load_transforms(stack=stack, downsample_factor=32, use_inverse=False)\n",
    "anchor_fn = metadata_cache['anchor_fn'][stack]\n",
    "xmin, xmax, ymin, ymax = metadata_cache['cropbox'][stack]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "expanding...Child returned 0\n",
      "13 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "Child returned 0\n",
      "13 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 4222.634601 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('expanding...')\n",
    "\n",
    "run_distributed('rm -rf /scratch/*', argument_type='single')\n",
    "\n",
    "raw_jp2_dir = DataManager.get_image_dir(stack=stack, resol='lossless', version='original_jp2', raw_data_dir='/scratch/CSHL_data')\n",
    "lossless_tif_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, resol='lossless', version='uncropped_tif', data_dir='/scratch/CSHL_data_processed'))\n",
    "lossless_aligned_cropped_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, resol='lossless', version='cropped', data_dir='/scratch/CSHL_data_processed'))\n",
    "\n",
    "warp_crop_script_fp = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v3.py')\n",
    "\n",
    "run_distributed('aws s3 cp s3://mousebrainatlas-rawdata/CSHL_data/%(stack)s/%%(fn)s_lossless.jp2 %(raw_jp2_dir)s/ && \\\n",
    "mkdir -p %(lossless_tif_dir)s && \\\n",
    "LD_LIBRARY_PATH=/home/ubuntu/KDU79_Demo_Apps_for_Linux-x86-64_170108:$LD_LIBRARY_PATH %(kdu_bin)s -i %(raw_jp2_dir)s/%%(fn)s_lossless.jp2 -o %(lossless_tif_dir)s/%%(fn)s_lossless.tif && \\\n",
    "mkdir -p %(lossless_aligned_cropped_dir)s && \\\n",
    "%(script_path)s %(stack)s %%(lossless_tif_fp)s %%(lossless_aligned_cropped_fp)s %%(transform)s lossless %(x)d %(y)d %(w)d %(h)d %%(pad_bg_color)s && \\\n",
    "aws s3 cp %%(lossless_aligned_cropped_fp)s s3://mousebrainatlas-data/%(s3_dest_dir)s/' % \\\n",
    "                {'stack': stack,\n",
    "                'kdu_bin': KDU_EXPAND_BIN,\n",
    "                'raw_jp2_dir': raw_jp2_dir,\n",
    "                'script_path': warp_crop_script_fp,\n",
    "                'lossless_tif_dir': lossless_tif_dir,\n",
    "                'lossless_aligned_cropped_dir': lossless_aligned_cropped_dir,\n",
    "                 's3_dest_dir': relative_to_local(lossless_aligned_cropped_dir, local_root='/scratch'),\n",
    "                'x': xmin,\n",
    "                'y': ymin,\n",
    "                'w': xmax + 1 - xmin,\n",
    "                'h': ymax + 1 - ymin},\n",
    "                kwargs_list=[{'fn': fn, \n",
    "                              'transform': ','.join(map(str, tfs[fn].flatten())),\n",
    "                                'lossless_tif_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='uncropped_tif', data_dir='/scratch/CSHL_data_processed'),\n",
    "                                'lossless_aligned_cropped_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped', data_dir='/scratch/CSHL_data_processed'),\n",
    "                                'pad_bg_color': 'black' if fn.split('-')[1][0] == 'F' else 'white'}\n",
    "                             for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 4222 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contrast stretch Neurotrace, convert to 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack = 'MD642'\n",
    "\n",
    "# download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "# _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "\n",
    "# valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "\n",
    "# _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "# first_fn = sections_to_filenames[first_sec]\n",
    "# last_fn = sections_to_filenames[last_sec]\n",
    "# first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "# last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Contrast stretch neurotrace images...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s %(imin)d %(imax)d'%\\\n",
    "#                     {'script_path': script_fp,\n",
    "#                      'imin': 0,\n",
    "#                      'imax': 400\n",
    "#                     },\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif')}\n",
    "#                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched'),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True) #700s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for full nissl stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1136.945903 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_nissl_stacks:\n",
    "for stack in ['MD595']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                    },\n",
    "                        argument_type='list2')\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to nissl-like grayscale - for alternating nissl/neurotrace stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1098.395771 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 2371.7916441 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1008.132029 seconds\n",
      "Convert nissl images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1053.684169 seconds\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 3785.25425816 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1298.919096 seconds\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD653', 'MD657']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Convert Nissl images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert nissl images to gray...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': \n",
    "                                     [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'N']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 900 seconds.\n",
    "    \n",
    "    # Match intensity profile between Neurotrace Blue to Nissl\n",
    "\n",
    "    t = time.time()\n",
    "    sys.stderr.write('Match intensity profile between Neurotrace and Nissl...')\n",
    "\n",
    "    filename_pairs = []\n",
    "    l = valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+d], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-d], l[i]))\n",
    "                    break\n",
    "            \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' ' % \\\n",
    "                    {'script_path': script_fp,\n",
    "                    'stack': stack,\n",
    "                    'filename_pairs': filename_pairs},\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds. \n",
    "    # TODO: One node is especially slow, investigate.\n",
    "    \n",
    "    # Convert Neurotrace images to grayscale\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Convert neurotrace images to gray...')\n",
    "    \n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                        {'script_path': script_fp, \n",
    "                        'stack': stack},\n",
    "                        kwargs_list={'filenames': [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                      if fn.split('-')[1][0] == 'F']\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrast stretch all nissl-like grayscale images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 402.651489 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 302.190462 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 593.845553 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 372.498169 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 151.272419 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 337.307819 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 236.764556 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 186.493343 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 538.482468 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "Contrast stretch nissl grayscale image...Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 508.330036 seconds\n",
      "Child returned 0\n",
      "16 nodes requested, 16 nodes available...Continuing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "for stack in ['MD590',\n",
    " 'MD591',\n",
    " 'MD592',\n",
    " 'MD593',\n",
    " 'MD594',\n",
    " 'MD595',\n",
    " 'MD598',\n",
    " 'MD599',\n",
    " 'MD602',\n",
    " 'MD603']:\n",
    "# for stack in ['MD589']:\n",
    "    \n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    \n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "\n",
    "    _, _, _, _, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "\n",
    "    # Contrast stretch nissl grayscale image\n",
    "    \n",
    "    t = time.time()\n",
    "    sys.stderr.write('Contrast stretch nissl grayscale image...')\n",
    "\n",
    "    script_fp = os.path.join(REPO_DIR, 'preprocess', 'stretch_contrast_image.py')\n",
    "\n",
    "    run_distributed(command='ROOT_DIR=/scratch/ %(script_path)s %(stack)s \\'%%(filenames)s\\' 23 160'%\\\n",
    "                        {'script_path': script_fp, 'stack': stack},\n",
    "                        kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                    },\n",
    "                        argument_type='list2',\n",
    "                       cluster_size=16)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    sys.stderr.write('done in %f seconds\\n' % (time.time() - t))\n",
    "        \n",
    "    run_distributed(command='rm -r /scratch/*',\n",
    "                        argument_type='single',\n",
    "                       cluster_size=16)\n",
    "    wait_qsub_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Convert Nissl images to grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert nissl images to gray...')\n",
    "               \n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                    {'script_path': script_fp, 'stack': stack},\n",
    "#                     kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]},\n",
    "                    kwargs_list={'filenames':\n",
    "                                 [fn for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "                                  if fn.split('-')[1][0] == 'N']},\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert contrast-stretched Neurotrace images to grayscale\n",
    "\n",
    "# script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace.py')\n",
    "# in_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "# out_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray')\n",
    "# ! mkdir -p {out_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 75.575123 seconds\n"
     ]
    }
   ],
   "source": [
    "# t = time.time()\n",
    "# sys.stderr.write('Convert neurotrace images to gray...')\n",
    "               \n",
    "# run_distributed(command='%(script_path)s %%(in_fn)s %%(out_fn)s'%\\\n",
    "#                     {'script_path': script_fp},\n",
    "#                     kwargs_list=[{'in_fn': os.path.join(in_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif'),\n",
    "#                                 'out_fn': os.path.join(out_dir, fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched_blueasgray.tif')}\n",
    "# #                                 for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "#                                  for fn in valid_filenames[150:151]\n",
    "#                                 if fn.split('-')[1][0] == 'F'],\n",
    "#                     argument_type='single',\n",
    "#                    cluster_size=16)\n",
    "\n",
    "# wait_qsub_complete()\n",
    "\n",
    "# sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 2500 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Match intensity profile between Neurotrace Blue to Nissl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match intensity profile between Neurotrace and Nissl..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "# for stack in all_alt_nissl_ntb_stacks + all_alt_nissl_tracing_stacks:\n",
    "for stack in ['MD642']:\n",
    "\n",
    "    download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "    _, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "    valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "    download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "    anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "    download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "    xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "    w = xmax + 1 - xmin\n",
    "    h = ymax + 1 - ymin\n",
    "    x = xmin\n",
    "    y = ymin\n",
    "    first_fn = sections_to_filenames[first_sec]\n",
    "    last_fn = sections_to_filenames[last_sec]\n",
    "    first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "    last_idx_among_valid = valid_filenames.index(last_fn)\n",
    "    \n",
    "    #########################################################\n",
    "\n",
    "    t = time.time()\n",
    "    print 'Match intensity profile between Neurotrace and Nissl...',\n",
    "\n",
    "    \n",
    "    filename_pairs = []\n",
    "    l = valid_filenames[first_idx_among_valid:last_idx_among_valid+1]\n",
    "    for i, fn in enumerate(l):\n",
    "        if l[i].split('-')[1][0] == 'F':\n",
    "            for d in range(1, 99):\n",
    "                if i+d < len(l) and l[i+d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i+j], l[i]))\n",
    "                    break\n",
    "                if i-d >= 0 and l[i-d].split('-')[1][0] == 'N':\n",
    "                    filename_pairs.append((l[i-j], l[i]))\n",
    "                    break\n",
    "    \n",
    "    script = os.path.join(REPO_DIR, 'preprocess', 'match_intensity_profile.py')\n",
    "    \n",
    "    run_distributed(command='%(script_path)s %(stack)s \\'%%(filename_pairs)s\\' ' % \\\n",
    "                    {'script_path': script,\n",
    "                    'stack': stack,\n",
    "                    'filename_pairs': filename_pairs},\n",
    "                    kwargs_list=dict(filename_pairs=filename_pairs),\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16,\n",
    "                   jobs_per_node=1)\n",
    "\n",
    "    wait_qsub_complete()\n",
    "\n",
    "    print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Convert Neurotrace images to grayscale (New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'convert_grayscale_neurotrace_v2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]:\n",
    "#     download_from_s3(DataManager.get_image_filepath(stack=stack, version='cropped', resol='lossless', fn=fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = create_if_not_exists(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'));\n",
    "! rm -r {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convert neurotrace images to gray...16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n",
      "qsub returned.\n",
      "done in 1183.526723 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('Convert neurotrace images to gray...')\n",
    "               \n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\''%\\\n",
    "                    {'script_path': script_fp, \n",
    "                    'stack': stack},\n",
    "#                     kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1]},\n",
    "                    kwargs_list={'filenames': valid_filenames[first_idx_among_valid:last_idx_among_valid+1][1:2]},\n",
    "                    argument_type='list2',\n",
    "                   cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_gray s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_gray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "328.34 seconds.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(DataManager.get_image_dir(stack=stack, version='cropped_gray', resol='lossless'), is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped && mkdir -p /shared/CSHL_data_processed/MD589\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped /shared/CSHL_data_processed/MD589/MD589_lossless_alignedTo_MD589-IHC31-2015.07.30-23.26.22_MD589_1_0091_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped'),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped')\n",
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed/*': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "! rm -r {output_dir}/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "if stack in all_nissl_stacks:\n",
    "    \n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=output_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1]]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16,\n",
    "                   jobs_per_node=16)\n",
    "    \n",
    "else:\n",
    "    run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                    dict(script=script_fp,\n",
    "                         stack=stack,\n",
    "                         input_dir=input_dir,\n",
    "                         output_compressed_dir=output_dir),\n",
    "                        kwargs_list={'input_filenames': \n",
    "                                     [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' \n",
    "                                      for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                      if fn.split('-')[1].startswith('N')]},\n",
    "                        argument_type='list2',\n",
    "                         cluster_size=16,\n",
    "                       jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "    \n",
    "print 'done in', time.time() - t, 'seconds' # 765 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "36.94 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate JPEG for neurotrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'generate_other_versions_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched')\n",
    "out_jpeg_dir = os.path.join(DATA_DIR, stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed image..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 18 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed image...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_compressed_dir %(output_compressed_dir)s' % \\\n",
    "                dict(script=script_fp,\n",
    "                     stack=stack,\n",
    "                     input_dir=input_dir,\n",
    "                     output_compressed_dir=out_jpeg_dir),\n",
    "                    kwargs_list={'input_filenames': \n",
    "                                 [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped_contrast_stretched.tif' \n",
    "                                  for fn in valid_filenames[first_idx_among_valid:last_idx_among_valid+1] \n",
    "                                  if fn.split('-')[1].startswith('F')]},\n",
    "                    argument_type='list2',\n",
    "                    cluster_size=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_lossless_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_cropped_compressed --exclude \"*\" --include \"*contrast_stretched*.jpg\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "31.04 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(os.path.join('CSHL_data_processed', stack, stack + '_lossless_alignedTo_' + anchor_fn + '_cropped_compressed'),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True,\n",
    "                    include_only='*contrast_stretched*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# print 'Generating saturation image...',\n",
    "\n",
    "# run_distributed4('%(script)s %(stack)s %(input_dir)s \\'%%(input_filenames)s\\' --output_saturation_dir %(output_saturation_dir)s' % \\\n",
    "#                 dict(script=script_fp,\n",
    "#                      stack=stack,\n",
    "#                      input_dir=input_dir,\n",
    "#                      output_saturation_dir=out_sat_dir,\n",
    "#                      kwargs_list={'input_filenames': [fn + '_lossless_alignedTo_' + anchor_fn + '_cropped.tif' for fn in filenames[first_idx:last_idx+1]]},\n",
    "#                     exclude_nodes=exclude_nodes,\n",
    "#                     argument_type='list2')\n",
    "\n",
    "# print 'done in', time.time() - t, 'seconds'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress nissl-like gray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD652'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating compressed images... rm -f ~/stderr_*; rm -f ~/stdout_*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1QFYAQIDV4KEM capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 13 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 303.044512033 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating compressed images...',\n",
    "\n",
    "script_fp = os.path.join(REPO_DIR, 'preprocess', 'compress_as_jpeg.py')\n",
    "\n",
    "run_distributed('rm -r /scratch/*', \n",
    "                argument_type='single')\n",
    "\n",
    "run_distributed('ROOT_DIR=/scratch/ %(script)s %%(input_fp)s %%(output_fp)s' % \\\n",
    "                {'script': script_fp},\n",
    "                kwargs_list=[{'input_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray', data_dir='/scratch/CSHL_data_processed'),\n",
    "                              'output_fp': DataManager.get_image_filepath(stack=stack, fn=fn, resol='lossless', version='cropped_gray_jpeg',data_dir='/scratch/CSHL_data_processed')}\n",
    "                             for fn in metadata_cache['valid_filenames'][stack]],\n",
    "                    argument_type='single')\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # for one stack 300 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Aligned Masks (new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download aligned thumbnails to local machine.\n",
    "- Run `mask_editing_gui.py`. Draw initial contours. Upload `init_snake_contours.pkl` to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_from_s3(DataManager.get_image_dir(stack=stack, version='aligned_tif', resol='thumbnail'), is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v5.py')\n",
    "\n",
    "output_dir = create_if_not_exists(DataManager.get_auto_submask_rootdir_filepath(stack=stack))\n",
    "! rm -rf {output_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init_snake_contours_fp = DataManager.get_initial_snake_contours_filepath(stack=stack)\n",
    "download_from_s3(init_snake_contours_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " done in 382.931476116 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s \\'%%(filenames)s\\' %(init_snake_contours_fp)s --min_size 500 --default_channel 1' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'init_snake_contours_fp': init_snake_contours_fp},\n",
    "                kwargs_list=dict(filenames=valid_filenames),\n",
    "                argument_type='list2',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'generate_thumbnail_masks_v4.py')\n",
    "input_dir = os.path.join(RAW_DATA_DIR, stack)\n",
    "output_dir = create_if_not_exists(os.path.join(DATA_DIR, stack, stack + '_submasks'))\n",
    "! rm -f output_dir/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Wait for SGE to know all nodes (timeout in 300 seconds)...\n",
      "All nodes are ready.\n",
      "16 nodes requested, 16 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 403.646880865 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'Generating thumbnail mask...',\n",
    "\n",
    "wait_num_nodes(16)\n",
    "\n",
    "run_distributed(command='%(script_path)s %(stack)s %(input_dir)s \\'%%(filenames)s\\' %(output_dir)s --border_dissim_percentile %(border_dissim_percentile)d --min_size %(min_size)d' % \\\n",
    "                {'script_path': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir,\n",
    "                'border_dissim_percentile': DEFAULT_BORDER_DISSIMILARITY_PERCENTILE,\n",
    "                'min_size': DEFAULT_MINSIZE},\n",
    "                kwargs_list=dict(filenames=valid_filenames),\n",
    "                exclude_nodes=[33],\n",
    "                argument_type='list2',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=1)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 300s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_submasks s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_submasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.72 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- download `submasks/` to local machine\n",
    "- review them in GUI\n",
    "- generate `submasks_modified/`, `masks/`, `submasks_finalDecisions.txt`, upload to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warp Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = os.path.join(REPO_DIR, 'preprocess', 'warp_crop_IM_v2.py')\n",
    "input_dir = os.path.join(DATA_DIR, stack, stack + '_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD594/MD594_masks && mkdir -p /shared/CSHL_data_processed/MD594\n",
      "aws s3 cp --recursive s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks /shared/CSHL_data_processed/MD594/MD594_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n",
      "1.87 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(input_dir),\n",
    "                    from_hostname='s3',\n",
    "                    to_hostname='ec2',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "output_dir = os.path.join(DATA_DIR, stack, stack + '_masks_alignedTo_' + anchor_fn)\n",
    "execute_command('rm -rf ' + output_dir)\n",
    "\n",
    "transforms_to_anchor = load_pickle(DataManager.get_transforms_filename(stack=stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warping thumbnail mask... Setting autoscaling group cfncluster-yuncongCluster-ComputeFleet-1LFRACYHLTNL8 capaticy to 16...it may take more than 5 minutes for SGE to know new hosts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16 nodes requested, 1 nodes available...Continuing\n",
      "Jobs submitted. Use wait_qsub_complete() to check if they finish.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 76.2961359024 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsub returned.\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "print 'warping thumbnail mask...',\n",
    "\n",
    "run_distributed('%(script)s %(stack)s %(input_dir)s %(output_dir)s %%(transform)s %%(filename)s %%(output_fn)s thumbnail 0 0 2000 1500 black' % \\\n",
    "                {'script': script,\n",
    "                'stack': stack,\n",
    "                'input_dir': input_dir,\n",
    "                'output_dir': output_dir},\n",
    "                kwargs_list=[{'transform': ','.join(map(str, transforms_to_anchor[fn].flatten())),\n",
    "                            'filename': fn + '_mask.png',\n",
    "                            'output_fn': fn + '_mask_alignedTo_' + anchor_fn + '.png'}\n",
    "                            for fn in valid_filenames],\n",
    "                argument_type='single',\n",
    "               cluster_size=16,\n",
    "               jobs_per_node=16)\n",
    "\n",
    "wait_qsub_complete()\n",
    "\n",
    "print 'done in', time.time() - t, 'seconds' # 20 seconds (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172 s3://mousebrainatlas-data/CSHL_data_processed/MD594/MD594_masks_alignedTo_MD594-IHC58-2015.08.26-18.48.50_MD594_1_0172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "3.42 seconds.\n"
     ]
    }
   ],
   "source": [
    "transfer_data_synced(relative_to_ec2(output_dir),\n",
    "                    from_hostname='ec2',\n",
    "                    to_hostname='s3',\n",
    "                    is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Thumbnail Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = 'MD658'\n",
    "\n",
    "download_from_s3(DataManager.get_sorted_filenames_filename(stack=stack))\n",
    "_, sections_to_filenames = DataManager.load_sorted_filenames(stack=stack)\n",
    "valid_filenames = [fn for fn in sections_to_filenames.values() if not is_invalid(fn=fn)]\n",
    "download_from_s3(DataManager.get_anchor_filename_filename(stack=stack))\n",
    "anchor_fn = DataManager.load_anchor_filename(stack=stack)\n",
    "download_from_s3(DataManager.get_cropbox_filename(stack=stack))\n",
    "xmin, xmax, ymin, ymax, first_sec, last_sec = DataManager.load_cropbox(stack=stack)\n",
    "w = xmax + 1 - xmin\n",
    "h = ymax + 1 - ymin\n",
    "x = xmin\n",
    "y = ymin\n",
    "first_fn = sections_to_filenames[first_sec]\n",
    "last_fn = sections_to_filenames[last_sec]\n",
    "first_idx_among_valid = valid_filenames.index(first_fn)\n",
    "last_idx_among_valid = valid_filenames.index(last_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped\n",
      "mkdir -p /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "Child returned 0\n"
     ]
    }
   ],
   "source": [
    "input_dir = DataManager.get_mask_dirpath(stack=stack, version='aligned')\n",
    "download_from_s3_to_ec2(input_dir, is_dir=True)\n",
    "\n",
    "output_dir = DataManager.get_mask_dirpath(stack=stack, version='aligned_cropped')\n",
    "\n",
    "execute_command('rm -rf ' + output_dir);\n",
    "execute_command('mkdir -p ' + output_dir);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cropping thumbnail mask..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mogrify -set filename:name %t -crop 623x492+563+65 -write \"/shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped/%[filename:name]_cropped.png\" /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks/*.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "done in 31.315031 seconds\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "sys.stderr.write('cropping thumbnail mask...')\n",
    "\n",
    "execute_command('mogrify -set filename:name %%t -crop %(w)dx%(h)d+%(x)d+%(y)d -write \"%(output_dir)s/%%[filename:name]_cropped.png\" %(input_dir)s/*.png' % \\\n",
    "    {'stack': stack,\n",
    "    'input_dir': input_dir,\n",
    "    'output_dir': output_dir,\n",
    "    'w':xmax+1-xmin, 'h':ymax+1-ymin, 'x':xmin, 'y':ymin})\n",
    "\n",
    "sys.stderr.write('done in %f seconds\\n' % (time.time() - t)) # 70s (aws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws s3 cp --recursive /shared/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped s3://mousebrainatlas-data/CSHL_data_processed/MD658/MD658_alignedTo_MD658-N58-2017.03.31-19.59.31_MD658_2_0173_masks_cropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Child returned 0\n",
      "2.17 seconds.\n"
     ]
    }
   ],
   "source": [
    "upload_to_s3(output_dir, is_dir=True)\n",
    "# transfer_data_synced(relative_to_ec2(output_dir),\n",
    "#                     from_hostname='ec2',\n",
    "#                     to_hostname='s3',\n",
    "#                     is_dir=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Run `extract_test_features_cnn.ipynb` on workstation.\n",
    "- Upload to extracted features to S3.\n",
    "- Continue with `learning/pipeline_aws.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
