{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting environment for Gordon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No vtk\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.environ['REPO_DIR'] + '/utilities')\n",
    "from utilities2015 import *\n",
    "from registration_utilities import *\n",
    "from annotation_utilities import *\n",
    "from metadata import *\n",
    "from data_manager import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stack_fixed = 'MD603'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sample_scheme = 1\n",
    "global_transform_scheme = 1\n",
    "\n",
    "# stack_moving = 'atlas_on_MD589'\n",
    "stack_moving = 'atlasV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paired_structures = ['5N', '6N', '7N', '7n', 'Amb', 'LC', 'LRt', 'Pn', 'Tz', 'VLL', 'RMC', 'SNC', 'SNR', '3N', '4N',\n",
    "                    'Sp5I', 'Sp5O', 'Sp5C', 'PBG', '10N', 'VCA', 'VCP', 'DC']\n",
    "singular_structures = ['AP', '12N', 'RtTg', 'SC', 'IC']\n",
    "structures = paired_structures + singular_structures\n",
    "\n",
    "structures_sided = sum([[n] if n in singular_structures \n",
    "                        else [convert_to_left_name(n), convert_to_right_name(n)] \n",
    "                        for n in structures], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_to_name_fixed = {i+1: name for i, name in enumerate(sorted(structures))}\n",
    "name_to_label_fixed = {n:l for l, n in label_to_name_fixed.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# label_to_name_moving = {i+1: name for i, name in enumerate(sorted(structures) + sorted([s+'_surround' for s in structures]))}\n",
    "# name_to_label_moving = {n:l for l, n in label_to_name_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_to_name_moving = {i+1: name for i, name in enumerate(sorted(structures_sided) + sorted([s+'_surround' for s in structures_sided]))}\n",
    "name_to_label_moving = {n:l for l, n in label_to_name_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(421, 654, 399)\n",
      "float16\n"
     ]
    }
   ],
   "source": [
    "volume_fixed = {name_to_label_fixed[name]: DataManager.load_score_volume(stack=stack_fixed, label=name, downscale=32, train_sample_scheme=train_sample_scheme)\n",
    "               for name in structures}\n",
    "\n",
    "print volume_fixed.values()[0].shape\n",
    "print volume_fixed.values()[0].dtype\n",
    "\n",
    "# vol_fixed_xmin, vol_fixed_ymin, vol_fixed_zmin = (0,0,0)\n",
    "# vol_fixed_ymax, vol_fixed_xmax, vol_fixed_zmax = np.array(volume_fixed.values()[0].shape) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(342, 418, 371)\n",
      "float16\n"
     ]
    }
   ],
   "source": [
    "# volume_moving = {name_to_label_moving[name]: DataManager.load_score_volume(stack_moving, label=name, downscale=32)\n",
    "#                  for name in structures + [s+'_surround' for s in structures]}\n",
    "\n",
    "volume_moving = {name_to_label_moving[name]: DataManager.load_score_volume(stack=stack_moving, label=name, downscale=32, train_sample_scheme=None)\n",
    "               for name in structures_sided}\n",
    "\n",
    "print volume_moving.values()[0].shape\n",
    "print volume_moving.values()[0].dtype\n",
    "\n",
    "# vol_moving_xmin, vol_moving_ymin, vol_moving_zmin = (0,0,0)\n",
    "# vol_moving_ymax, vol_moving_xmax, vol_moving_zmax = np.array(volume_moving.values()[0].shape) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "volume_moving_structure_sizes = {l: np.count_nonzero(vol > 0) for l, vol in volume_moving.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_original_name(name):\n",
    "    return name.split('_')[0]\n",
    "\n",
    "labelIndexMap_m2f = {}\n",
    "for label_m, name_m in label_to_name_moving.iteritems():\n",
    "    labelIndexMap_m2f[label_m] = name_to_label_fixed[convert_to_original_name(name_m)]\n",
    "\n",
    "label_weights_m = {}\n",
    "for label_m, name_m in label_to_name_moving.iteritems():\n",
    "    if 'surround' in name_m:\n",
    "        label_weights_m[label_m] = 0\n",
    "    else:\n",
    "#         label_weights_m[label_m] = 1\n",
    "        label_weights_m[label_m] = np.minimum(1e5 / volume_moving_structure_sizes[label_m], 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligner = Aligner4(volume_fixed, volume_moving, labelIndexMap_m2f=labelIndexMap_m2f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aligner.set_centroid(centroid_m='volume_centroid', centroid_f='volume_centroid')\n",
    "# aligner.set_centroid(centroid_m='structure_centroid', centroid_f='centroid_m', indices_m=[name_to_label_moving['SNR_R']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_filepath_map_f = {ind_f: DataManager.get_score_volume_gradient_filepath_template(stack=stack_fixed, label=label_to_name_fixed[ind_f],\n",
    "                            downscale=32, train_sample_scheme=train_sample_scheme)\n",
    "                            for ind_m, ind_f in labelIndexMap_m2f.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "load gradient 1: 1.310661 seconds\n",
      "load gradient 2: 1.977060 seconds\n",
      "load gradient 3: 1.760638 seconds\n",
      "load gradient 4: 1.514809 seconds\n",
      "load gradient 5: 1.823989 seconds\n",
      "load gradient 6: 1.243615 seconds\n",
      "load gradient 7: 1.930981 seconds\n",
      "load gradient 8: 1.523559 seconds\n",
      "load gradient 9: 1.478452 seconds\n",
      "load gradient 10: 1.799599 seconds\n",
      "load gradient 11: 2.921514 seconds\n",
      "load gradient 12: 2.198878 seconds\n",
      "load gradient 13: 1.563735 seconds\n",
      "load gradient 14: 2.318128 seconds\n",
      "load gradient 15: 1.653548 seconds\n",
      "load gradient 16: 2.202204 seconds\n",
      "load gradient 17: 2.682532 seconds\n",
      "load gradient 18: 2.470826 seconds\n",
      "load gradient 19: 3.034634 seconds\n",
      "load gradient 20: 2.894266 seconds\n",
      "load gradient 21: 2.686151 seconds\n",
      "load gradient 22: 2.441745 seconds\n",
      "load gradient 23: 2.726368 seconds\n",
      "load gradient 24: 2.379899 seconds\n",
      "load gradient 25: 1.320701 seconds\n",
      "load gradient 26: 2.033009 seconds\n",
      "load gradient 27: 2.351011 seconds\n",
      "load gradient 28: 2.797821 seconds\n",
      "overall: 59.044498 seconds\n"
     ]
    }
   ],
   "source": [
    "aligner.load_gradient(gradient_filepath_map_f=gradient_filepath_map_f, indices_f=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regularization weights not set, default to 0.\n",
      "grid search: 5.833147 seconds\n",
      "-inf 0.916499\n",
      "grid search: 3.624322 seconds\n",
      "grid search: 3.332715 seconds\n",
      "grid search: 2.638975 seconds\n",
      "0.916499 0.977554\n",
      "grid search: 1.822301 seconds\n",
      "0.977554 1.005150\n",
      "grid search: 1.422947 seconds\n",
      "grid search: 1.123301 seconds\n",
      "1.005150 1.005823\n",
      "grid search: 1.022294 seconds\n",
      "1.005823 1.008513\n",
      "grid search: 0.720714 seconds\n",
      "1.008513 1.010285\n",
      "grid search: 0.616055 seconds\n",
      "grid search: 0.619479 seconds\n",
      "1.010285 1.012186\n",
      "grid search: 0.617445 seconds\n",
      "1.012186 1.013272\n",
      "grid search: 0.622824 seconds\n",
      "grid search: 0.618043 seconds\n",
      "grid search: 0.607561 seconds\n",
      "grid search: 0.598534 seconds\n",
      "grid search: 0.611199 seconds\n",
      "grid search: 0.611800 seconds\n",
      "grid search: 0.610994 seconds\n",
      "grid search: 0.603438 seconds\n",
      "grid search: 0.608207 seconds\n",
      "grid search: 0.606431 seconds\n",
      "grid search: 0.618916 seconds\n",
      "grid search: 0.617732 seconds\n",
      "grid search: 0.616751 seconds\n",
      "grid search: 0.611715 seconds\n",
      "grid search: 0.611705 seconds\n",
      "grid search: 0.610269 seconds\n",
      "grid search: 0.617803 seconds\n",
      "grid search: 0.616836 seconds\n",
      "iteration 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_best_upToNow [ 7.1690801   4.20344239 -7.17065361 -0.02057486]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "step: 2.55 seconds\n",
      "score: 1.013272\n",
      "iteration 1\n",
      "step: 2.54 seconds\n",
      "score: 0.988771\n",
      "iteration 2\n",
      "step: 2.53 seconds\n",
      "score: 1.069093\n",
      "iteration 3\n",
      "step: 2.52 seconds\n",
      "score: 1.060606\n",
      "iteration 4\n",
      "step: 2.53 seconds\n",
      "score: 1.114060\n",
      "iteration 5\n",
      "step: 2.52 seconds\n",
      "score: 1.074313\n",
      "iteration 6\n",
      "step: 2.52 seconds\n",
      "score: 1.100388\n",
      "iteration 7\n",
      "step: 2.52 seconds\n",
      "score: 1.183932\n",
      "iteration 8\n",
      "step: 2.53 seconds\n",
      "score: 1.133573\n",
      "iteration 9\n",
      "step: 2.52 seconds\n",
      "score: 1.146255\n",
      "iteration 10\n",
      "step: 2.52 seconds\n",
      "score: 1.258399\n",
      "iteration 11\n",
      "step: 2.52 seconds\n",
      "score: 1.270383\n",
      "iteration 12\n",
      "step: 2.53 seconds\n",
      "score: 1.273965\n",
      "iteration 13\n",
      "step: 2.52 seconds\n",
      "score: 1.271382\n",
      "iteration 14\n",
      "step: 2.53 seconds\n",
      "score: 1.280779\n",
      "iteration 15\n",
      "step: 2.53 seconds\n",
      "score: 1.236230\n",
      "iteration 16\n",
      "step: 2.53 seconds\n",
      "score: 1.282274\n",
      "iteration 17\n",
      "step: 2.53 seconds\n",
      "score: 1.229222\n",
      "iteration 18\n",
      "step: 2.54 seconds\n",
      "score: 1.290962\n",
      "iteration 19\n",
      "step: 2.53 seconds\n",
      "score: 1.282236\n",
      "iteration 20\n",
      "step: 2.54 seconds\n",
      "score: 1.305472\n",
      "iteration 21\n",
      "step: 2.53 seconds\n",
      "score: 1.297702\n",
      "iteration 22\n",
      "step: 2.53 seconds\n",
      "score: 1.314220\n",
      "iteration 23\n",
      "step: 2.53 seconds\n",
      "score: 1.310275\n",
      "iteration 24\n",
      "step: 2.54 seconds\n",
      "score: 1.319573\n",
      "iteration 25\n",
      "step: 2.53 seconds\n",
      "score: 1.318234\n",
      "iteration 26\n",
      "step: 2.54 seconds\n",
      "score: 1.323259\n",
      "iteration 27\n",
      "step: 2.53 seconds\n",
      "score: 1.321237\n",
      "iteration 28\n",
      "step: 2.54 seconds\n",
      "score: 1.323929\n",
      "iteration 29\n",
      "step: 2.53 seconds\n",
      "score: 1.322559\n",
      "iteration 30\n",
      "step: 2.54 seconds\n",
      "score: 1.326329\n",
      "iteration 31\n",
      "step: 2.53 seconds\n",
      "score: 1.324767\n",
      "iteration 32\n",
      "step: 2.54 seconds\n",
      "score: 1.326668\n",
      "iteration 33\n",
      "step: 2.53 seconds\n",
      "score: 1.323429\n",
      "iteration 34\n",
      "step: 2.54 seconds\n",
      "score: 1.326273\n",
      "iteration 35\n",
      "step: 2.53 seconds\n",
      "score: 1.322708\n",
      "iteration 36\n",
      "step: 2.54 seconds\n",
      "score: 1.326591\n",
      "iteration 37\n",
      "step: 2.53 seconds\n",
      "score: 1.323807\n",
      "iteration 38\n",
      "step: 2.54 seconds\n",
      "score: 1.327998\n",
      "iteration 39\n",
      "step: 2.53 seconds\n",
      "score: 1.325128\n",
      "iteration 40\n",
      "step: 2.53 seconds\n",
      "score: 1.329380\n",
      "iteration 41\n",
      "step: 2.53 seconds\n",
      "score: 1.327583\n",
      "iteration 42\n",
      "step: 2.54 seconds\n",
      "score: 1.330540\n",
      "iteration 43\n",
      "step: 2.53 seconds\n",
      "score: 1.329497\n",
      "iteration 44\n",
      "step: 2.54 seconds\n",
      "score: 1.331250\n",
      "iteration 45\n",
      "step: 2.53 seconds\n",
      "score: 1.330307\n",
      "iteration 46\n",
      "step: 2.54 seconds\n",
      "score: 1.331595\n",
      "iteration 47\n",
      "step: 2.53 seconds\n",
      "score: 1.330870\n",
      "iteration 48\n",
      "step: 2.53 seconds\n",
      "score: 1.332044\n",
      "iteration 49\n",
      "step: 2.53 seconds\n",
      "score: 1.331680\n",
      "iteration 50\n",
      "step: 2.53 seconds\n",
      "score: 1.332730\n",
      "iteration 51\n",
      "step: 2.53 seconds\n",
      "score: 1.332087\n",
      "iteration 52\n",
      "step: 2.53 seconds\n",
      "score: 1.333118\n",
      "iteration 53\n",
      "step: 2.53 seconds\n",
      "score: 1.332798\n",
      "iteration 54\n",
      "step: 2.53 seconds\n",
      "score: 1.333300\n",
      "iteration 55\n",
      "step: 2.53 seconds\n",
      "score: 1.333032\n",
      "iteration 56\n",
      "step: 2.54 seconds\n",
      "score: 1.333703\n",
      "iteration 57\n",
      "step: 2.53 seconds\n",
      "score: 1.333130\n",
      "iteration 58\n",
      "step: 2.53 seconds\n",
      "score: 1.333885\n",
      "iteration 59\n",
      "step: 2.53 seconds\n",
      "score: 1.333404\n",
      "iteration 60\n",
      "step: 2.54 seconds\n",
      "score: 1.333985\n",
      "iteration 61\n",
      "step: 2.53 seconds\n",
      "score: 1.333440\n",
      "iteration 62\n",
      "step: 2.53 seconds\n",
      "score: 1.334150\n",
      "iteration 63\n",
      "step: 2.53 seconds\n",
      "score: 1.333930\n",
      "iteration 64\n",
      "step: 2.53 seconds\n",
      "score: 1.334308\n",
      "iteration 65\n",
      "step: 2.53 seconds\n",
      "score: 1.334420\n",
      "iteration 66\n",
      "step: 2.53 seconds\n",
      "score: 1.334754\n",
      "iteration 67\n",
      "step: 2.53 seconds\n",
      "score: 1.334730\n",
      "iteration 68\n",
      "step: 2.53 seconds\n",
      "score: 1.334924\n",
      "iteration 69\n",
      "step: 2.53 seconds\n",
      "score: 1.335071\n",
      "iteration 70\n",
      "step: 2.53 seconds\n",
      "score: 1.334770\n",
      "iteration 71\n",
      "step: 2.53 seconds\n",
      "score: 1.334857\n",
      "iteration 72\n",
      "step: 2.53 seconds\n",
      "score: 1.334728\n",
      "iteration 73\n",
      "step: 2.53 seconds\n",
      "score: 1.334626\n",
      "iteration 74\n",
      "step: 2.53 seconds\n",
      "score: 1.334771\n",
      "iteration 75\n",
      "step: 2.53 seconds\n",
      "score: 1.334635\n",
      "iteration 76\n",
      "step: 2.53 seconds\n",
      "score: 1.334705\n",
      "iteration 77\n",
      "step: 2.53 seconds\n",
      "score: 1.334580\n",
      "iteration 78\n",
      "step: 2.53 seconds\n",
      "score: 1.334814\n",
      "iteration 79\n",
      "step: 2.53 seconds\n",
      "score: 1.334615\n",
      "iteration 80\n",
      "step: 2.53 seconds\n",
      "score: 1.334806\n",
      "iteration 81\n",
      "step: 2.53 seconds\n",
      "score: 1.334605\n",
      "iteration 82\n",
      "step: 2.53 seconds\n",
      "score: 1.334929\n"
     ]
    }
   ],
   "source": [
    "# largely the same optimization path regardless of the starting condition\n",
    "\n",
    "# For rigid, \n",
    "# grad_computation_sample_number = 1e5 is desired\n",
    "# grid_search_iteration_number and grid_search_sample_number seem to be unimportant as well, set to 100\n",
    "# lr1=10, lr2=.1 is best\n",
    "\n",
    "# For affine, \n",
    "# lr2 = .001 is too slow; 0.1 rises faster than 0.01\n",
    "# lr1 does not matter\n",
    "# plateus around iteration 100, but keep rising afterwards.\n",
    "# grad_computation_sample_number does not make a difference\n",
    "\n",
    "while True:\n",
    "\n",
    "    try:\n",
    "\n",
    "        if global_transform_scheme == 1:\n",
    "\n",
    "            T, scores = aligner.optimize(type='affine', max_iter_num=1000, history_len=10, terminate_thresh=1e-4,\n",
    "#                                          indices_m=[name_to_label_moving['SC'], name_to_label_moving['IC'],\n",
    "#                                                    name_to_label_moving['SC_surround'], name_to_label_moving['IC_surround']],\n",
    "                                         indices_m=None,\n",
    "                                        grid_search_iteration_number=30,\n",
    "                                         grid_search_sample_number=100,\n",
    "                                         grad_computation_sample_number=1e5,\n",
    "                                         lr1=10, lr2=0.1,\n",
    "                                         label_weights=label_weights_m,\n",
    "                                        std_tx=50, std_ty=50, std_tz=100, std_theta_xy=np.deg2rad(10))\n",
    "\n",
    "        elif global_transform_scheme == 2:\n",
    "\n",
    "            T, scores = aligner.optimize(type='rigid', max_iter_num=1000, history_len=10, terminate_thresh=1e-4,\n",
    "                                         indices_m=None,\n",
    "                                        grid_search_iteration_number=30,\n",
    "                                         grid_search_sample_number=100,\n",
    "                                         grad_computation_sample_number=1e5,\n",
    "                                         lr1=10, lr2=0.1,\n",
    "                                        label_weights=label_weights_m,\n",
    "                                        std_tx=50, std_ty=50, std_tz=100, std_theta_xy=np.deg2rad(10))\n",
    "        \n",
    "        break\n",
    "        \n",
    "    except Exception as e:\n",
    "        sys.stderr.write(e.message + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-eff692ebc88e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'T' is not defined"
     ]
    }
   ],
   "source": [
    "print T.reshape((3,4))\n",
    "plt.plot(scores);\n",
    "print max(scores), scores[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_fp = DataManager.get_global_alignment_parameters_filepath(stack_moving=stack_moving,\n",
    "                                                                stack_fixed=stack_fixed,\n",
    "                                                                train_sample_scheme=train_sample_scheme,\n",
    "                                                                global_transform_scheme=global_transform_scheme)\n",
    "\n",
    "\n",
    "DataManager.save_alignment_parameters(params_fp, T, \n",
    "                                      aligner.centroid_m, aligner.centroid_f,\n",
    "                                      aligner.xdim_m, aligner.ydim_m, aligner.zdim_m, \n",
    "                                      aligner.xdim_f, aligner.ydim_f, aligner.zdim_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score_plot_fp = DataManager.get_global_alignment_score_plot_filepath(stack_moving=stack_moving,\n",
    "                                                                    stack_fixed=stack_fixed,\n",
    "                                                                    train_sample_scheme=train_sample_scheme,\n",
    "                                                                    global_transform_scheme=global_transform_scheme)\n",
    "\n",
    "fig = plt.figure();\n",
    "plt.plot(scores);\n",
    "plt.savefig(score_plot_fp, bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stack_fixed = 'MD591'\n",
    "# stack_moving = 'atlas_on_MD589'\n",
    "stack_moving = 'atlasV2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_params, centroid_m, centroid_f, xdim_m, ydim_m, zdim_m, xdim_f, ydim_f, zdim_f = \\\n",
    "DataManager.load_global_alignment_parameters(stack_moving=stack_moving,\n",
    "                                                    stack_fixed=stack_fixed,\n",
    "                                                    train_sample_scheme=train_sample_scheme,\n",
    "                                                    global_transform_scheme=global_transform_scheme)\n",
    "#                                             trial_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmin_vol_f, xmax_vol_f, ymin_vol_f, ymax_vol_f, zmin_vol_f, zmax_vol_f = \\\n",
    "DataManager.load_score_volume_bbox(stack=stack_fixed, label='7N', downscale=32)\n",
    "\n",
    "print xmin_vol_f, xmax_vol_f, ymin_vol_f, ymax_vol_f, zmin_vol_f, zmax_vol_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# volumes_annotation = {'MD594':bp.unpack_ndarray_file('/home/yuncong/csd395/CSHL_atlasAlignParams_atlas_v2/MD594_to_MD589/MD594_down32_annotationVolume_alignedTo_MD589_down32_annotationVolume.bp'),\n",
    "#                       'MD589': bp.unpack_ndarray_file(VOLUME_ROOTDIR + '/MD589/MD589_down32_annotationVolume.bp')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "volumes_annotation = {'MD594': bp.unpack_ndarray_file(DataManager.get_transformed_volume_filepath(stack_m='MD594', type_m='annotation',\n",
    "                                                stack_f='MD589', type_f='annotation',\n",
    "                                                downscale=32, global_transform_scheme=global_transform_scheme)),\n",
    "                      \n",
    "                      'MD589': bp.unpack_ndarray_file(DataManager.get_annotation_volume_filepath(stack='MD589', downscale=32))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from registration_utilities import transform_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotation_volumes_volume_m_aligned_to_f = {}\n",
    "\n",
    "for stack, volume_annotation in volumes_annotation.iteritems():\n",
    "    \n",
    "    annotation_volumes_volume_m_aligned_to_f[stack] = transform_volume(vol=volume_annotation, \n",
    "                                                                       global_params=global_params, \n",
    "                                                                       centroid_m=centroid_m, \n",
    "                                                                       centroid_f=centroid_f,\n",
    "                                                                      xdim_f=xdim_f,\n",
    "                                                                      ydim_f=ydim_f,\n",
    "                                                                      zdim_f=zdim_f)\n",
    "    \n",
    "    output_fn = DataManager.get_transformed_volume_filepath(stack_m=stack, type_m='annotation',\n",
    "                                                stack_f=stack_fixed, type_f='score',\n",
    "                                                downscale=32, train_sample_scheme_f=train_sample_scheme)\n",
    "    \n",
    "    create_if_not_exists(os.path.dirname(output_fn))\n",
    "\n",
    "    bp.pack_ndarray_file(annotation_volumes_volume_m_aligned_to_f[stack], output_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# atlas_on_MD589"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from registration_utilities import find_contour_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "downsample_factor = 32\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "voxel_z_size = section_thickness / xy_pixel_distance_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "viz_dir = create_if_not_exists(DataManager.get_global_alignment_viz_dir(stack_moving=stack_moving,\n",
    "                                                        stack_fixed=stack_fixed,\n",
    "                                                        train_sample_scheme=train_sample_scheme,\n",
    "                                                        global_transform_scheme=global_transform_scheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first_sec, last_sec = metadata_cache['section_limits'][stack_fixed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack_colors = {'MD589': (255,0,0), 'MD594': (0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd395/yuncong/brain_virtualenv/lib/python2.7/site-packages/skimage/external/tifffile/tifffile.py:1794: RuntimeWarning: py_decodelzw encountered unexpected end of stream\n",
      "  strip = decompress(strip)\n"
     ]
    }
   ],
   "source": [
    "bar = show_progress_bar(first_sec, last_sec)\n",
    "\n",
    "for sec in range(first_sec, last_sec+1):\n",
    "    \n",
    "    if metadata_cache['sections_to_filenames'][stack_fixed][sec] in ['Placeholder', 'Rescan', 'Nonexisting']:\n",
    "        continue\n",
    "    \n",
    "    bar.value = sec\n",
    "\n",
    "    img_fn = DataManager.get_image_filepath(stack=stack_fixed, section=sec, resol='thumbnail', version='cropped_tif')\n",
    "    img = imread(img_fn)\n",
    "    \n",
    "    viz = img.copy()\n",
    "    \n",
    "    z = voxel_z_size * (sec - 1) - zmin_vol_f\n",
    "    \n",
    "    # Find fixed volume annotation contours\n",
    "#     contours_f_on_volume = find_contour_points(volume_fixed[..., int(z)])\n",
    "#     contours_f_on_cropped = {i: [cnt + (xmin_vol_f, ymin_vol_f) for cnt in cnts] for i, cnts in contours_f_on_volume.iteritems()}\n",
    "\n",
    "    # Find moving volume annotation contours\n",
    "    \n",
    "    for stack, volume_m_aligned_to_f in annotation_volumes_volume_m_aligned_to_f.iteritems():\n",
    "        contours_m_alignedTo_f_on_volume = find_contour_points(volume_m_aligned_to_f[..., int(z)])\n",
    "        contours_m_alignedTo_f_on_cropped = {i: [cnt + (xmin_vol_f, ymin_vol_f) for cnt in cnts] \n",
    "                                             for i, cnts in contours_m_alignedTo_f_on_volume.iteritems()}\n",
    "\n",
    "    #     # Draw fixed volume annotation contours\n",
    "    #     for ind_f, cnts_f in contours_f_on_cropped.iteritems():\n",
    "    #         for cnt_f in cnts_f:\n",
    "    #             cv2.polylines(viz, [cnt_f.astype(np.int)], True, (0,255,0), 2)\n",
    "\n",
    "        # Draw moving volume annotation contours\n",
    "        for ind_m, cnts_m in contours_m_alignedTo_f_on_cropped.iteritems():\n",
    "            for cnt_m in cnts_m:\n",
    "                cv2.polylines(viz, [cnt_m.astype(np.int)], True, stack_colors[stack], 2)\n",
    "\n",
    "    viz_fn = os.path.join(viz_dir, '%(stack_moving)s_to_%(stack_fixed)s_%(sec)04d.jpg' % \\\n",
    "          {'stack_moving': stack_moving, 'stack_fixed': stack_fixed, 'sec': sec})\n",
    "    imsave(viz_fn, viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Transform probabilistic atlas\n",
    "This part should go to `transform_brains`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform probabilistic atlas - atlasV2 \n",
    "# Identical to the part at the bottom of this notebook.\n",
    "\n",
    "for name_s in structures_sided:\n",
    "    \n",
    "    print name_s\n",
    "    \n",
    "    vol = bp.unpack_ndarray_file(DataManager.get_score_volume_filepath(stack=stack_moving, label=name_s, downscale=32))\n",
    "    \n",
    "    vol_m_aligned_to_f = transform_volume(vol=vol, global_params=global_params, \n",
    "                        centroid_m=centroid_m, \n",
    "                        centroid_f=centroid_f,\n",
    "                        xdim_f=xdim_f,\n",
    "                        ydim_f=ydim_f,\n",
    "                        zdim_f=zdim_f)\n",
    "    \n",
    "    vol_m_aligned_to_f = fill_sparse_score_volume(vol_m_aligned_to_f)\n",
    "    \n",
    "    output_fn = DataManager.get_transformed_volume_filepath(stack_m=stack_moving, type_m='score',\n",
    "                                                stack_f=stack_fixed, type_f='score',\n",
    "                                                label=name_s,\n",
    "                                                downscale=32, \n",
    "                                                train_sample_scheme_f=train_sample_scheme,\n",
    "                                                global_transform_scheme=global_transform_scheme)\n",
    "    \n",
    "    create_if_not_exists(os.path.dirname(output_fn))\n",
    "    bp.pack_ndarray_file(vol_m_aligned_to_f, output_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes2/atlasV2_to_MD603/atlasV2_down32_scoreVolume_to_MD603_down32_scoreVolume_5N_L_trainSampleScheme_1_globalTxScheme_1.bp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-dad9fd5b4244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mtrain_sample_scheme_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sample_scheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                          global_transform_scheme=global_transform_scheme)\n\u001b[0;32m----> 8\u001b[0;31m                         for name_s in structures_sided}\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-dad9fd5b4244>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m((name_s,))\u001b[0m\n\u001b[1;32m      6\u001b[0m                                          \u001b[0mtrain_sample_scheme_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_sample_scheme\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                          global_transform_scheme=global_transform_scheme)\n\u001b[0;32m----> 8\u001b[0;31m                         for name_s in structures_sided}\n\u001b[0m",
      "\u001b[0;32m/oasis/projects/nsf/csd395/yuncong/Brain/utilities/data_manager.pyc\u001b[0m in \u001b[0;36mload_transformed_volume\u001b[0;34m(stack_m, type_m, stack_f, type_f, downscale, train_sample_scheme_m, train_sample_scheme_f, global_transform_scheme, local_transform_scheme, label, transitive)\u001b[0m\n\u001b[1;32m    403\u001b[0m                                             \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                                             transitive=transitive)\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_ndarray_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/oasis/projects/nsf/csd395/yuncong/brain_virtualenv/lib/python2.7/site-packages/bloscpack/numpy_io.pyc\u001b[0m in \u001b[0;36munpack_ndarray_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0munpack_ndarray_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCompressedFPSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0munpack_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/oasis/projects/nsf/csd395/yuncong/CSHL_volumes2/atlasV2_to_MD603/atlasV2_down32_scoreVolume_to_MD603_down32_scoreVolume_5N_L_trainSampleScheme_1_globalTxScheme_1.bp'"
     ]
    }
   ],
   "source": [
    "# Read transformed volumes\n",
    "\n",
    "vols_m_aligned_to_f = {name_s: DataManager.load_transformed_volume(stack_m=stack_moving, type_m='score',\n",
    "                                         stack_f=stack_fixed, type_f='score',\n",
    "                                         label=name_s, downscale=32,\n",
    "                                         train_sample_scheme_f=train_sample_scheme,\n",
    "                                         global_transform_scheme=global_transform_scheme)\n",
    "                        for name_s in structures_sided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_colors = {level: (int(level*255),0,0) for level in [0.1, 0.25, 0.5, 0.75, .99]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_dir = create_if_not_exists(DataManager.get_global_alignment_viz_dir(stack_moving=stack_moving,\n",
    "                                                        stack_fixed=stack_fixed,\n",
    "                                                        train_sample_scheme=train_sample_scheme,\n",
    "                                                        global_transform_scheme=global_transform_scheme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/oasis/projects/nsf/csd395/yuncong/brain_virtualenv/lib/python2.7/site-packages/ipykernel/__main__.py:20: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "from registration_utilities import find_contour_points\n",
    "\n",
    "# estimate mapping between z and section\n",
    "downsample_factor = 32\n",
    "xy_pixel_distance_downsampled = xy_pixel_distance_lossless * downsample_factor\n",
    "voxel_z_size = section_thickness / xy_pixel_distance_downsampled\n",
    "\n",
    "first_sec, last_sec = metadata_cache['section_limits'][stack_fixed]\n",
    "bar = show_progress_bar(first_sec, last_sec)\n",
    "\n",
    "for sec in range(first_sec, last_sec+1):\n",
    "    \n",
    "    if metadata_cache['sections_to_filenames'][stack_fixed][sec] in ['Placeholder', 'Rescan', 'Nonexisting']:\n",
    "        continue\n",
    "    \n",
    "    bar.value = sec\n",
    "\n",
    "    img_fn = DataManager.get_image_filepath(stack=stack_fixed, section=sec, resol='thumbnail', version='cropped_tif')\n",
    "    img = imread(img_fn)\n",
    "    \n",
    "    viz = img.copy()\n",
    "    \n",
    "    z = voxel_z_size * (sec - 1) - zmin_vol_f\n",
    "    \n",
    "    # Find moving volume annotation contours\n",
    "    for name_s, vol in vols_m_aligned_to_f.iteritems():\n",
    "        for level in [0, 0.25, 0.5, 0.75, .99]:\n",
    "            cnts = find_contours(vol[..., z], level=level) # rows, cols\n",
    "            for cnt in cnts:\n",
    "                # r,c to x,y\n",
    "                cnt_on_cropped = cnt[:,::-1] + (xmin_vol_f, ymin_vol_f)\n",
    "                cv2.polylines(viz, [cnt_on_cropped.astype(np.int)], True, level_colors[level], 2)\n",
    "                \n",
    "\n",
    "    viz_fn = os.path.join(viz_dir, '%(stack_moving)s_to_%(stack_fixed)s_%(sec)04d.jpg' % \\\n",
    "          {'stack_moving': stack_moving, 'stack_fixed': stack_fixed, 'sec': sec})\n",
    "    imsave(viz_fn, viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRANSFORM VOLUMES - TODO: put in a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from registration_utilities import transform_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N_L\n",
      "5N_R\n",
      "6N_L\n",
      "6N_R\n",
      "7N_L\n",
      "7N_R\n",
      "7n_L\n",
      "7n_R\n",
      "Amb_L\n",
      "Amb_R\n",
      "LC_L\n",
      "LC_R\n",
      "LRt_L\n",
      "LRt_R\n",
      "Pn_L\n",
      "Pn_R\n",
      "Tz_L\n",
      "Tz_R\n",
      "VLL_L\n",
      "VLL_R\n",
      "RMC_L\n",
      "RMC_R\n",
      "SNC_L\n",
      "SNC_R\n",
      "SNR_L\n",
      "SNR_R\n",
      "3N_L\n",
      "3N_R\n",
      "4N_L\n",
      "4N_R\n",
      "Sp5I_L\n",
      "Sp5I_R\n",
      "Sp5O_L\n",
      "Sp5O_R\n",
      "Sp5C_L\n",
      "Sp5C_R\n",
      "PBG_L\n",
      "PBG_R\n",
      "10N_L\n",
      "10N_R\n",
      "VCA_L\n",
      "VCA_R\n",
      "VCP_L\n",
      "VCP_R\n",
      "DC_L\n",
      "DC_R\n",
      "AP\n",
      "12N\n",
      "RtTg\n",
      "SC\n",
      "IC\n"
     ]
    }
   ],
   "source": [
    "# Transform moving volume, sided\n",
    "\n",
    "structures_sided = sum([[n] if n in singular_structures else [convert_to_left_name(n), convert_to_right_name(n)] \n",
    "                        for n in structures], [])\n",
    "\n",
    "for name_s in structures_sided:\n",
    "    \n",
    "    print name_s\n",
    "    \n",
    "    vol_m = DataManager.load_score_volume(stack=stack_moving, label=name_s, downscale=32)\n",
    "    \n",
    "    volume_m_alignedTo_f = \\\n",
    "    transform_volume(vol=vol_m, global_params=global_params, centroid_m=centroid_m, centroid_f=centroid_f,\n",
    "                      xdim_f=xdim_f, ydim_f=ydim_f, zdim_f=zdim_f)\n",
    "    \n",
    "    volume_m_alignedTo_f_fn = DataManager.get_transformed_volume_filepath(stack_m=stack_moving, type_m='score',\n",
    "                                            stack_f=stack_fixed, type_f='score',\n",
    "                                            label=name_s,\n",
    "                                            downscale=32, \n",
    "                                            train_sample_scheme_f=1)\n",
    "    \n",
    "    create_if_not_exists(os.path.dirname(volume_m_alignedTo_f_fn))\n",
    "    \n",
    "    bp.pack_ndarray_file(volume_m_alignedTo_f, volume_m_alignedTo_f_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5N_L\n",
      "5N_R\n",
      "6N_L\n",
      "6N_R\n",
      "7N_L\n",
      "7N_R\n",
      "7n_L\n",
      "7n_R\n",
      "Amb_L\n",
      "Amb_R\n",
      "LC_L\n",
      "LC_R\n",
      "LRt_L\n",
      "LRt_R\n",
      "Pn_L\n",
      "Pn_R\n",
      "Tz_L\n",
      "Tz_R\n",
      "VLL_L\n",
      "VLL_R\n",
      "RMC_L\n",
      "RMC_R\n",
      "SNC_L\n",
      "SNC_R\n",
      "SNR_L\n",
      "SNR_R\n",
      "3N_L\n",
      "3N_R\n",
      "4N_L\n",
      "4N_R\n",
      "Sp5I_L\n",
      "Sp5I_R\n",
      "Sp5O_L\n",
      "Sp5O_R\n",
      "Sp5C_L\n",
      "Sp5C_R\n",
      "PBG_L\n",
      "PBG_R\n",
      "10N_L\n",
      "10N_R\n",
      "VCA_L\n",
      "VCA_R\n",
      "VCP_L\n",
      "VCP_R\n",
      "DC_L\n",
      "DC_R\n",
      "AP\n",
      "12N\n",
      "RtTg\n",
      "SC\n",
      "IC\n"
     ]
    }
   ],
   "source": [
    "# Transform moving volume, sided\n",
    "\n",
    "structures_sided = sum([[n] if n in singular_structures else [convert_to_left_name(n), convert_to_right_name(n)] \n",
    "                        for n in structures], [])\n",
    "\n",
    "for name_s in structures_sided:\n",
    "    \n",
    "    print name_s+'_surround'\n",
    "    \n",
    "    vol_m = DataManager.load_score_volume(stack=stack_moving, label=name_s+'_surround', downscale=32)\n",
    "    \n",
    "    volume_m_alignedTo_f = \\\n",
    "    transform_volume(vol=vol_m, global_params=global_params, centroid_m=centroid_m, centroid_f=centroid_f,\n",
    "                      xdim_f=xdim_f, ydim_f=ydim_f, zdim_f=zdim_f)\n",
    "    \n",
    "    volume_m_alignedTo_f_fn = DataManager.get_transformed_volume_filepath(stack_m=stack_moving, type_m='score',\n",
    "                                            stack_f=stack_fixed, type_f='score',\n",
    "                                            label=name_s+'_surround',\n",
    "                                            downscale=32, \n",
    "                                            train_sample_scheme_f=1)\n",
    "    \n",
    "    create_if_not_exists(os.path.dirname(volume_m_alignedTo_f_fn))\n",
    "    \n",
    "    bp.pack_ndarray_file(volume_m_alignedTo_f, volume_m_alignedTo_f_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
